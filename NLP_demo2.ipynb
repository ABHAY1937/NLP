{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa00oG2ZIrq9PaYqzww3yl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHAY1937/NLP/blob/main/NLP_demo2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnP5CZuTVv40",
        "outputId": "06c743bf-8920-46e5-8e10-6087db25a42a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"XLNet: Generalized Autoregressive Pretraining\n",
        "for Language Understanding\n",
        "Zhilin Yang∗1\n",
        ", Zihang Dai∗12, Yiming Yang1\n",
        ", Jaime Carbonell1\n",
        ",\n",
        "Ruslan Salakhutdinov1\n",
        ", Quoc V. Le2\n",
        "1Carnegie Mellon University, 2Google AI Brain Team\n",
        "{zhiliny,dzihang,yiming,jgc,rsalakhu}@cs.cmu.edu, qvl@google.com\n",
        "Abstract\n",
        "With the capability of modeling bidirectional contexts, denoising autoencoding\n",
        "based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions\n",
        "and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we\n",
        "propose XLNet, a generalized autoregressive pretraining method that (1) enables\n",
        "learning bidirectional contexts by maximizing the expected likelihood over all\n",
        "permutations of the factorization order and (2) overcomes the limitations of BERT\n",
        "thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas\n",
        "from Transformer-XL, the state-of-the-art autoregressive model, into pretraining.\n",
        "Empirically, under comparable experiment settings, XLNet outperforms BERT on\n",
        "20 tasks, often by a large margin, including question answering, natural language\n",
        "inference, sentiment analysis, and document ranking.1\n",
        ".\n",
        "1 Introduction\n",
        "Unsupervised representation learning has been highly successful in the domain of natural language\n",
        "processing [7, 22, 27, 28, 10]. Typically, these methods first pretrain neural networks on large-scale\n",
        "unlabeled text corpora, and then finetune the models or representations on downstream tasks. Under\n",
        "this shared high-level idea, different unsupervised pretraining objectives have been explored in\n",
        "literature. Among them, autoregressive (AR) language modeling and autoencoding (AE) have been\n",
        "the two most successful pretraining objectives.\n",
        "AR language modeling seeks to estimate the probability distribution of a text corpus with an autoregressive model [7, 27, 28]. Specifically, given a text sequence x = (x1, · · · , xT ), AR language\n",
        "modeling factorizes the likelihood into a forward product p(x) = QT\n",
        "t=1 p(xt | x<t) or a backward\n",
        "one p(x) = Q1\n",
        "t=T\n",
        "p(xt | x>t). A parametric model (e.g. a neural network) is trained to model each\n",
        "conditional distribution. Since an AR language model is only trained to encode a uni-directional context (either forward or backward), it is not effective at modeling deep bidirectional contexts. On the\n",
        "contrary, downstream language understanding tasks often require bidirectional context information.\n",
        "This results in a gap between AR language modeling and effective pretraining.\n",
        "In comparison, AE based pretraining does not perform explicit density estimation but instead aims to\n",
        "reconstruct the original data from corrupted input. A notable example is BERT [10], which has been\n",
        "the state-of-the-art pretraining approach. Given the input token sequence, a certain portion of tokens\n",
        "are replaced by a special symbol [MASK], and the model is trained to recover the original tokens from\n",
        "the corrupted version. Since density estimation is not part of the objective, BERT is allowed to utilize\n",
        "∗Equal contribution. Order determined by swapping the one in [9].\n",
        "1\n",
        "Pretrained models and code are available at https://github.com/zihangdai/xlnet\n",
        "33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\n",
        "arXiv:1906.08237v2 [cs.CL] 2 Jan 2020\n",
        "bidirectional contexts for reconstruction. As an immediate benefit, this closes the aforementioned\n",
        "bidirectional information gap in AR language modeling, leading to improved performance. However,\n",
        "the artificial symbols like [MASK] used by BERT during pretraining are absent from real data at\n",
        "finetuning time, resulting in a pretrain-finetune discrepancy. Moreover, since the predicted tokens are\n",
        "masked in the input, BERT is not able to model the joint probability using the product rule as in AR\n",
        "language modeling. In other words, BERT assumes the predicted tokens are independent of each\n",
        "other given the unmasked tokens, which is oversimplified as high-order, long-range dependency is\n",
        "prevalent in natural language [9].\n",
        "Faced with the pros and cons of existing language pretraining objectives, in this work, we propose\n",
        "XLNet, a generalized autoregressive method that leverages the best of both AR language modeling\n",
        "and AE while avoiding their limitations.\n",
        "• Firstly, instead of using a fixed forward or backward factorization order as in conventional AR models, XLNet maximizes the expected log likelihood of a sequence w.r.t. all possible permutations\n",
        "of the factorization order. Thanks to the permutation operation, the context for each position can\n",
        "consist of tokens from both left and right. In expectation, each position learns to utilize contextual\n",
        "information from all positions, i.e., capturing bidirectional context.\n",
        "• Secondly, as a generalized AR language model, XLNet does not rely on data corruption. Hence,\n",
        "XLNet does not suffer from the pretrain-finetune discrepancy that BERT is subject to. Meanwhile,\n",
        "the autoregressive objective also provides a natural way to use the product rule for factorizing the\n",
        "joint probability of the predicted tokens, eliminating the independence assumption made in BERT.\n",
        "In addition to a novel pretraining objective, XLNet improves architectural designs for pretraining.\n",
        "• Inspired by the latest advancements in AR language modeling, XLNet integrates the segment\n",
        "recurrence mechanism and relative encoding scheme of Transformer-XL [9] into pretraining, which\n",
        "empirically improves the performance especially for tasks involving a longer text sequence.\n",
        "• Naively applying a Transformer(-XL) architecture to permutation-based language modeling does\n",
        "not work because the factorization order is arbitrary and the target is ambiguous. As a solution, we\n",
        "propose to reparameterize the Transformer(-XL) network to remove the ambiguity.\n",
        "Empirically, under comparable experiment setting, XLNet consistently outperforms BERT [10] on a\n",
        "wide spectrum of problems including GLUE language understanding tasks, reading comprehension\n",
        "tasks like SQuAD and RACE, text classification tasks such as Yelp and IMDB, and the ClueWeb09-B\n",
        "document ranking task.\n",
        "Related Work The idea of permutation-based AR modeling has been explored in [32, 12], but there\n",
        "are several key differences. Firstly, previous models aim to improve density estimation by baking\n",
        "an “orderless” inductive bias into the model while XLNet is motivated by enabling AR language\n",
        "models to learn bidirectional contexts. Technically, to construct a valid target-aware prediction\n",
        "distribution, XLNet incorporates the target position into the hidden state via two-stream attention\n",
        "while previous permutation-based AR models relied on implicit position awareness inherent to their\n",
        "MLP architectures. Finally, for both orderless NADE and XLNet, we would like to emphasize that\n",
        "“orderless” does not mean that the input sequence can be randomly permuted but that the model\n",
        "allows for different factorization orders of the distribution.\n",
        "Another related idea is to perform autoregressive denoising in the context of text generation [11],\n",
        "which only considers a fixed order though.\n",
        "2 Proposed Method\n",
        "2.1 Background\n",
        "In this section, we first review and compare the conventional AR language modeling and BERT for\n",
        "language pretraining. Given a text sequence x = [x1, · · · , xT ], AR language modeling performs\n",
        "pretraining by maximizing the likelihood under the forward autoregressive factorization:\n",
        "max\n",
        "θ\n",
        "log pθ(x) = X\n",
        "T\n",
        "t=1\n",
        "log pθ(xt | x<t) = X\n",
        "T\n",
        "t=1\n",
        "log\n",
        "exp\n",
        "hθ(x1:t−1)\n",
        ">e(xt)\n",
        "\u0001\n",
        "P\n",
        "x0 exp (hθ(x1:t−1)>e(x\n",
        "0)), (1)\n",
        "\n",
        "where hθ(x1:t−1) is a context representation produced by neural models, such as RNNs or Transformers, and e(x) denotes the embedding of x. In comparison, BERT is based on denoising auto-encoding.\n",
        "Specifically, for a text sequence x, BERT first constructs a corrupted version xˆ by randomly setting\n",
        "a portion (e.g. 15%) of tokens in x to a special symbol [MASK]. Let the masked tokens be x¯. The\n",
        "training objective is to reconstruct x¯ from xˆ:\n",
        "max\n",
        "θ\n",
        "log pθ(x¯ | xˆ) ≈\n",
        "X\n",
        "T\n",
        "t=1\n",
        "mt log pθ(xt | xˆ) = X\n",
        "T\n",
        "t=1\n",
        "mt log\n",
        "exp\n",
        "Hθ(xˆ)\n",
        ">\n",
        "t\n",
        "e(xt)\n",
        "\u0001\n",
        "P\n",
        "x0 exp\n",
        "Hθ(xˆ)\n",
        ">\n",
        "t\n",
        "e(x\n",
        "0)\n",
        "\u0001 , (2)\n",
        "where mt = 1 indicates xt is masked, and Hθ is a Transformer that maps a length-T text sequence x\n",
        "into a sequence of hidden vectors Hθ(x) = [Hθ(x)1, Hθ(x)2, · · · , Hθ(x)T ]. The pros and cons of\n",
        "the two pretraining objectives are compared in the following aspects:\n",
        "• Independence Assumption: As emphasized by the ≈ sign in Eq. (2), BERT factorizes the joint\n",
        "conditional probability p(x¯ | xˆ) based on an independence assumption that all masked tokens x¯\n",
        "are separately reconstructed. In comparison, the AR language modeling objective (1) factorizes\n",
        "pθ(x) using the product rule that holds universally without such an independence assumption.\n",
        "• Input noise: The input to BERT contains artificial symbols like [MASK] that never occur in\n",
        "downstream tasks, which creates a pretrain-finetune discrepancy. Replacing [MASK] with original\n",
        "tokens as in [10] does not solve the problem because original tokens can be only used with a small\n",
        "probability — otherwise Eq. (2) will be trivial to optimize. In comparison, AR language modeling\n",
        "does not rely on any input corruption and does not suffer from this issue.\n",
        "• Context dependency: The AR representation hθ(x1:t−1) is only conditioned on the tokens up\n",
        "to position t (i.e. tokens to the left), while the BERT representation Hθ(x)t has access to the\n",
        "contextual information on both sides. As a result, the BERT objective allows the model to be\n",
        "pretrained to better capture bidirectional context.\n",
        "2.2 Objective: Permutation Language Modeling\n",
        "According to the comparison above, AR language modeling and BERT possess their unique advantages over the other. A natural question to ask is whether there exists a pretraining objective that\n",
        "brings the advantages of both while avoiding their weaknesses.\n",
        "Borrowing ideas from orderless NADE [32], we propose the permutation language modeling objective\n",
        "that not only retains the benefits of AR models but also allows models to capture bidirectional\n",
        "contexts. Specifically, for a sequence x of length T, there are T! different orders to perform a valid\n",
        "autoregressive factorization. Intuitively, if model parameters are shared across all factorization orders,\n",
        "in expectation, the model will learn to gather information from all positions on both sides.\n",
        "To formalize the idea, let ZT be the set of all possible permutations of the length-T index sequence\n",
        "[1, 2, . . . , T]. We use zt and z<t to denote the t-th element and the first t−1 elements of a permutation\n",
        "z ∈ ZT . Then, our proposed permutation language modeling objective can be expressed as follows:\n",
        "max\n",
        "θ\n",
        "Ez∼ZT\n",
        "\"X\n",
        "T\n",
        "t=1\n",
        "log pθ(xzt\n",
        "| xz<t )\n",
        "#\n",
        ". (3)\n",
        "Essentially, for a text sequence x, we sample a factorization order z at a time and decompose the\n",
        "likelihood pθ(x) according to factorization order. Since the same model parameter θ is shared across\n",
        "all factorization orders during training, in expectation, xt has seen every possible element xi 6= xt in\n",
        "the sequence, hence being able to capture the bidirectional context. Moreover, as this objective fits\n",
        "into the AR framework, it naturally avoids the independence assumption and the pretrain-finetune\n",
        "discrepancy discussed in Section 2.1.\n",
        "Remark on Permutation The proposed objective only permutes the factorization order, not the\n",
        "sequence order. In other words, we keep the original sequence order, use the positional encodings\n",
        "corresponding to the original sequence, and rely on a proper attention mask in Transformers to\n",
        "achieve permutation of the factorization order. Note that this choice is necessary, since the model\n",
        "will only encounter text sequences with the natural order during finetuning.\n",
        "To provide an overall picture, we show an example of predicting the token x3 given the same input\n",
        "sequence x but under different factorization orders in the Appendix A.7 with Figure 4.\n",
        "\n",
        "2.3 Architecture: Two-Stream Self-Attention for Target-Aware Representations\n",
        "Sample a factorization order:\n",
        "3 à 2 à 4 à 1\n",
        "Attention Masks\n",
        "e(x$) w e(x') w e(x() w e(x)) w\n",
        "h$\n",
        "($) g$\n",
        "($) h'\n",
        "($) g'\n",
        "($) h(\n",
        "($) g(\n",
        "($) h)\n",
        "($) g)\n",
        "($)\n",
        "h$\n",
        "(') g$\n",
        "(') h'\n",
        "(') g'\n",
        "(') h(\n",
        "(') g(\n",
        "(') h)\n",
        "(') g)\n",
        "(')\n",
        "Content stream:\n",
        "can see self\n",
        "Query stream:\n",
        "cannot see self\n",
        "x$ x' x( x)\n",
        "Masked Two-stream Attention\n",
        "Masked Two-stream Attention\n",
        "(c)\n",
        "h$\n",
        "(,) g$\n",
        "(,) h'\n",
        "(,) g'\n",
        "(,) h(\n",
        "(,) g(\n",
        "(,) h)\n",
        "(,) g)\n",
        "(,)\n",
        "h$\n",
        "($) g$\n",
        "($)\n",
        "Attention\n",
        "Q K, V\n",
        "h$\n",
        "($) g$\n",
        "($)\n",
        "Attention\n",
        "Q K, V\n",
        "(b)\n",
        "(a)\n",
        "h$\n",
        "(,) g$\n",
        "(,) h'\n",
        "(,) g'\n",
        "(,) h(\n",
        "(,) g(\n",
        "(,) h)\n",
        "(,) g)\n",
        "(,)\n",
        "Figure 1: (a): Content stream attention, which is the same as the standard self-attention. (b): Query\n",
        "stream attention, which does not have access information about the content xzt\n",
        ". (c): Overview of the\n",
        "permutation language modeling training with two-stream attention.\n",
        "While the permutation language modeling objective has desired properties, naive implementation with\n",
        "standard Transformer parameterization may not work. To see the problem, assume we parameterize\n",
        "the next-token distribution pθ(Xzt\n",
        "| xz<t ) using the standard Softmax formulation, i.e., pθ(Xzt =\n",
        "x | xz<t ) = exp(e(x)\n",
        ">hθ(xz<t ))\n",
        "P\n",
        "x0 exp(e(x0)>hθ(xz<t ))\n",
        ", where hθ(xz<t ) denotes the hidden representation of xz<t\n",
        "produced by the shared Transformer network after proper masking. Now notice that the representation\n",
        "hθ(xz<t ) does not depend on which position it will predict, i.e., the value of zt. Consequently, the\n",
        "same distribution is predicted regardless of the target position, which is not able to learn useful\n",
        "representations (see Appendix A.1 for a concrete example). To avoid this problem, we propose to\n",
        "re-parameterize the next-token distribution to be target position aware:\n",
        "pθ(Xzt = x | xz<t ) = exp\n",
        "e(x)\n",
        ">gθ(xz<t , zt)\n",
        "\u0001\n",
        "P\n",
        "x0 exp (e(x\n",
        "0)>gθ(xz<t , zt)), (4)\n",
        "where gθ(xz<t , zt) denotes a new type of representations which additionally take the target position\n",
        "zt as input.\n",
        "Two-Stream Self-Attention While the idea of target-aware representations removes the ambiguity\n",
        "in target prediction, how to formulate gθ(xz<t , zt) remains a non-trivial problem. Among other\n",
        "possibilities, we propose to “stand” at the target position zt and rely on the position zt to gather\n",
        "information from the context xz<t through attention. For this parameterization to work, there are two\n",
        "requirements that are contradictory in a standard Transformer architecture: (1) to predict the token\n",
        "xzt\n",
        ", gθ(xz<t , zt) should only use the position zt and not the content xzt\n",
        ", otherwise the objective\n",
        "becomes trivial; (2) to predict the other tokens xzj with j > t, gθ(xz<t , zt) should also encode the\n",
        "content xzt\n",
        "to provide full contextual information. To resolve such a contradiction, we propose to use\n",
        "two sets of hidden representations instead of one:\n",
        "• The content representation hθ(xz≤t\n",
        "), or abbreviated as hzt\n",
        ", which serves a similar role to the\n",
        "standard hidden states in Transformer. This representation encodes both the context and xzt\n",
        "itself.\n",
        "• The query representation gθ(xz<t , zt), or abbreviated as gzt\n",
        ", which only has access to the contextual information xz<t and the position zt, but not the content xzt\n",
        ", as discussed above.\n",
        "Computationally, the first layer query stream is initialized with a trainable vector, i.e. g\n",
        "(0)\n",
        "i = w,\n",
        "while the content stream is set to the corresponding word embedding, i.e. h\n",
        "(0)\n",
        "i = e(xi). For each\n",
        "self-attention layer m = 1, . . . , M, the two streams of representations are schematically2 updated\n",
        "2To avoid clutter, we omit the implementation details including multi-head attention, residual connection,\n",
        "layer normalization and position-wise feed-forward as used in Transformer(-XL). The details are included in\n",
        "Appendix A.2 for reference.\n",
        "\n",
        "with a shared set of parameters as follows (illustrated in Figures 1 (a) and (b)):\n",
        "g\n",
        "(m)\n",
        "zt ← Attention(Q = g\n",
        "(m−1)\n",
        "zt\n",
        ", KV = h\n",
        "(m−1)\n",
        "z<t\n",
        "; θ), (query stream: use zt but cannot see xzt\n",
        ")\n",
        "h\n",
        "(m)\n",
        "zt ← Attention(Q = h\n",
        "(m−1)\n",
        "zt\n",
        ", KV = h\n",
        "(m−1)\n",
        "z≤t\n",
        "; θ), (content stream: use both zt and xzt\n",
        ").\n",
        "where Q, K, V denote the query, key, and value in an attention operation [33]. The update rule of the\n",
        "content representations is exactly the same as the standard self-attention, so during finetuning, we\n",
        "can simply drop the query stream and use the content stream as a normal Transformer(-XL). Finally,\n",
        "we can use the last-layer query representation g\n",
        "(M)\n",
        "zt\n",
        "to compute Eq. (4).\n",
        "Partial Prediction While the permutation language modeling objective (3) has several benefits, it is\n",
        "a much more challenging optimization problem due to the permutation and causes slow convergence\n",
        "in preliminary experiments. To reduce the optimization difficulty, we choose to only predict the last\n",
        "tokens in a factorization order. Formally, we split z into a non-target subsequence z≤c and a target\n",
        "subsequence z>c, where c is the cutting point. The objective is to maximize the log-likelihood of the\n",
        "target subsequence conditioned on the non-target subsequence, i.e.,\n",
        "max\n",
        "θ\n",
        "Ez∼ZT\n",
        "h\n",
        "log pθ(xz>c | xz≤c\n",
        ")\n",
        "i\n",
        "= Ez∼ZT\n",
        "\n",
        "\n",
        "X\n",
        "|z|\n",
        "t=c+1\n",
        "log pθ(xzt\n",
        "| xz<t )\n",
        "\n",
        ". (5)\n",
        "Note that z>c is chosen as the target because it possesses the longest context in the sequence given the\n",
        "current factorization order z. A hyperparameter K is used such that about 1/K tokens are selected\n",
        "for predictions; i.e., |z| /(|z| − c) ≈ K. For unselected tokens, their query representations need not\n",
        "be computed, which saves speed and memory.\n",
        "2.4 Incorporating Ideas from Transformer-XL\n",
        "Since our objective function fits in the AR framework, we incorporate the state-of-the-art AR\n",
        "language model, Transformer-XL [9], into our pretraining framework, and name our method after it.\n",
        "We integrate two important techniques in Transformer-XL, namely the relative positional encoding\n",
        "scheme and the segment recurrence mechanism. We apply relative positional encodings based on the\n",
        "original sequence as discussed earlier, which is straightforward. Now we discuss how to integrate the\n",
        "recurrence mechanism into the proposed permutation setting and enable the model to reuse hidden\n",
        "states from previous segments. Without loss of generality, suppose we have two segments taken from\n",
        "a long sequence s; i.e., x˜ = s1:T and x = sT +1:2T . Let z˜ and z be permutations of [1 · · · T] and\n",
        "[T + 1 · · · 2T] respectively. Then, based on the permutation z˜, we process the first segment, and then\n",
        "cache the obtained content representations h˜(m)\n",
        "for each layer m. Then, for the next segment x, the\n",
        "attention update with memory can be written as\n",
        "h\n",
        "(m)\n",
        "zt ← Attention(Q = h\n",
        "(m−1)\n",
        "zt\n",
        ", KV =\n",
        "h\n",
        "h˜(m−1)\n",
        ", h\n",
        "(m−1)\n",
        "z≤t\n",
        "i\n",
        "; θ)\n",
        "where [., .] denotes concatenation along the sequence dimension. Notice that positional encodings\n",
        "only depend on the actual positions in the original sequence. Thus, the above attention update is\n",
        "independent of z˜ once the representations h˜(m)\n",
        "are obtained. This allows caching and reusing the\n",
        "memory without knowing the factorization order of the previous segment. In expectation, the model\n",
        "learns to utilize the memory over all factorization orders of the last segment. The query stream can\n",
        "be computed in the same way. Finally, Figure 1 (c) presents an overview of the proposed permutation\n",
        "language modeling with two-stream attention (see Appendix A.7 for more detailed illustration).\n",
        "2.5 Modeling Multiple Segments\n",
        "Many downstream tasks have multiple input segments, e.g., a question and a context paragraph in\n",
        "question answering. We now discuss how we pretrain XLNet to model multiple segments in the\n",
        "autoregressive framework. During the pretraining phase, following BERT, we randomly sample two\n",
        "segments (either from the same context or not) and treat the concatenation of two segments as one\n",
        "sequence to perform permutation language modeling. We only reuse the memory that belongs to\n",
        "the same context. Specifically, the input to our model is the same as BERT: [CLS, A, SEP, B, SEP],\n",
        "where “SEP” and “CLS” are two special symbols and “A” and “B” are the two segments. Although\n",
        "5\n",
        "we follow the two-segment data format, XLNet-Large does not use the objective of next sentence\n",
        "prediction [10] as it does not show consistent improvement in our ablation study (see Section 3.4).\n",
        "Relative Segment Encodings Architecturally, different from BERT that adds an absolute segment\n",
        "embedding to the word embedding at each position, we extend the idea of relative encodings from\n",
        "Transformer-XL to also encode the segments. Given a pair of positions i and j in the sequence, if\n",
        "i and j are from the same segment, we use a segment encoding sij = s+ or otherwise sij = s−,\n",
        "where s+ and s− are learnable model parameters for each attention head. In other words, we only\n",
        "consider whether the two positions are within the same segment, as opposed to considering which\n",
        "specific segments they are from. This is consistent with the core idea of relative encodings; i.e., only\n",
        "modeling the relationships between positions. When i attends to j, the segment encoding sij is used\n",
        "to compute an attention weight aij = (qi + b)\n",
        ">sij , where qi\n",
        "is the query vector as in a standard\n",
        "attention operation and b is a learnable head-specific bias vector. Finally, the value aij is added to\n",
        "the normal attention weight. There are two benefits of using relative segment encodings. First, the\n",
        "inductive bias of relative encodings improves generalization [9]. Second, it opens the possibility of\n",
        "finetuning on tasks that have more than two input segments, which is not possible using absolute\n",
        "segment encodings.\n",
        "2.6 Discussion\n",
        "Comparing Eq. (2) and (5), we observe that both BERT and XLNet perform partial prediction, i.e.,\n",
        "only predicting a subset of tokens in the sequence. This is a necessary choice for BERT because if all\n",
        "tokens are masked, it is impossible to make any meaningful predictions. In addition, for both BERT\n",
        "and XLNet, partial prediction plays a role of reducing optimization difficulty by only predicting\n",
        "tokens with sufficient context. However, the independence assumption discussed in Section 2.1\n",
        "disables BERT to model dependency between targets.\n",
        "To better understand the difference, let’s consider a concrete example [New, York, is, a, city]. Suppose\n",
        "both BERT and XLNet select the two tokens [New, York] as the prediction targets and maximize\n",
        "log p(New York | is a city). Also suppose that XLNet samples the factorization order [is, a, city,\n",
        "New, York]. In this case, BERT and XLNet respectively reduce to the following objectives:\n",
        "JBERT = log p(New | is a city) + log p(York | is a city),\n",
        "JXLNet = log p(New | is a city) + log p(York | New, is a city).\n",
        "Notice that XLNet is able to capture the dependency between the pair (New, York), which is omitted\n",
        "by BERT. Although in this example, BERT learns some dependency pairs such as (New, city) and\n",
        "(York, city), it is obvious that XLNet always learns more dependency pairs given the same target and\n",
        "contains “denser” effective training signals.\n",
        "For more formal analysis and further discussion, please refer to Appendix A.5.\n",
        "3 Experiments\n",
        "3.1 Pretraining and Implementation\n",
        "Following BERT [10], we use the BooksCorpus [40] and English Wikipedia as part of our pretraining\n",
        "data, which have 13GB plain text combined. In addition, we include Giga5 (16GB text) [26],\n",
        "ClueWeb 2012-B (extended from [5]), and Common Crawl [6] for pretraining. We use heuristics\n",
        "to aggressively filter out short or low-quality articles for ClueWeb 2012-B and Common Crawl,\n",
        "which results in 19GB and 110GB text respectively. After tokenization with SentencePiece [17], we\n",
        "obtain 2.78B, 1.09B, 4.75B, 4.30B, and 19.97B subword pieces for Wikipedia, BooksCorpus, Giga5,\n",
        "ClueWeb, and Common Crawl respectively, which are 32.89B in total.\n",
        "Our largest model XLNet-Large has the same architecture hyperparameters as BERT-Large, which\n",
        "results in a similar model size. During pretraining, we always use a full sequence length of 512.\n",
        "Firstly, to provide a fair comparison with BERT (section 3.2), we also trained XLNet-Large-wikibooks\n",
        "on BooksCorpus and Wikipedia only, where we reuse all pretraining hyper-parameters as in the\n",
        "original BERT. Then, we scale up the training of XLNet-Large by using all the datasets described\n",
        "above. Specifically, we train on 512 TPU v3 chips for 500K steps with an Adam weight decay\n",
        "optimizer, linear learning rate decay, and a batch size of 8192, which takes about 5.5 days. It was\n",
        "6\n",
        "observed that the model still underfits the data at the end of training. Finally, we perform ablation\n",
        "study (section 3.4) based on the XLNet-Base-wikibooks.\n",
        "Since the recurrence mechanism is introduced, we use a bidirectional data input pipeline where each\n",
        "of the forward and backward directions takes half of the batch size. For training XLNet-Large, we set\n",
        "the partial prediction constant K as 6 (see Section 2.3). Our finetuning procedure follows BERT [10]\n",
        "except otherwise specified3\n",
        ". We employ an idea of span-based prediction, where we first sample a\n",
        "length L ∈ [1, · · · , 5], and then randomly select a consecutive span of L tokens as prediction targets\n",
        "within a context of (KL) tokens.\n",
        "We use a variety of natural language understanding datasets to evaluate the performance of our\n",
        "method. Detailed descriptions of the settings for all the datasets can be found in Appendix A.3.\n",
        "3.2 Fair Comparison with BERT\n",
        "Model SQuAD1.1 SQuAD2.0 RACE MNLI QNLI QQP RTE SST-2 MRPC CoLA STS-B\n",
        "BERT-Large\n",
        "(Best of 3)\n",
        "86.7/92.8 82.8/85.5 75.1 87.3 93.0 91.4 74.0 94.0 88.7 63.7 90.2\n",
        "XLNet-Largewikibooks\n",
        "88.2/94.0 85.1/87.8 77.4 88.4 93.9 91.8 81.2 94.4 90.0 65.2 91.1\n",
        "Table 1: Fair comparison with BERT. All models are trained using the same data and hyperparameters as in\n",
        "BERT. We use the best of 3 BERT variants for comparison; i.e., the original BERT, BERT with whole word\n",
        "masking, and BERT without next sentence prediction.\n",
        "Here, we first compare the performance of BERT and XLNet in a fair setting to decouple the effects\n",
        "of using more data and the improvement from BERT to XLNet. In Table 1, we compare (1) best\n",
        "performance of three different variants of BERT and (2) XLNet trained with the same data and\n",
        "hyperparameters. As we can see, trained on the same data with an almost identical training recipe,\n",
        "XLNet outperforms BERT by a sizable margin on all the considered datasets.\n",
        "3.3 Comparison with RoBERTa: Scaling Up\n",
        "RACE Accuracy Middle High Model NDCG@20 ERR@20\n",
        "GPT [28] 59.0 62.9 57.4 DRMM [13] 24.3 13.8\n",
        "BERT [25] 72.0 76.6 70.1 KNRM [8] 26.9 14.9\n",
        "BERT+DCMN∗\n",
        "[38] 74.1 79.5 71.8 Conv [8] 28.7 18.1\n",
        "RoBERTa [21] 83.2 86.5 81.8 BERT†\n",
        "30.53 18.67\n",
        "XLNet 85.4 88.6 84.0 XLNet 31.10 20.28\n",
        "Table 2: Comparison with state-of-the-art results on the test set of RACE, a reading comprehension task, and on\n",
        "ClueWeb09-B, a document ranking task. ∗ indicates using ensembles. † indicates our implementations. “Middle”\n",
        "and “High” in RACE are two subsets representing middle and high school difficulty levels. All BERT, RoBERTa,\n",
        "and XLNet results are obtained with a 24-layer architecture with similar model sizes (aka BERT-Large).\n",
        "After the initial publication of our manuscript, a few other pretrained models were released such as\n",
        "RoBERTa [21] and ALBERT [19]. Since ALBERT involves increasing the model hidden size from\n",
        "1024 to 2048/4096 and thus substantially increases the amount of computation in terms of FLOPs, we\n",
        "exclude ALBERT from the following results as it is hard to lead to scientific conclusions. To obtain\n",
        "relatively fair comparison with RoBERTa, the experiment in this section is based on full data and\n",
        "reuses the hyper-parameters of RoBERTa, as described in section 3.1.\n",
        "The results are presented in Tables 2 (reading comprehension & document ranking), 3 (question\n",
        "answering), 4 (text classification) and 5 (natural language understanding), where XLNet generally\n",
        "outperforms BERT and RoBERTa. In addition, we make two more interesting observations:\n",
        "3Hyperparameters for pretraining and finetuning are in Appendix A.4.\n",
        "7\n",
        "SQuAD2.0 EM F1 SQuAD1.1 EM F1\n",
        "Dev set results (single model)\n",
        "BERT [10] 78.98 81.77 BERT† [10] 84.1 90.9\n",
        "RoBERTa [21] 86.5 89.4 RoBERTa [21] 88.9 94.6\n",
        "XLNet 87.9 90.6 XLNet 89.7 95.1\n",
        "Test set results on leaderboard (single model, as of Dec 14, 2019)\n",
        "BERT [10] 80.005 83.061 BERT [10] 85.083 91.835\n",
        "RoBERTa [21] 86.820 89.795 BERT∗\n",
        "[10] 87.433 93.294\n",
        "XLNet 87.926 90.689 XLNet 89.898‡ 95.080‡\n",
        "Table 3: Results on SQuAD, a reading comprehension dataset. † marks our runs with the official code. ∗\n",
        "indicates ensembles. ‡: We are not able to obtain the test results of our latest model on SQuAD1.1 from the\n",
        "organizers after submitting our result for more than one month, and thus report the results of an older version for\n",
        "the SQuAD1.1 test set.\n",
        "Model IMDB Yelp-2 Yelp-5 DBpedia AG Amazon-2 Amazon-5\n",
        "CNN [15] - 2.90 32.39 0.84 6.57 3.79 36.24\n",
        "DPCNN [15] - 2.64 30.58 0.88 6.87 3.32 34.81\n",
        "Mixed VAT [31, 23] 4.32 - - 0.70 4.95 - -\n",
        "ULMFiT [14] 4.6 2.16 29.98 0.80 5.01 - -\n",
        "BERT [35] 4.51 1.89 29.32 0.64 - 2.63 34.17\n",
        "XLNet 3.20 1.37 27.05 0.60 4.45 2.11 31.67\n",
        "Table 4: Comparison with state-of-the-art error rates on the test sets of several text classification datasets. All\n",
        "BERT and XLNet results are obtained with a 24-layer architecture with similar model sizes (aka BERT-Large).\n",
        "Model MNLI QNLI QQP RTE SST-2 MRPC CoLA STS-B WNLI\n",
        "Single-task single models on dev\n",
        "BERT [2] 86.6/- 92.3 91.3 70.4 93.2 88.0 60.6 90.0 -\n",
        "RoBERTa [21] 90.2/90.2 94.7 92.2 86.6 96.4 90.9 68.0 92.4 -\n",
        "XLNet 90.8/90.8 94.9 92.3 85.9 97.0 90.8 69.0 92.5 -\n",
        "Multi-task ensembles on test (from leaderboard as of Oct 28, 2019)\n",
        "MT-DNN∗\n",
        "[20] 87.9/87.4 96.0 89.9 86.3 96.5 92.7 68.4 91.1 89.0\n",
        "RoBERTa∗\n",
        "[21] 90.8/90.2 98.9 90.2 88.2 96.7 92.3 67.8 92.2 89.0\n",
        "XLNet∗\n",
        "90.9/90.9†\n",
        "99.0†\n",
        "90.4†\n",
        "88.5 97.1†\n",
        "92.9 70.2 93.0 92.5\n",
        "Table 5: Results on GLUE. ∗ indicates using ensembles, and † denotes single-task results in a multi-task row.\n",
        "All dev results are the median of 10 runs. The upper section shows direct comparison on dev data and the lower\n",
        "section shows comparison with state-of-the-art results on the public leaderboard.\n",
        "• For explicit reasoning tasks like SQuAD and RACE that involve longer context, the performance\n",
        "gain of XLNet is usually larger. This superiority at dealing with longer context could come from\n",
        "the Transformer-XL backbone in XLNet.\n",
        "• For classification tasks that already have abundant supervised examples such as MNLI (>390K),\n",
        "Yelp (>560K) and Amazon (>3M), XLNet still lead to substantial gains.\n",
        "3.4 Ablation Study\n",
        "We perform an ablation study to understand the importance of each design choice based on four\n",
        "datasets with diverse characteristics. Specifically, there are three main aspects we hope to study:\n",
        "• The effectiveness of the permutation language modeling objective alone, especially compared to\n",
        "the denoising auto-encoding objective used by BERT.\n",
        "• The importance of using Transformer-XL as the backbone neural architecture.\n",
        "• The necessity of some implementation details including span-based prediction, the bidirectional\n",
        "input pipeline, and next-sentence prediction.\n",
        "8\n",
        "With these purposes in mind, in Table 6, we compare 6 XLNet-Base variants with different implementation details (rows 3 - 8), the original BERT-Base model (row 1), and an additional Transformer-XL\n",
        "baseline trained with the denoising auto-encoding (DAE) objective used in BERT but with the bidirectional input pipeline (row 2). For fair comparison, all models are based on a 12-layer architecture\n",
        "with the same model hyper-parameters as BERT-Base and are trained on only Wikipedia and the\n",
        "BooksCorpus. All results reported are the median of 5 runs.\n",
        "# Model RACE SQuAD2.0 MNLI SST-2\n",
        "F1 EM m/mm\n",
        "1 BERT-Base 64.3 76.30 73.66 84.34/84.65 92.78\n",
        "2 DAE + Transformer-XL 65.03 79.56 76.80 84.88/84.45 92.60\n",
        "3 XLNet-Base (K = 7) 66.05 81.33 78.46 85.84/85.43 92.66\n",
        "4 XLNet-Base (K = 6) 66.66 80.98 78.18 85.63/85.12 93.35\n",
        "5 - memory 65.55 80.15 77.27 85.32/85.05 92.78\n",
        "6 - span-based pred 65.95 80.61 77.91 85.49/85.02 93.12\n",
        "7 - bidirectional data 66.34 80.65 77.87 85.31/84.99 92.66\n",
        "8 + next-sent pred 66.76 79.83 76.94 85.32/85.09 92.89\n",
        "Table 6: The results of BERT on RACE are taken from [38]. We run BERT on the other datasets using the\n",
        "official implementation and the same hyperparameter search space as XLNet. K is a hyperparameter to control\n",
        "the optimization difficulty (see Section 2.3).\n",
        "Examining rows 1 - 4 of Table 6, we can see both Transformer-XL and the permutation LM clearly\n",
        "contribute the superior performance of XLNet over BERT. Moreover, if we remove the memory\n",
        "caching mechanism (row 5), the performance clearly drops, especially for RACE which involves the\n",
        "longest context among the 4 tasks. In addition, rows 6 - 7 show that both span-based prediction and\n",
        "the bidirectional input pipeline play important roles in XLNet. Finally, we unexpectedly find the the\n",
        "next-sentence prediction objective proposed in the original BERT does not necessarily lead to an\n",
        "improvement in our setting. Hence, we exclude the next-sentence prediction objective from XLNet.\n",
        "Finally, we also perform a qualitative study of the attention patterns, which is included in Appendix\n",
        "A.6 due to page limit.\n",
        "4 Conclusions\n",
        "XLNet is a generalized AR pretraining method that uses a permutation language modeling objective\n",
        "to combine the advantages of AR and AE methods. The neural architecture of XLNet is developed to\n",
        "work seamlessly with the AR objective, including integrating Transformer-XL and the careful design\n",
        "of the two-stream attention mechanism. XLNet achieves substantial improvement over previous\n",
        "pretraining objectives on various tasks.\n",
        "Acknowledgments\n",
        "The authors would like to thank Qizhe Xie and Adams Wei Yu for providing useful feedback on the\n",
        "project, Jamie Callan for providing the ClueWeb dataset, Youlong Cheng, Yanping Huang and Shibo\n",
        "Wang for providing ideas to improve our TPU implementation, Chenyan Xiong and Zhuyun Dai\n",
        "for clarifying the setting of the document ranking task. ZY and RS were supported by the Office of\n",
        "Naval Research grant N000141812861, the National Science Foundation (NSF) grant IIS1763562,\n",
        "the Nvidia fellowship, and the Siebel scholarship. ZD and YY were supported in part by NSF under\n",
        "the grant IIS-1546329 and by the DOE-Office of Science under the grant ASCR #KJ040201.\n",
        "References\n",
        "[1] Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, and Llion Jones. Character-level\n",
        "language modeling with deeper self-attention. arXiv preprint arXiv:1808.04444, 2018.\n",
        "[2] Anonymous. Bam! born-again multi-task networks for natural language understanding. anonymous preprint under review, 2018.\n",
        "[3] Alexei Baevski and Michael Auli. Adaptive input representations for neural language modeling.\n",
        "arXiv preprint arXiv:1809.10853, 2018.\n",
        "9\n",
        "[4] Yoshua Bengio and Samy Bengio. Modeling high-dimensional discrete data with multi-layer\n",
        "neural networks. In Advances in Neural Information Processing Systems, pages 400–406, 2000.\n",
        "[5] Jamie Callan, Mark Hoy, Changkuk Yoo, and Le Zhao. Clueweb09 data set, 2009.\n",
        "[6] Common Crawl. Common crawl. URl: http://http://commoncrawl. org, 2019.\n",
        "[7] Andrew M Dai and Quoc V Le. Semi-supervised sequence learning. In Advances in neural\n",
        "information processing systems, pages 3079–3087, 2015.\n",
        "[8] Zhuyun Dai, Chenyan Xiong, Jamie Callan, and Zhiyuan Liu. Convolutional neural networks\n",
        "for soft-matching n-grams in ad-hoc search. In Proceedings of the eleventh ACM international\n",
        "conference on web search and data mining, pages 126–134. ACM, 2018.\n",
        "[9] Zihang Dai, Zhilin Yang, Yiming Yang, William W Cohen, Jaime Carbonell, Quoc V Le,\n",
        "and Ruslan Salakhutdinov. Transformer-xl: Attentive language models beyond a fixed-length\n",
        "context. arXiv preprint arXiv:1901.02860, 2019.\n",
        "[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of\n",
        "deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805,\n",
        "2018.\n",
        "[11] William Fedus, Ian Goodfellow, and Andrew M Dai. Maskgan: better text generation via filling\n",
        "in the_. arXiv preprint arXiv:1801.07736, 2018.\n",
        "[12] Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle. Made: Masked autoencoder\n",
        "for distribution estimation. In International Conference on Machine Learning, pages 881–889,\n",
        "2015.\n",
        "[13] Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Croft. A deep relevance matching model for\n",
        "ad-hoc retrieval. In Proceedings of the 25th ACM International on Conference on Information\n",
        "and Knowledge Management, pages 55–64. ACM, 2016.\n",
        "[14] Jeremy Howard and Sebastian Ruder. Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146, 2018.\n",
        "[15] Rie Johnson and Tong Zhang. Deep pyramid convolutional neural networks for text categorization. In Proceedings of the 55th Annual Meeting of the Association for Computational\n",
        "Linguistics (Volume 1: Long Papers), pages 562–570, 2017.\n",
        "[16] Vid Kocijan, Ana-Maria Cretu, Oana-Maria Camburu, Yordan Yordanov, and Thomas\n",
        "Lukasiewicz. A surprisingly robust trick for winograd schema challenge. arXiv preprint\n",
        "arXiv:1905.06290, 2019.\n",
        "[17] Taku Kudo and John Richardson. Sentencepiece: A simple and language independent subword\n",
        "tokenizer and detokenizer for neural text processing. arXiv preprint arXiv:1808.06226, 2018.\n",
        "[18] Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. Race: Large-scale\n",
        "reading comprehension dataset from examinations. arXiv preprint arXiv:1704.04683, 2017.\n",
        "[19] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu\n",
        "Soricut. Albert: A lite bert for self-supervised learning of language representations. arXiv\n",
        "preprint arXiv:1909.11942, 2019.\n",
        "[20] Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks\n",
        "for natural language understanding. arXiv preprint arXiv:1901.11504, 2019.\n",
        "[21] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike\n",
        "Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining\n",
        "approach. arXiv preprint arXiv:1907.11692, 2019.\n",
        "[22] Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation:\n",
        "Contextualized word vectors. In Advances in Neural Information Processing Systems, pages\n",
        "6294–6305, 2017.\n",
        "[23] Takeru Miyato, Andrew M Dai, and Ian Goodfellow. Adversarial training methods for semisupervised text classification. arXiv preprint arXiv:1605.07725, 2016.\n",
        "[24] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural\n",
        "networks. arXiv preprint arXiv:1601.06759, 2016.\n",
        "[25] Xiaoman Pan, Kai Sun, Dian Yu, Heng Ji, and Dong Yu. Improving question answering with\n",
        "external knowledge. arXiv preprint arXiv:1902.00993, 2019.\n",
        "10\n",
        "[26] Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. English gigaword\n",
        "fifth edition, linguistic data consortium. Technical report, Technical Report. Linguistic Data\n",
        "Consortium, Philadelphia, Tech. Rep., 2011.\n",
        "[27] Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint\n",
        "arXiv:1802.05365, 2018.\n",
        "[28] Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language\n",
        "understanding by generative pre-training. URL https://s3-us-west-2. amazonaws. com/openaiassets/research-covers/languageunsupervised/language understanding paper. pdf, 2018.\n",
        "[29] Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable\n",
        "questions for squad. arXiv preprint arXiv:1806.03822, 2018.\n",
        "[30] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions\n",
        "for machine comprehension of text. arXiv preprint arXiv:1606.05250, 2016.\n",
        "[31] Devendra Singh Sachan, Manzil Zaheer, and Ruslan Salakhutdinov. Revisiting lstm networks\n",
        "for semi-supervised text classification via mixed objective function. 2018.\n",
        "[32] Benigno Uria, Marc-Alexandre Côté, Karol Gregor, Iain Murray, and Hugo Larochelle. Neural\n",
        "autoregressive distribution estimation. The Journal of Machine Learning Research, 17(1):7184–\n",
        "7220, 2016.\n",
        "[33] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n",
        "Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information\n",
        "processing systems, pages 5998–6008, 2017.\n",
        "[34] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman.\n",
        "GLUE: A multi-task benchmark and analysis platform for natural language understanding. 2019.\n",
        "In the Proceedings of ICLR.\n",
        "[35] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V. Le. Unsupervised data\n",
        "augmentation. arXiv preprint arXiv:1904.12848, 2019.\n",
        "[36] Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural\n",
        "ad-hoc ranking with kernel pooling. In Proceedings of the 40th International ACM SIGIR\n",
        "conference on research and development in information retrieval, pages 55–64. ACM, 2017.\n",
        "[37] Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William W Cohen. Breaking the softmax\n",
        "bottleneck: A high-rank rnn language model. arXiv preprint arXiv:1711.03953, 2017.\n",
        "[38] Shuailiang Zhang, Hai Zhao, Yuwei Wu, Zhuosheng Zhang, Xi Zhou, and Xiang Zhou. Dual comatching network for multi-choice reading comprehension. arXiv preprint arXiv:1901.09381,\n",
        "2019.\n",
        "[39] Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text\n",
        "classification. In Advances in neural information processing systems, pages 649–657, 2015.\n",
        "[40] Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba,\n",
        "and Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by\n",
        "watching movies and reading books. In Proceedings of the IEEE international conference on\n",
        "computer vision, pages 19–27, 2015.\n",
        "11\n",
        "A Target-Aware Representation via Two-Stream Self-Attention\n",
        "A.1 A Concrete Example of How Standard LM Parameterization Fails\n",
        "In this section, we provide a concrete example to show how the standard language model parameterization fails under the permutation objective, as discussed in Section 2.3. Specifically, let’s consider\n",
        "two different permutations z\n",
        "(1) and z\n",
        "(2) satisfying the following relationship\n",
        "z\n",
        "(1)\n",
        "<t = z\n",
        "(2)\n",
        "<t = z<t but z\n",
        "(1)\n",
        "t = i 6= j = z\n",
        "(2)\n",
        "t\n",
        ".\n",
        "Then, substituting the two permutations respectively into the naive parameterization, we have\n",
        "pθ(Xi = x | xz<t )\n",
        "| {z }\n",
        "z\n",
        "(1)\n",
        "t =i, z\n",
        "(1)\n",
        "<t =z<t\n",
        "= pθ(Xj = x | xz<t )\n",
        "| {z }\n",
        "z\n",
        "(1)\n",
        "t =j, z\n",
        "(2)\n",
        "<t =z<t\n",
        "=\n",
        "exp\n",
        "e(x)\n",
        ">h(xz<t )\n",
        "\u0001\n",
        "P\n",
        "x0 exp (e(x\n",
        "0)>h(xz<t )).\n",
        "Effectively, two different target positions i and j share exactly the same model prediction. However,\n",
        "the ground-truth distribution of two positions should certainly be different.\n",
        "A.2 Two-Stream Attention\n",
        "Here, we provide the implementation details of the two-stream attention with a Transformer-XL\n",
        "backbone.\n",
        "Initial represetation:\n",
        "∀t = 1, . . . , T : ht = e(xt) and gt = w\n",
        "Cached layer-m content represetation (memory) from previous segment: h˜(m)\n",
        "For the Transformer-XL layer m = 1, · · · , M, attention with relative positional encoding and\n",
        "position-wise feed-forward are consecutively employed to update the represetntations:\n",
        "∀t = 1, . . . , T : hˆ(m)\n",
        "zt = LayerNorm\u0010\n",
        "h\n",
        "(m−1)\n",
        "zt + RelAttn\u0010\n",
        "h\n",
        "(m−1)\n",
        "zt\n",
        ",\n",
        "h\n",
        "h˜(m−1)\n",
        ", h\n",
        "(m−1)\n",
        "z≤t\n",
        "i\u0011\u0011\n",
        "h\n",
        "(m)\n",
        "zt = LayerNorm\u0010\n",
        "hˆ(m)\n",
        "zt + PosFF\u0010\n",
        "hˆ(m)\n",
        "zt\n",
        "\u0011\u0011\n",
        "gˆ\n",
        "(m)\n",
        "zt = LayerNorm\u0010\n",
        "g\n",
        "(m−1)\n",
        "zt + RelAttn\u0010\n",
        "g\n",
        "(m−1)\n",
        "zt\n",
        ",\n",
        "h\n",
        "h˜(m−1)\n",
        ", h\n",
        "(m−1)\n",
        "z<t i\u0011\u0011\n",
        "g\n",
        "(m)\n",
        "zt = LayerNorm\u0010\n",
        "gˆ\n",
        "(m)\n",
        "zt + PosFF\u0010\n",
        "gˆ\n",
        "(m)\n",
        "zt\n",
        "\u0011\u0011\n",
        "Target-aware prediction distribution:\n",
        "pθ(Xzt = x | xz<t ) =\n",
        "exp \u0010\n",
        "e(x)\n",
        ">g\n",
        "(M)\n",
        "zt\n",
        "\u0011\n",
        "P\n",
        "x0 exp \u0010\n",
        "e(x\n",
        "0)>g\n",
        "(M)\n",
        "zt\n",
        "\u0011,\n",
        "A.3 Datasets\n",
        "A.3.1 RACE Dataset\n",
        "The RACE dataset [18] contains near 100K questions taken from the English exams for middle and\n",
        "high school Chinese students in the age range between 12 to 18, with the answers generated by human\n",
        "experts. This is one of the most difficult reading comprehension datasets that involve challenging\n",
        "reasoning questions. Moreover, the average length of the passages in RACE are longer than 300,\n",
        "which is significantly longer than other popular reading comprehension datasets such as SQuAD [29].\n",
        "As a result, this dataset serves as a challenging benchmark for long text understanding. We use a\n",
        "sequence length of 512 during finetuning.\n",
        "A.3.2 SQuAD\n",
        "SQuAD is a large-scale reading comprehension dataset with two tasks. SQuAD1.1 [30] contains\n",
        "questions that always have a corresponding answer in the given passages, while SQuAD2.0 [29]\n",
        "introduces unanswerable questions. To finetune an XLNet on SQuAD2.0, we jointly apply a logistic regression loss for answerability prediction similar to classification tasks and a standard span\n",
        "extraction loss for question answering [10].\n",
        "1\n",
        "A.3.3 Text classification Datasets\n",
        "Following previous work on text classification [39, 23], we evaluate XLNet on the following benchmarks: IMDB, Yelp-2, Yelp-5, DBpedia, AG, Amazon-2, and Amazon-5.\n",
        "A.3.4 GLUE Dataset\n",
        "The GLUE dataset [34] is a collection of 9 natural language understanding tasks. The test set labels\n",
        "are removed from the publicly released version, and all the practitioners must submit their predictions\n",
        "on the evaluation server to obtain test set results. In Table 5, we present results of multiple settings,\n",
        "including single-task and multi-task, as well as single models and ensembles. In the multi-task setting,\n",
        "we jointly train an XLNet on the four largest datasets—MNLI, SST-2, QNLI, and QQP—and finetune\n",
        "the network on the other datasets. Only single-task training is employed for the four large datasets.\n",
        "For QNLI, we employed a pairwise relevance ranking scheme as in [20] for our test set submission.\n",
        "However, for fair comparison with BERT, our result on the QNLI dev set is based on a standard\n",
        "classification paradigm. For WNLI, we use the loss described in [16].\n",
        "A.3.5 ClueWeb09-B Dataset\n",
        "Following the setting in previous work [8], we use the ClueWeb09-B dataset to evaluate the performance on document ranking. The queries were created by the TREC 2009-2012 Web Tracks based on\n",
        "50M documents and the task is to rerank the top 100 documents retrieved using a standard retrieval\n",
        "method. Since document ranking, or ad-hoc retrieval, mainly concerns the low-level representations\n",
        "instead of high-level semantics, this dataset serves as a testbed for evaluating the quality of word\n",
        "embeddings. We use a pretrained XLNet to extract word embeddings for the documents and queries\n",
        "without finetuning, and employ a kernel pooling network [36] to rank the documents.\n",
        "A.4 Hyperparameters\n",
        "A.4.1 Pretraining Hyperparameters\n",
        "Hparam Value\n",
        "Number of layers 24\n",
        "Hidden size 1024\n",
        "Number of attention heads 16\n",
        "Attention head size 64\n",
        "FFN inner hidden size 4096\n",
        "Hidden Dropout 0.1\n",
        "GeLU Dropout 0.0\n",
        "Attention dropout 0.1\n",
        "Partial prediction K 6\n",
        "Max sequence length 512\n",
        "Batch size 8192\n",
        "Learning rate 4e-4\n",
        "Number of steps 500K\n",
        "Warmup steps 40,000\n",
        "Learning rate decay linear\n",
        "Adam epsilon 1e-6\n",
        "Weight decay 0.01\n",
        "Table 7: Hyperparameters for pretraining.\n",
        "The hyperparameters used for pretraining XLNet are shown in Table 7.\n",
        "A.4.2 Hyperparameters for Finetuning\n",
        "The hyperparameters used for finetuning XLNet on various tasks are shown in Table 8. “Layer-wise\n",
        "decay” means exponentially decaying the learning rates of individual layers in a top-down manner.\n",
        "For example, suppose the 24-th layer uses a learning rate l, and the Layer-wise decay rate is α, then\n",
        "the learning rate of layer m is lα24−m.\n",
        "13\n",
        "Hparam RACE SQuAD MNLI Yelp-5\n",
        "Dropout 0.1\n",
        "Attention dropout 0.1\n",
        "Max sequence length 512 512 128 512\n",
        "Batch size 32 48 128 128\n",
        "Learning rate 2e-5 3e-5 2e-5 1e-5\n",
        "Number of steps 12K 8K 10K 10K\n",
        "Learning rate decay linear\n",
        "Weight decay 0.01\n",
        "Adam epsilon 1e-6 1e-6 1e-6 1e-6\n",
        "Layer-wise lr decay 1.0 0.75 1.0 1.0\n",
        "Table 8: Hyperparameters for finetuning.\n",
        "A.5 Discussion and Analysis\n",
        "A.5.1 Comparison with BERT\n",
        "To prove a general point beyond one example, we now turn to more formal expressions. Inspired\n",
        "by previous work [37], given a sequence x = [x1, · · · , xT ], we define a set of target-context pairs\n",
        "of interest, I = {(x, U)}, where U is a set of tokens in x that form a context of x. Intuitively, we\n",
        "want the model to learn the dependency of x on U through a pretraining loss term log p(x | U). For\n",
        "example, given the above sentence, the pairs of interest I could be instantiated as:\n",
        "I =\n",
        "n\n",
        "x = York, U = {New}\n",
        "\u0001\n",
        ",\n",
        "\n",
        "x = York, U = {city}\n",
        "\u0001\n",
        ",\n",
        "\n",
        "x = York, U = {New, city}\n",
        "\u0001\n",
        ", · · · o\n",
        ".\n",
        "Note that I is merely a virtual notion without unique ground truth, and our analysis will hold\n",
        "regardless of how I is instantiated.\n",
        "Given a set of target tokens T and a set of non-target tokens N = x\\T , BERT and XLNet both\n",
        "maximize log p(T | N ) but with different formulations:\n",
        "JBERT =\n",
        "X\n",
        "x∈T\n",
        "log p(x | N ); JXLNet =\n",
        "X\n",
        "x∈T\n",
        "log p(x | N ∪ T<x)\n",
        "where T<x denote tokens in T that have a factorization order prior to x. Both objectives consist\n",
        "of multiple loss terms in the form of log p(x | Vx). Intuitively, if there exists a target-context pair\n",
        "(x, U) ∈ I such that U ⊆ Vx, then the loss term log p(x | Vx) provides a training signal to the\n",
        "dependency between x and U. For convenience, we say a target-context pair (x, U) ∈ I is covered\n",
        "by a model (objective) if U ⊆ Vx.\n",
        "Given the definition, let’s consider two cases:\n",
        "• If U ⊆ N , the dependency (x, U) is covered by both BERT and XLNet.\n",
        "• If U ⊆ N ∪ T<x and U ∩ T<x 6= ∅, the dependency can only be covered by XLNet but not BERT.\n",
        "As a result, XLNet is able to cover more dependencies than BERT. In other words, the XLNet\n",
        "objective contains more effective training signals, which empirically leads to better performance in\n",
        "Section 3.\n",
        "A.5.2 Comparison with Language Modeling\n",
        "Borrowing examples and notations from Section A.5.1, a standard AR language model like GPT\n",
        "[28] is only able to cover the dependency (x = York, U = {New}) but not (x = New, U = {York}).\n",
        "XLNet, on the other hand, is able to cover both in expectation over all factorization orders. Such a\n",
        "limitation of AR language modeling can be critical in real-world applications. For example, consider\n",
        "a span extraction question answering task with the context “Thom Yorke is the singer of Radiohead”\n",
        "and the question “Who is the singer of Radiohead”. The representations of “Thom Yorke” are not\n",
        "dependent on “Radiohead” with AR language modeling and thus they will not be chosen as the\n",
        "answer by the standard approach that employs softmax over all token representations. More formally,\n",
        "consider a context-target pair (x, U):\n",
        "• If U 6⊆ T<x, where T<x denotes the tokens prior to x in the original sequence, AR language\n",
        "modeling is not able to cover the dependency.\n",
        "\n",
        "• In comparison, XLNet is able to cover all dependencies in expectation.\n",
        "Approaches like ELMo [27] concatenate forward and backward language models in a shallow manner,\n",
        "which is not sufficient for modeling deep interactions between the two directions.\n",
        "A.5.3 Bridging the Gap Between Language Modeling and Pretraining\n",
        "With a deep root in density estimation4\n",
        "[4, 32, 24], language modeling has been a rapidly-developing\n",
        "research area [9, 1, 3]. However, there has been a gap between language modeling and pretraining\n",
        "due to the lack of the capability of bidirectional context modeling, as analyzed in Section A.5.2. It\n",
        "has even been challenged by some machine learning practitioners whether language modeling is a\n",
        "meaningful pursuit if it does not directly improve downstream tasks 5\n",
        ". XLNet generalizes language\n",
        "modeling and bridges such a gap. As a result, it further “justifies” language modeling research.\n",
        "Moreover, it becomes possible to leverage the rapid progress of language modeling research for\n",
        "pretraining. As an example, we integrate Transformer-XL into XLNet to demonstrate the usefulness\n",
        "of the latest language modeling progress.\n",
        "A.6 Qualitative Analysis of Attention Patterns\n",
        "We compare the attention pattern of BERT and XLNet without finetuning. Firstly, we found 4 typical\n",
        "patterns shared by both, as shown in Fig. 2.\n",
        "(a) Content stripes (b) Local/Self focus (c) Two segments\n",
        "(d) Content-based symmetry\n",
        "Figure 2: Attention patterns shared by XLNet and BERT. Rows and columns represent query and key\n",
        "respectively.\n",
        "More interestingly, in Fig. 3, we present 3 patterns that only appear in XLNet but not BERT: (a) The\n",
        "self-exclusion pattern attends to all other tokens but itself, probably offering a fast way to gather\n",
        "global information; (b) The relative-stride pattern attends to positions every a few stride apart relative\n",
        "to the query position; (c) The one-side masked pattern is very similar to the lower-left part of Fig.\n",
        "1-(d), with the upper-right triangle masked out. It seems that the model learns not to attend the\n",
        "relative right half. Note that all these three unique patterns involve the relative positions rather than\n",
        "absolute ones, and hence are likely enabled by the “relative attention” mechanism in XLNet. We\n",
        "conjecture these unique patterns contribute to the performance advantage of XLNet. On the other\n",
        "hand, the proposed permutation LM objective mostly contributes to a better data efficiency, whose\n",
        "effects may not be obvious from qualitative visualization.\n",
        "(a) Self exclusion (b) Relative stride (c) One-side masked\n",
        "Figure 3: Attention patterns that appear only in XLNet. Rows and columns represent query and key respectively.\n",
        "15\n",
        "x\" x# x$ x%\n",
        "h\"\n",
        "(#) h#\n",
        "(#) h$\n",
        "(#)\n",
        "h\"\n",
        "($) h#\n",
        "($) h$\n",
        "($)\n",
        "Factorization order: 3 à 2 à 4 à 1\n",
        "x\" x# x$ x%\n",
        "h#\n",
        "(#)\n",
        "h\"\n",
        "($) h#\n",
        "($) h$\n",
        "($) h%\n",
        "($)\n",
        "Factorization order: 1 à 4 à 2 à 3\n",
        "h\"\n",
        "(#) h$\n",
        "(#) h%\n",
        "(#)\n",
        "h%\n",
        "(#)\n",
        "h%\n",
        "($)\n",
        "mem(+)\n",
        "mem(+)\n",
        "x\" x# x$ x%\n",
        "h\"\n",
        "(#) h#\n",
        "(#)\n",
        "h\"\n",
        "($) h#\n",
        "($) h%\n",
        "($)\n",
        "Factorization order: 2 à 4 à 3 à 1\n",
        "h$\n",
        "(#) h%\n",
        "(#)\n",
        "h$\n",
        "($)\n",
        "x\" x# x$ x%\n",
        "h\"\n",
        "(#) h#\n",
        "(#) h$\n",
        "(#) h%\n",
        "(#)\n",
        "h\"\n",
        "($) h#\n",
        "($) h$\n",
        "($) h%\n",
        "($)\n",
        "Factorization order: 4 à 3 à 1 à 2\n",
        "mem(+)\n",
        "mem(+)\n",
        "mem(#) mem(#)\n",
        "mem(#) mem(+)\n",
        "x% x%\n",
        "x% x%\n",
        "Figure 4: Illustration of the permutation language modeling objective for predicting x3 given the\n",
        "same input sequence x but with different factorization orders.\n",
        "A.7 Visualizing Memory and Permutation\n",
        "In this section, we provide a detailed visualization of the proposed permutation language modeling\n",
        "objective, including the mechanism of reusing memory (aka the recurrence mechanism), how we use\n",
        "attention masks to permute the factorization order, and the difference of the two attention streams.\n",
        "As shown in Figure 5 and 6, given the current position zt, the attention mask is decided by the\n",
        "permutation (or factorization order) z such that only tokens the occur before zt in the permutation can\n",
        "be attended; i.e., positions zi with i < t. Moreover, comparing Figure 5 and 6, we can see how the\n",
        "query stream and the content stream work differently with a specific permutation through attention\n",
        "masks. The main difference is that the query stream cannot do self-attention and does not have access\n",
        "to the token at the position, while the content stream performs normal self-attention.\n",
        "4The problem of language modeling is essentially density estimation for text data.\n",
        "5\n",
        "https://openreview.net/forum?id=HJePno0cYm\n",
        "16\n",
        "Position-3 View Position-2 View\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "w w w w\n",
        "g#\n",
        "(%) h%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "Position-4 View\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "Position-1 View\n",
        "Split View of the Content Stream\n",
        "(Factorization order: 3 à 2 à 4 à 1)\n",
        "Joint View of the Content Stream\n",
        "(Factorization order: 3 à 2 à 4 à 1)\n",
        "mem(+) x% w x' w x( w x# w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%) g(\n",
        "(%) mem(%) h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(') g(\n",
        "(') h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "Split View\n",
        "Figure 5: A detailed illustration of the content stream of the proposed objective with both the joint\n",
        "view and split views based on a length-4 sequence under the factorization order [3, 2, 4, 1].\n",
        "Note that if we ignore the query representation, the computation in this figure is simply the standard\n",
        "self-attention, though with a particular attention mask.\n",
        "17\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "w w w w\n",
        "g#\n",
        "(%) h%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "w w w w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(')\n",
        "g(\n",
        "(%)\n",
        "g(\n",
        "(')\n",
        "mem(+)\n",
        "mem(%)\n",
        "x% x' x( x#\n",
        "h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "Position-3 View Position-2 View\n",
        "Position-4 View Position-1 View\n",
        "Split View of the Query Stream\n",
        "(Factorization order: 3 à 2 à 4 à 1)\n",
        "Split View\n",
        "mem(+) x% w x' w x( w x# w\n",
        "g#\n",
        "(%) g%\n",
        "(%) g'\n",
        "(%) g( mem(%) (%) h#\n",
        "(%) h%\n",
        "(%) h'\n",
        "(%) h(\n",
        "(%)\n",
        "g#\n",
        "(') g%\n",
        "(') g'\n",
        "(') g(\n",
        "(') h#\n",
        "(') h%\n",
        "(') h'\n",
        "(') h(\n",
        "(')\n",
        "Joint View of the Query Stream\n",
        "(Factorization order: 3 à 2 à 4 à 1)\n",
        "Figure 6: A detailed illustration of the query stream of the proposed objective with both the joint\n",
        "view and split views based on a length-4 sequence under the factorization order [3, 2, 4, 1].\n",
        "The dash arrows indicate that the query stream cannot access the token (content) at the same position,\n",
        "but only the location information.\n",
        "18\"\"\""
      ],
      "metadata": {
        "id": "bCGZCZJXU-gH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "rt2ZyrA3Vsio"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "097TVlbMWNxO",
        "outputId": "ce773c44-2e12-4db0-f798-10e8232bb365"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "tQNZK3MRWWCb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8ykACNGWh3q",
        "outputId": "9eba0a6a-5571-4268-e90a-0e11a5518b83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corpus = []\n",
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a-zA-Z]',\" \",sentences[i])\n",
        "  review = review.lower()\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "F8b-wEKIXE6m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687a-ZvXXQ5N",
        "outputId": "d1e38413-df2c-48a9-a9a0-d4c09a858765"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xlnet  generalized autoregressive pretraining for language understanding zhilin yang     zihang dai     yiming yang    jaime carbonell    ruslan salakhutdinov    quoc v  le   carnegie mellon university   google ai brain team  zhiliny dzihang yiming jgc rsalakhu  cs cmu edu  qvl google com abstract with the capability of modeling bidirectional contexts  denoising autoencoding based pretraining like bert achieves better performance than pretraining approaches based on autoregressive language modeling ',\n",
              " 'however  relying on corrupting the input with masks  bert neglects dependency between the masked positions and suffers from a pretrain finetune discrepancy ',\n",
              " 'in light of these pros and cons  we propose xlnet  a generalized autoregressive pretraining method that     enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and     overcomes the limitations of bert thanks to its autoregressive formulation ',\n",
              " 'furthermore  xlnet integrates ideas from transformer xl  the state of the art autoregressive model  into pretraining ',\n",
              " 'empirically  under comparable experiment settings  xlnet outperforms bert on    tasks  often by a large margin  including question answering  natural language inference  sentiment analysis  and document ranking    ',\n",
              " '  introduction unsupervised representation learning has been highly successful in the domain of natural language processing                     ',\n",
              " 'typically  these methods first pretrain neural networks on large scale unlabeled text corpora  and then finetune the models or representations on downstream tasks ',\n",
              " 'under this shared high level idea  different unsupervised pretraining objectives have been explored in literature ',\n",
              " 'among them  autoregressive  ar  language modeling and autoencoding  ae  have been the two most successful pretraining objectives ',\n",
              " 'ar language modeling seeks to estimate the probability distribution of a text corpus with an autoregressive model             ',\n",
              " 'specifically  given a text sequence x    x           xt    ar language modeling factorizes the likelihood into a forward product p x    qt t   p xt   x t  or a backward one p x    q  t t p xt   x t  ',\n",
              " 'a parametric model  e g ',\n",
              " 'a neural network  is trained to model each conditional distribution ',\n",
              " 'since an ar language model is only trained to encode a uni directional context  either forward or backward   it is not effective at modeling deep bidirectional contexts ',\n",
              " 'on the contrary  downstream language understanding tasks often require bidirectional context information ',\n",
              " 'this results in a gap between ar language modeling and effective pretraining ',\n",
              " 'in comparison  ae based pretraining does not perform explicit density estimation but instead aims to reconstruct the original data from corrupted input ',\n",
              " 'a notable example is bert       which has been the state of the art pretraining approach ',\n",
              " 'given the input token sequence  a certain portion of tokens are replaced by a special symbol  mask   and the model is trained to recover the original tokens from the corrupted version ',\n",
              " 'since density estimation is not part of the objective  bert is allowed to utilize  equal contribution ',\n",
              " 'order determined by swapping the one in     ',\n",
              " '  pretrained models and code are available at https   github com zihangdai xlnet   rd conference on neural information processing systems  neurips        vancouver  canada ',\n",
              " 'arxiv           v   cs cl    jan      bidirectional contexts for reconstruction ',\n",
              " 'as an immediate benefit  this closes the aforementioned bidirectional information gap in ar language modeling  leading to improved performance ',\n",
              " 'however  the artificial symbols like  mask  used by bert during pretraining are absent from real data at finetuning time  resulting in a pretrain finetune discrepancy ',\n",
              " 'moreover  since the predicted tokens are masked in the input  bert is not able to model the joint probability using the product rule as in ar language modeling ',\n",
              " 'in other words  bert assumes the predicted tokens are independent of each other given the unmasked tokens  which is oversimplified as high order  long range dependency is prevalent in natural language     ',\n",
              " 'faced with the pros and cons of existing language pretraining objectives  in this work  we propose xlnet  a generalized autoregressive method that leverages the best of both ar language modeling and ae while avoiding their limitations ',\n",
              " '  firstly  instead of using a fixed forward or backward factorization order as in conventional ar models  xlnet maximizes the expected log likelihood of a sequence w r t ',\n",
              " 'all possible permutations of the factorization order ',\n",
              " 'thanks to the permutation operation  the context for each position can consist of tokens from both left and right ',\n",
              " 'in expectation  each position learns to utilize contextual information from all positions  i e   capturing bidirectional context ',\n",
              " '  secondly  as a generalized ar language model  xlnet does not rely on data corruption ',\n",
              " 'hence  xlnet does not suffer from the pretrain finetune discrepancy that bert is subject to ',\n",
              " 'meanwhile  the autoregressive objective also provides a natural way to use the product rule for factorizing the joint probability of the predicted tokens  eliminating the independence assumption made in bert ',\n",
              " 'in addition to a novel pretraining objective  xlnet improves architectural designs for pretraining ',\n",
              " '  inspired by the latest advancements in ar language modeling  xlnet integrates the segment recurrence mechanism and relative encoding scheme of transformer xl     into pretraining  which empirically improves the performance especially for tasks involving a longer text sequence ',\n",
              " '  naively applying a transformer  xl  architecture to permutation based language modeling does not work because the factorization order is arbitrary and the target is ambiguous ',\n",
              " 'as a solution  we propose to reparameterize the transformer  xl  network to remove the ambiguity ',\n",
              " 'empirically  under comparable experiment setting  xlnet consistently outperforms bert      on a wide spectrum of problems including glue language understanding tasks  reading comprehension tasks like squad and race  text classification tasks such as yelp and imdb  and the clueweb   b document ranking task ',\n",
              " 'related work the idea of permutation based ar modeling has been explored in           but there are several key differences ',\n",
              " 'firstly  previous models aim to improve density estimation by baking an  orderless  inductive bias into the model while xlnet is motivated by enabling ar language models to learn bidirectional contexts ',\n",
              " 'technically  to construct a valid target aware prediction distribution  xlnet incorporates the target position into the hidden state via two stream attention while previous permutation based ar models relied on implicit position awareness inherent to their mlp architectures ',\n",
              " 'finally  for both orderless nade and xlnet  we would like to emphasize that  orderless  does not mean that the input sequence can be randomly permuted but that the model allows for different factorization orders of the distribution ',\n",
              " 'another related idea is to perform autoregressive denoising in the context of text generation       which only considers a fixed order though ',\n",
              " '  proposed method     background in this section  we first review and compare the conventional ar language modeling and bert for language pretraining ',\n",
              " 'given a text sequence x    x           xt    ar language modeling performs pretraining by maximizing the likelihood under the forward autoregressive factorization  max   log p  x    x t t   log p  xt   x t    x t t   log exp h  x  t     e xt    p x  exp  h  x  t    e x           where h  x  t    is a context representation produced by neural models  such as rnns or transformers  and e x  denotes the embedding of x ',\n",
              " 'in comparison  bert is based on denoising auto encoding ',\n",
              " 'specifically  for a text sequence x  bert first constructs a corrupted version x  by randomly setting a portion  e g ',\n",
              " '     of tokens in x to a special symbol  mask  ',\n",
              " 'let the masked tokens be x  ',\n",
              " 'the training objective is to reconstruct x  from x   max   log p  x    x     x t t   mt log p  xt   x     x t t   mt log exp h  x     t e xt    p x  exp h  x     t e x            where mt     indicates xt is masked  and h  is a transformer that maps a length t text sequence x into a sequence of hidden vectors h  x     h  x    h  x            h  x t   ',\n",
              " 'the pros and cons of the two pretraining objectives are compared in the following aspects    independence assumption  as emphasized by the   sign in eq ',\n",
              " '     bert factorizes the joint conditional probability p x    x   based on an independence assumption that all masked tokens x  are separately reconstructed ',\n",
              " 'in comparison  the ar language modeling objective     factorizes p  x  using the product rule that holds universally without such an independence assumption ',\n",
              " '  input noise  the input to bert contains artificial symbols like  mask  that never occur in downstream tasks  which creates a pretrain finetune discrepancy ',\n",
              " 'replacing  mask  with original tokens as in      does not solve the problem because original tokens can be only used with a small probability   otherwise eq ',\n",
              " '    will be trivial to optimize ',\n",
              " 'in comparison  ar language modeling does not rely on any input corruption and does not suffer from this issue ',\n",
              " '  context dependency  the ar representation h  x  t    is only conditioned on the tokens up to position t  i e ',\n",
              " 'tokens to the left   while the bert representation h  x t has access to the contextual information on both sides ',\n",
              " 'as a result  the bert objective allows the model to be pretrained to better capture bidirectional context ',\n",
              " '    objective  permutation language modeling according to the comparison above  ar language modeling and bert possess their unique advantages over the other ',\n",
              " 'a natural question to ask is whether there exists a pretraining objective that brings the advantages of both while avoiding their weaknesses ',\n",
              " 'borrowing ideas from orderless nade       we propose the permutation language modeling objective that not only retains the benefits of ar models but also allows models to capture bidirectional contexts ',\n",
              " 'specifically  for a sequence x of length t  there are t ',\n",
              " 'different orders to perform a valid autoregressive factorization ',\n",
              " 'intuitively  if model parameters are shared across all factorization orders  in expectation  the model will learn to gather information from all positions on both sides ',\n",
              " 'to formalize the idea  let zt be the set of all possible permutations of the length t index sequence         ',\n",
              " ' ',\n",
              " ' ',\n",
              " '  t  ',\n",
              " 'we use zt and z t to denote the t th element and the first t   elements of a permutation z   zt  ',\n",
              " 'then  our proposed permutation language modeling objective can be expressed as follows  max   ez zt  x t t   log p  xzt   xz t      ',\n",
              " '    essentially  for a text sequence x  we sample a factorization order z at a time and decompose the likelihood p  x  according to factorization order ',\n",
              " 'since the same model parameter   is shared across all factorization orders during training  in expectation  xt has seen every possible element xi    xt in the sequence  hence being able to capture the bidirectional context ',\n",
              " 'moreover  as this objective fits into the ar framework  it naturally avoids the independence assumption and the pretrain finetune discrepancy discussed in section     ',\n",
              " 'remark on permutation the proposed objective only permutes the factorization order  not the sequence order ',\n",
              " 'in other words  we keep the original sequence order  use the positional encodings corresponding to the original sequence  and rely on a proper attention mask in transformers to achieve permutation of the factorization order ',\n",
              " 'note that this choice is necessary  since the model will only encounter text sequences with the natural order during finetuning ',\n",
              " 'to provide an overall picture  we show an example of predicting the token x  given the same input sequence x but under different factorization orders in the appendix a   with figure   ',\n",
              " '    architecture  two stream self attention for target aware representations sample a factorization order                attention masks e x   w e x   w e x   w e x   w h      g      h      g      h      g      h      g      h      g      h      g      h      g      h      g      content stream  can see self query stream  cannot see self x  x  x  x  masked two stream attention masked two stream attention  c  h      g      h      g      h      g      h      g      h      g      attention q k  v h      g      attention q k  v  b   a  h      g      h      g      h      g      h      g      figure     a   content stream attention  which is the same as the standard self attention ',\n",
              " ' b   query stream attention  which does not have access information about the content xzt  ',\n",
              " ' c   overview of the permutation language modeling training with two stream attention ',\n",
              " 'while the permutation language modeling objective has desired properties  naive implementation with standard transformer parameterization may not work ',\n",
              " 'to see the problem  assume we parameterize the next token distribution p  xzt   xz t   using the standard softmax formulation  i e   p  xzt   x   xz t     exp e x   h  xz t    p x  exp e x   h  xz t      where h  xz t   denotes the hidden representation of xz t produced by the shared transformer network after proper masking ',\n",
              " 'now notice that the representation h  xz t   does not depend on which position it will predict  i e   the value of zt ',\n",
              " 'consequently  the same distribution is predicted regardless of the target position  which is not able to learn useful representations  see appendix a   for a concrete example  ',\n",
              " 'to avoid this problem  we propose to re parameterize the next token distribution to be target position aware  p  xzt   x   xz t     exp e x   g  xz t   zt    p x  exp  e x    g  xz t   zt        where g  xz t   zt  denotes a new type of representations which additionally take the target position zt as input ',\n",
              " 'two stream self attention while the idea of target aware representations removes the ambiguity in target prediction  how to formulate g  xz t   zt  remains a non trivial problem ',\n",
              " 'among other possibilities  we propose to  stand  at the target position zt and rely on the position zt to gather information from the context xz t through attention ',\n",
              " 'for this parameterization to work  there are two requirements that are contradictory in a standard transformer architecture      to predict the token xzt   g  xz t   zt  should only use the position zt and not the content xzt   otherwise the objective becomes trivial      to predict the other tokens xzj with j   t  g  xz t   zt  should also encode the content xzt to provide full contextual information ',\n",
              " 'to resolve such a contradiction  we propose to use two sets of hidden representations instead of one    the content representation h  xz t    or abbreviated as hzt   which serves a similar role to the standard hidden states in transformer ',\n",
              " 'this representation encodes both the context and xzt itself ',\n",
              " '  the query representation g  xz t   zt   or abbreviated as gzt   which only has access to the contextual information xz t and the position zt  but not the content xzt   as discussed above ',\n",
              " 'computationally  the first layer query stream is initialized with a trainable vector  i e ',\n",
              " 'g     i   w  while the content stream is set to the corresponding word embedding  i e ',\n",
              " 'h     i   e xi  ',\n",
              " 'for each self attention layer m       ',\n",
              " ' ',\n",
              " ' ',\n",
              " '  m  the two streams of representations are schematically  updated  to avoid clutter  we omit the implementation details including multi head attention  residual connection  layer normalization and position wise feed forward as used in transformer  xl  ',\n",
              " 'the details are included in appendix a   for reference ',\n",
              " 'with a shared set of parameters as follows  illustrated in figures    a  and  b    g  m  zt   attention q   g  m    zt   kv   h  m    z t        query stream  use zt but cannot see xzt   h  m  zt   attention q   h  m    zt   kv   h  m    z t        content stream  use both zt and xzt   ',\n",
              " 'where q  k  v denote the query  key  and value in an attention operation      ',\n",
              " 'the update rule of the content representations is exactly the same as the standard self attention  so during finetuning  we can simply drop the query stream and use the content stream as a normal transformer  xl  ',\n",
              " 'finally  we can use the last layer query representation g  m  zt to compute eq ',\n",
              " '    ',\n",
              " 'partial prediction while the permutation language modeling objective     has several benefits  it is a much more challenging optimization problem due to the permutation and causes slow convergence in preliminary experiments ',\n",
              " 'to reduce the optimization difficulty  we choose to only predict the last tokens in a factorization order ',\n",
              " 'formally  we split z into a non target subsequence z c and a target subsequence z c  where c is the cutting point ',\n",
              " 'the objective is to maximize the log likelihood of the target subsequence conditioned on the non target subsequence  i e   max   ez zt h log p  xz c   xz c   i   ez zt     x  z  t c   log p  xzt   xz t       ',\n",
              " '    note that z c is chosen as the target because it possesses the longest context in the sequence given the current factorization order z ',\n",
              " 'a hyperparameter k is used such that about   k tokens are selected for predictions  i e    z     z    c    k  for unselected tokens  their query representations need not be computed  which saves speed and memory ',\n",
              " '    incorporating ideas from transformer xl since our objective function fits in the ar framework  we incorporate the state of the art ar language model  transformer xl      into our pretraining framework  and name our method after it ',\n",
              " 'we integrate two important techniques in transformer xl  namely the relative positional encoding scheme and the segment recurrence mechanism ',\n",
              " 'we apply relative positional encodings based on the original sequence as discussed earlier  which is straightforward ',\n",
              " 'now we discuss how to integrate the recurrence mechanism into the proposed permutation setting and enable the model to reuse hidden states from previous segments ',\n",
              " 'without loss of generality  suppose we have two segments taken from a long sequence s  i e   x    s  t and x   st     t  ',\n",
              " 'let z  and z be permutations of          t  and  t            t  respectively ',\n",
              " 'then  based on the permutation z   we process the first segment  and then cache the obtained content representations h  m  for each layer m  then  for the next segment x  the attention update with memory can be written as h  m  zt   attention q   h  m    zt   kv   h h  m      h  m    z t i      where       ',\n",
              " 'denotes concatenation along the sequence dimension ',\n",
              " 'notice that positional encodings only depend on the actual positions in the original sequence ',\n",
              " 'thus  the above attention update is independent of z  once the representations h  m  are obtained ',\n",
              " 'this allows caching and reusing the memory without knowing the factorization order of the previous segment ',\n",
              " 'in expectation  the model learns to utilize the memory over all factorization orders of the last segment ',\n",
              " 'the query stream can be computed in the same way ',\n",
              " 'finally  figure    c  presents an overview of the proposed permutation language modeling with two stream attention  see appendix a   for more detailed illustration  ',\n",
              " '    modeling multiple segments many downstream tasks have multiple input segments  e g   a question and a context paragraph in question answering ',\n",
              " 'we now discuss how we pretrain xlnet to model multiple segments in the autoregressive framework ',\n",
              " 'during the pretraining phase  following bert  we randomly sample two segments  either from the same context or not  and treat the concatenation of two segments as one sequence to perform permutation language modeling ',\n",
              " 'we only reuse the memory that belongs to the same context ',\n",
              " 'specifically  the input to our model is the same as bert   cls  a  sep  b  sep   where  sep  and  cls  are two special symbols and  a  and  b  are the two segments ',\n",
              " 'although   we follow the two segment data format  xlnet large does not use the objective of next sentence prediction      as it does not show consistent improvement in our ablation study  see section      ',\n",
              " 'relative segment encodings architecturally  different from bert that adds an absolute segment embedding to the word embedding at each position  we extend the idea of relative encodings from transformer xl to also encode the segments ',\n",
              " 'given a pair of positions i and j in the sequence  if i and j are from the same segment  we use a segment encoding sij   s  or otherwise sij   s   where s  and s  are learnable model parameters for each attention head ',\n",
              " 'in other words  we only consider whether the two positions are within the same segment  as opposed to considering which specific segments they are from ',\n",
              " 'this is consistent with the core idea of relative encodings  i e   only modeling the relationships between positions ',\n",
              " 'when i attends to j  the segment encoding sij is used to compute an attention weight aij    qi   b   sij   where qi is the query vector as in a standard attention operation and b is a learnable head specific bias vector ',\n",
              " 'finally  the value aij is added to the normal attention weight ',\n",
              " 'there are two benefits of using relative segment encodings ',\n",
              " 'first  the inductive bias of relative encodings improves generalization     ',\n",
              " 'second  it opens the possibility of finetuning on tasks that have more than two input segments  which is not possible using absolute segment encodings ',\n",
              " '    discussion comparing eq ',\n",
              " '    and      we observe that both bert and xlnet perform partial prediction  i e   only predicting a subset of tokens in the sequence ',\n",
              " 'this is a necessary choice for bert because if all tokens are masked  it is impossible to make any meaningful predictions ',\n",
              " 'in addition  for both bert and xlnet  partial prediction plays a role of reducing optimization difficulty by only predicting tokens with sufficient context ',\n",
              " 'however  the independence assumption discussed in section     disables bert to model dependency between targets ',\n",
              " 'to better understand the difference  let s consider a concrete example  new  york  is  a  city  ',\n",
              " 'suppose both bert and xlnet select the two tokens  new  york  as the prediction targets and maximize log p new york   is a city  ',\n",
              " 'also suppose that xlnet samples the factorization order  is  a  city  new  york  ',\n",
              " 'in this case  bert and xlnet respectively reduce to the following objectives  jbert   log p new   is a city    log p york   is a city   jxlnet   log p new   is a city    log p york   new  is a city  ',\n",
              " 'notice that xlnet is able to capture the dependency between the pair  new  york   which is omitted by bert ',\n",
              " 'although in this example  bert learns some dependency pairs such as  new  city  and  york  city   it is obvious that xlnet always learns more dependency pairs given the same target and contains  denser  effective training signals ',\n",
              " 'for more formal analysis and further discussion  please refer to appendix a   ',\n",
              " '  experiments     pretraining and implementation following bert       we use the bookscorpus      and english wikipedia as part of our pretraining data  which have   gb plain text combined ',\n",
              " 'in addition  we include giga     gb text        clueweb      b  extended from       and common crawl     for pretraining ',\n",
              " 'we use heuristics to aggressively filter out short or low quality articles for clueweb      b and common crawl  which results in   gb and    gb text respectively ',\n",
              " 'after tokenization with sentencepiece       we obtain     b      b      b      b  and      b subword pieces for wikipedia  bookscorpus  giga   clueweb  and common crawl respectively  which are      b in total ',\n",
              " 'our largest model xlnet large has the same architecture hyperparameters as bert large  which results in a similar model size ',\n",
              " 'during pretraining  we always use a full sequence length of     ',\n",
              " 'firstly  to provide a fair comparison with bert  section       we also trained xlnet large wikibooks on bookscorpus and wikipedia only  where we reuse all pretraining hyper parameters as in the original bert ',\n",
              " 'then  we scale up the training of xlnet large by using all the datasets described above ',\n",
              " 'specifically  we train on     tpu v  chips for    k steps with an adam weight decay optimizer  linear learning rate decay  and a batch size of       which takes about     days ',\n",
              " 'it was   observed that the model still underfits the data at the end of training ',\n",
              " 'finally  we perform ablation study  section      based on the xlnet base wikibooks ',\n",
              " 'since the recurrence mechanism is introduced  we use a bidirectional data input pipeline where each of the forward and backward directions takes half of the batch size ',\n",
              " 'for training xlnet large  we set the partial prediction constant k as    see section      ',\n",
              " 'our finetuning procedure follows bert      except otherwise specified   ',\n",
              " 'we employ an idea of span based prediction  where we first sample a length l                   and then randomly select a consecutive span of l tokens as prediction targets within a context of  kl  tokens ',\n",
              " 'we use a variety of natural language understanding datasets to evaluate the performance of our method ',\n",
              " 'detailed descriptions of the settings for all the datasets can be found in appendix a   ',\n",
              " '    fair comparison with bert model squad    squad    race mnli qnli qqp rte sst   mrpc cola sts b bert large  best of                                                                     xlnet largewikibooks                                                                  table    fair comparison with bert ',\n",
              " 'all models are trained using the same data and hyperparameters as in bert ',\n",
              " 'we use the best of   bert variants for comparison  i e   the original bert  bert with whole word masking  and bert without next sentence prediction ',\n",
              " 'here  we first compare the performance of bert and xlnet in a fair setting to decouple the effects of using more data and the improvement from bert to xlnet ',\n",
              " 'in table    we compare     best performance of three different variants of bert and     xlnet trained with the same data and hyperparameters ',\n",
              " 'as we can see  trained on the same data with an almost identical training recipe  xlnet outperforms bert by a sizable margin on all the considered datasets ',\n",
              " '    comparison with roberta  scaling up race accuracy middle high model ndcg    err    gpt                     drmm                bert                     knrm               bert dcmn                      conv               roberta                     bert              xlnet                xlnet             table    comparison with state of the art results on the test set of race  a reading comprehension task  and on clueweb   b  a document ranking task ',\n",
              " '  indicates using ensembles ',\n",
              " '  indicates our implementations ',\n",
              " ' middle  and  high  in race are two subsets representing middle and high school difficulty levels ',\n",
              " 'all bert  roberta  and xlnet results are obtained with a    layer architecture with similar model sizes  aka bert large  ',\n",
              " 'after the initial publication of our manuscript  a few other pretrained models were released such as roberta      and albert      ',\n",
              " 'since albert involves increasing the model hidden size from      to           and thus substantially increases the amount of computation in terms of flops  we exclude albert from the following results as it is hard to lead to scientific conclusions ',\n",
              " 'to obtain relatively fair comparison with roberta  the experiment in this section is based on full data and reuses the hyper parameters of roberta  as described in section     ',\n",
              " 'the results are presented in tables    reading comprehension   document ranking      question answering      text classification  and    natural language understanding   where xlnet generally outperforms bert and roberta ',\n",
              " 'in addition  we make two more interesting observations   hyperparameters for pretraining and finetuning are in appendix a   ',\n",
              " '  squad    em f  squad    em f  dev set results  single model  bert                  bert                 roberta                roberta                xlnet           xlnet           test set results on leaderboard  single model  as of dec           bert                    bert                    roberta                    bert                     xlnet               xlnet                 table    results on squad  a reading comprehension dataset ',\n",
              " '  marks our runs with the official code ',\n",
              " '  indicates ensembles ',\n",
              " '   we are not able to obtain the test results of our latest model on squad    from the organizers after submitting our result for more than one month  and thus report the results of an older version for the squad    test set ',\n",
              " 'model imdb yelp   yelp   dbpedia ag amazon   amazon   cnn                                        dpcnn                                        mixed vat                                 ulmfit                                   bert                                        xlnet                                      table    comparison with state of the art error rates on the test sets of several text classification datasets ',\n",
              " 'all bert and xlnet results are obtained with a    layer architecture with similar model sizes  aka bert large  ',\n",
              " 'model mnli qnli qqp rte sst   mrpc cola sts b wnli single task single models on dev bert                                                 roberta                                                     xlnet                                                multi task ensembles on test  from leaderboard as of oct           mt dnn                                                         roberta                                                         xlnet                                                        table    results on glue ',\n",
              " '  indicates using ensembles  and   denotes single task results in a multi task row ',\n",
              " 'all dev results are the median of    runs ',\n",
              " 'the upper section shows direct comparison on dev data and the lower section shows comparison with state of the art results on the public leaderboard ',\n",
              " '  for explicit reasoning tasks like squad and race that involve longer context  the performance gain of xlnet is usually larger ',\n",
              " 'this superiority at dealing with longer context could come from the transformer xl backbone in xlnet ',\n",
              " '  for classification tasks that already have abundant supervised examples such as mnli      k   yelp      k  and amazon    m   xlnet still lead to substantial gains ',\n",
              " '    ablation study we perform an ablation study to understand the importance of each design choice based on four datasets with diverse characteristics ',\n",
              " 'specifically  there are three main aspects we hope to study    the effectiveness of the permutation language modeling objective alone  especially compared to the denoising auto encoding objective used by bert ',\n",
              " '  the importance of using transformer xl as the backbone neural architecture ',\n",
              " '  the necessity of some implementation details including span based prediction  the bidirectional input pipeline  and next sentence prediction ',\n",
              " '  with these purposes in mind  in table    we compare   xlnet base variants with different implementation details  rows         the original bert base model  row     and an additional transformer xl baseline trained with the denoising auto encoding  dae  objective used in bert but with the bidirectional input pipeline  row    ',\n",
              " 'for fair comparison  all models are based on a    layer architecture with the same model hyper parameters as bert base and are trained on only wikipedia and the bookscorpus ',\n",
              " 'all results reported are the median of   runs ',\n",
              " '  model race squad    mnli sst   f  em m mm   bert base                                      dae   transformer xl                                       xlnet base  k                                            xlnet base  k                                              memory                                         span based pred                                         bidirectional data                                         next sent pred                                     table    the results of bert on race are taken from      ',\n",
              " 'we run bert on the other datasets using the official implementation and the same hyperparameter search space as xlnet ',\n",
              " 'k is a hyperparameter to control the optimization difficulty  see section      ',\n",
              " 'examining rows       of table    we can see both transformer xl and the permutation lm clearly contribute the superior performance of xlnet over bert ',\n",
              " 'moreover  if we remove the memory caching mechanism  row     the performance clearly drops  especially for race which involves the longest context among the   tasks ',\n",
              " 'in addition  rows       show that both span based prediction and the bidirectional input pipeline play important roles in xlnet ',\n",
              " 'finally  we unexpectedly find the the next sentence prediction objective proposed in the original bert does not necessarily lead to an improvement in our setting ',\n",
              " 'hence  we exclude the next sentence prediction objective from xlnet ',\n",
              " 'finally  we also perform a qualitative study of the attention patterns  which is included in appendix a   due to page limit ',\n",
              " '  conclusions xlnet is a generalized ar pretraining method that uses a permutation language modeling objective to combine the advantages of ar and ae methods ',\n",
              " 'the neural architecture of xlnet is developed to work seamlessly with the ar objective  including integrating transformer xl and the careful design of the two stream attention mechanism ',\n",
              " 'xlnet achieves substantial improvement over previous pretraining objectives on various tasks ',\n",
              " 'acknowledgments the authors would like to thank qizhe xie and adams wei yu for providing useful feedback on the project  jamie callan for providing the clueweb dataset  youlong cheng  yanping huang and shibo wang for providing ideas to improve our tpu implementation  chenyan xiong and zhuyun dai for clarifying the setting of the document ranking task ',\n",
              " 'zy and rs were supported by the office of naval research grant n              the national science foundation  nsf  grant iis         the nvidia fellowship  and the siebel scholarship ',\n",
              " 'zd and yy were supported in part by nsf under the grant iis         and by the doe office of science under the grant ascr  kj       ',\n",
              " 'references     rami al rfou  dokook choe  noah constant  mandy guo  and llion jones ',\n",
              " 'character level language modeling with deeper self attention ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '    anonymous ',\n",
              " 'bam ',\n",
              " 'born again multi task networks for natural language understanding ',\n",
              " 'anonymous preprint under review       ',\n",
              " '    alexei baevski and michael auli ',\n",
              " 'adaptive input representations for neural language modeling ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '      yoshua bengio and samy bengio ',\n",
              " 'modeling high dimensional discrete data with multi layer neural networks ',\n",
              " 'in advances in neural information processing systems  pages               ',\n",
              " '    jamie callan  mark hoy  changkuk yoo  and le zhao ',\n",
              " 'clueweb   data set       ',\n",
              " '    common crawl ',\n",
              " 'common crawl ',\n",
              " 'url  http   http   commoncrawl ',\n",
              " 'org       ',\n",
              " '    andrew m dai and quoc v le ',\n",
              " 'semi supervised sequence learning ',\n",
              " 'in advances in neural information processing systems  pages                 ',\n",
              " '    zhuyun dai  chenyan xiong  jamie callan  and zhiyuan liu ',\n",
              " 'convolutional neural networks for soft matching n grams in ad hoc search ',\n",
              " 'in proceedings of the eleventh acm international conference on web search and data mining  pages         ',\n",
              " 'acm       ',\n",
              " '    zihang dai  zhilin yang  yiming yang  william w cohen  jaime carbonell  quoc v le  and ruslan salakhutdinov ',\n",
              " 'transformer xl  attentive language models beyond a fixed length context ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     jacob devlin  ming wei chang  kenton lee  and kristina toutanova ',\n",
              " 'bert  pre training of deep bidirectional transformers for language understanding ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     william fedus  ian goodfellow  and andrew m dai ',\n",
              " 'maskgan  better text generation via filling in the  ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     mathieu germain  karol gregor  iain murray  and hugo larochelle ',\n",
              " 'made  masked autoencoder for distribution estimation ',\n",
              " 'in international conference on machine learning  pages               ',\n",
              " '     jiafeng guo  yixing fan  qingyao ai  and w bruce croft ',\n",
              " 'a deep relevance matching model for ad hoc retrieval ',\n",
              " 'in proceedings of the   th acm international on conference on information and knowledge management  pages       ',\n",
              " 'acm       ',\n",
              " '     jeremy howard and sebastian ruder ',\n",
              " 'universal language model fine tuning for text classification ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     rie johnson and tong zhang ',\n",
              " 'deep pyramid convolutional neural networks for text categorization ',\n",
              " 'in proceedings of the   th annual meeting of the association for computational linguistics  volume    long papers   pages               ',\n",
              " '     vid kocijan  ana maria cretu  oana maria camburu  yordan yordanov  and thomas lukasiewicz ',\n",
              " 'a surprisingly robust trick for winograd schema challenge ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     taku kudo and john richardson ',\n",
              " 'sentencepiece  a simple and language independent subword tokenizer and detokenizer for neural text processing ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     guokun lai  qizhe xie  hanxiao liu  yiming yang  and eduard hovy ',\n",
              " 'race  large scale reading comprehension dataset from examinations ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     zhenzhong lan  mingda chen  sebastian goodman  kevin gimpel  piyush sharma  and radu soricut ',\n",
              " 'albert  a lite bert for self supervised learning of language representations ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     xiaodong liu  pengcheng he  weizhu chen  and jianfeng gao ',\n",
              " 'multi task deep neural networks for natural language understanding ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     yinhan liu  myle ott  naman goyal  jingfei du  mandar joshi  danqi chen  omer levy  mike lewis  luke zettlemoyer  and veselin stoyanov ',\n",
              " 'roberta  a robustly optimized bert pretraining approach ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     bryan mccann  james bradbury  caiming xiong  and richard socher ',\n",
              " 'learned in translation  contextualized word vectors ',\n",
              " 'in advances in neural information processing systems  pages                 ',\n",
              " '     takeru miyato  andrew m dai  and ian goodfellow ',\n",
              " 'adversarial training methods for semisupervised text classification ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     aaron van den oord  nal kalchbrenner  and koray kavukcuoglu ',\n",
              " 'pixel recurrent neural networks ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     xiaoman pan  kai sun  dian yu  heng ji  and dong yu ',\n",
              " 'improving question answering with external knowledge ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '        robert parker  david graff  junbo kong  ke chen  and kazuaki maeda ',\n",
              " 'english gigaword fifth edition  linguistic data consortium ',\n",
              " 'technical report  technical report ',\n",
              " 'linguistic data consortium  philadelphia  tech ',\n",
              " 'rep        ',\n",
              " '     matthew e peters  mark neumann  mohit iyyer  matt gardner  christopher clark  kenton lee  and luke zettlemoyer ',\n",
              " 'deep contextualized word representations ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     alec radford  karthik narasimhan  tim salimans  and ilya sutskever ',\n",
              " 'improving language understanding by generative pre training ',\n",
              " 'url https   s  us west   ',\n",
              " 'amazonaws ',\n",
              " 'com openaiassets research covers languageunsupervised language understanding paper ',\n",
              " 'pdf       ',\n",
              " '     pranav rajpurkar  robin jia  and percy liang ',\n",
              " 'know what you don t know  unanswerable questions for squad ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     pranav rajpurkar  jian zhang  konstantin lopyrev  and percy liang ',\n",
              " 'squad           questions for machine comprehension of text ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     devendra singh sachan  manzil zaheer  and ruslan salakhutdinov ',\n",
              " 'revisiting lstm networks for semi supervised text classification via mixed objective function ',\n",
              " '     ',\n",
              " '     benigno uria  marc alexandre c t   karol gregor  iain murray  and hugo larochelle ',\n",
              " 'neural autoregressive distribution estimation ',\n",
              " 'the journal of machine learning research                         ',\n",
              " '     ashish vaswani  noam shazeer  niki parmar  jakob uszkoreit  llion jones  aidan n gomez   ukasz kaiser  and illia polosukhin ',\n",
              " 'attention is all you need ',\n",
              " 'in advances in neural information processing systems  pages                 ',\n",
              " '     alex wang  amanpreet singh  julian michael  felix hill  omer levy  and samuel r  bowman ',\n",
              " 'glue  a multi task benchmark and analysis platform for natural language understanding ',\n",
              " '     ',\n",
              " 'in the proceedings of iclr ',\n",
              " '     qizhe xie  zihang dai  eduard hovy  minh thang luong  and quoc v  le ',\n",
              " 'unsupervised data augmentation ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     chenyan xiong  zhuyun dai  jamie callan  zhiyuan liu  and russell power ',\n",
              " 'end to end neural ad hoc ranking with kernel pooling ',\n",
              " 'in proceedings of the   th international acm sigir conference on research and development in information retrieval  pages       ',\n",
              " 'acm       ',\n",
              " '     zhilin yang  zihang dai  ruslan salakhutdinov  and william w cohen ',\n",
              " 'breaking the softmax bottleneck  a high rank rnn language model ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     shuailiang zhang  hai zhao  yuwei wu  zhuosheng zhang  xi zhou  and xiang zhou ',\n",
              " 'dual comatching network for multi choice reading comprehension ',\n",
              " 'arxiv preprint arxiv                  ',\n",
              " '     xiang zhang  junbo zhao  and yann lecun ',\n",
              " 'character level convolutional networks for text classification ',\n",
              " 'in advances in neural information processing systems  pages               ',\n",
              " '     yukun zhu  ryan kiros  rich zemel  ruslan salakhutdinov  raquel urtasun  antonio torralba  and sanja fidler ',\n",
              " 'aligning books and movies  towards story like visual explanations by watching movies and reading books ',\n",
              " 'in proceedings of the ieee international conference on computer vision  pages             ',\n",
              " '   a target aware representation via two stream self attention a   a concrete example of how standard lm parameterization fails in this section  we provide a concrete example to show how the standard language model parameterization fails under the permutation objective  as discussed in section     ',\n",
              " 'specifically  let s consider two different permutations z     and z     satisfying the following relationship z      t   z      t   z t but z     t   i    j   z     t  ',\n",
              " 'then  substituting the two permutations respectively into the naive parameterization  we have p  xi   x   xz t      z   z     t  i  z      t  z t   p  xj   x   xz t      z   z     t  j  z      t  z t   exp e x   h xz t     p x  exp  e x    h xz t    ',\n",
              " 'effectively  two different target positions i and j share exactly the same model prediction ',\n",
              " 'however  the ground truth distribution of two positions should certainly be different ',\n",
              " 'a   two stream attention here  we provide the implementation details of the two stream attention with a transformer xl backbone ',\n",
              " 'initial represetation   t       ',\n",
              " ' ',\n",
              " ' ',\n",
              " '  t   ht   e xt  and gt   w cached layer m content represetation  memory  from previous segment  h  m  for the transformer xl layer m              m  attention with relative positional encoding and position wise feed forward are consecutively employed to update the represetntations   t       ',\n",
              " ' ',\n",
              " ' ',\n",
              " '  t   h  m  zt   layernorm  h  m    zt   relattn  h  m    zt   h h  m      h  m    z t i   h  m  zt   layernorm  h  m  zt   posff  h  m  zt    g   m  zt   layernorm  g  m    zt   relattn  g  m    zt   h h  m      h  m    z t i   g  m  zt   layernorm  g   m  zt   posff  g   m  zt    target aware prediction distribution  p  xzt   x   xz t     exp   e x   g  m  zt   p x  exp   e x    g  m  zt    a   datasets a     race dataset the race dataset      contains near    k questions taken from the english exams for middle and high school chinese students in the age range between    to     with the answers generated by human experts ',\n",
              " 'this is one of the most difficult reading comprehension datasets that involve challenging reasoning questions ',\n",
              " 'moreover  the average length of the passages in race are longer than      which is significantly longer than other popular reading comprehension datasets such as squad      ',\n",
              " 'as a result  this dataset serves as a challenging benchmark for long text understanding ',\n",
              " 'we use a sequence length of     during finetuning ',\n",
              " 'a     squad squad is a large scale reading comprehension dataset with two tasks ',\n",
              " 'squad         contains questions that always have a corresponding answer in the given passages  while squad         introduces unanswerable questions ',\n",
              " 'to finetune an xlnet on squad     we jointly apply a logistic regression loss for answerability prediction similar to classification tasks and a standard span extraction loss for question answering      ',\n",
              " '  a     text classification datasets following previous work on text classification           we evaluate xlnet on the following benchmarks  imdb  yelp    yelp    dbpedia  ag  amazon    and amazon   ',\n",
              " 'a     glue dataset the glue dataset      is a collection of   natural language understanding tasks ',\n",
              " 'the test set labels are removed from the publicly released version  and all the practitioners must submit their predictions on the evaluation server to obtain test set results ',\n",
              " 'in table    we present results of multiple settings  including single task and multi task  as well as single models and ensembles ',\n",
              " 'in the multi task setting  we jointly train an xlnet on the four largest datasets mnli  sst    qnli  and qqp and finetune the network on the other datasets ',\n",
              " 'only single task training is employed for the four large datasets ',\n",
              " 'for qnli  we employed a pairwise relevance ranking scheme as in      for our test set submission ',\n",
              " 'however  for fair comparison with bert  our result on the qnli dev set is based on a standard classification paradigm ',\n",
              " 'for wnli  we use the loss described in      ',\n",
              " 'a     clueweb   b dataset following the setting in previous work      we use the clueweb   b dataset to evaluate the performance on document ranking ',\n",
              " 'the queries were created by the trec           web tracks based on   m documents and the task is to rerank the top     documents retrieved using a standard retrieval method ',\n",
              " 'since document ranking  or ad hoc retrieval  mainly concerns the low level representations instead of high level semantics  this dataset serves as a testbed for evaluating the quality of word embeddings ',\n",
              " 'we use a pretrained xlnet to extract word embeddings for the documents and queries without finetuning  and employ a kernel pooling network      to rank the documents ',\n",
              " 'a   hyperparameters a     pretraining hyperparameters hparam value number of layers    hidden size      number of attention heads    attention head size    ffn inner hidden size      hidden dropout     gelu dropout     attention dropout     partial prediction k   max sequence length     batch size      learning rate  e   number of steps    k warmup steps        learning rate decay linear adam epsilon  e   weight decay      table    hyperparameters for pretraining ',\n",
              " 'the hyperparameters used for pretraining xlnet are shown in table   ',\n",
              " 'a     hyperparameters for finetuning the hyperparameters used for finetuning xlnet on various tasks are shown in table   ',\n",
              " ' layer wise decay  means exponentially decaying the learning rates of individual layers in a top down manner ',\n",
              " 'for example  suppose the    th layer uses a learning rate l  and the layer wise decay rate is    then the learning rate of layer m is l    m ',\n",
              " '   hparam race squad mnli yelp   dropout     attention dropout     max sequence length                 batch size               learning rate  e    e    e    e   number of steps   k  k   k   k learning rate decay linear weight decay      adam epsilon  e    e    e    e   layer wise lr decay                  table    hyperparameters for finetuning ',\n",
              " 'a   discussion and analysis a     comparison with bert to prove a general point beyond one example  we now turn to more formal expressions ',\n",
              " 'inspired by previous work       given a sequence x    x           xt    we define a set of target context pairs of interest  i     x  u    where u is a set of tokens in x that form a context of x ',\n",
              " 'intuitively  we want the model to learn the dependency of x on u through a pretraining loss term log p x   u  ',\n",
              " 'for example  given the above sentence  the pairs of interest i could be instantiated as  i   n x   york  u    new       x   york  u    city       x   york  u    new  city            o  ',\n",
              " 'note that i is merely a virtual notion without unique ground truth  and our analysis will hold regardless of how i is instantiated ',\n",
              " 'given a set of target tokens t and a set of non target tokens n   x t   bert and xlnet both maximize log p t   n   but with different formulations  jbert   x x t log p x   n    jxlnet   x x t log p x   n   t x  where t x denote tokens in t that have a factorization order prior to x ',\n",
              " 'both objectives consist of multiple loss terms in the form of log p x   vx  ',\n",
              " 'intuitively  if there exists a target context pair  x  u    i such that u   vx  then the loss term log p x   vx  provides a training signal to the dependency between x and u ',\n",
              " 'for convenience  we say a target context pair  x  u    i is covered by a model  objective  if u   vx ',\n",
              " 'given the definition  let s consider two cases    if u   n   the dependency  x  u  is covered by both bert and xlnet ',\n",
              " '  if u   n   t x and u   t x       the dependency can only be covered by xlnet but not bert ',\n",
              " 'as a result  xlnet is able to cover more dependencies than bert ',\n",
              " 'in other words  the xlnet objective contains more effective training signals  which empirically leads to better performance in section   ',\n",
              " 'a     comparison with language modeling borrowing examples and notations from section a      a standard ar language model like gpt      is only able to cover the dependency  x   york  u    new   but not  x   new  u    york   ',\n",
              " 'xlnet  on the other hand  is able to cover both in expectation over all factorization orders ',\n",
              " 'such a limitation of ar language modeling can be critical in real world applications ',\n",
              " 'for example  consider a span extraction question answering task with the context  thom yorke is the singer of radiohead  and the question  who is the singer of radiohead  ',\n",
              " 'the representations of  thom yorke  are not dependent on  radiohead  with ar language modeling and thus they will not be chosen as the answer by the standard approach that employs softmax over all token representations ',\n",
              " 'more formally  consider a context target pair  x  u     if u    t x  where t x denotes the tokens prior to x in the original sequence  ar language modeling is not able to cover the dependency ',\n",
              " '  in comparison  xlnet is able to cover all dependencies in expectation ',\n",
              " 'approaches like elmo      concatenate forward and backward language models in a shallow manner  which is not sufficient for modeling deep interactions between the two directions ',\n",
              " 'a     bridging the gap between language modeling and pretraining with a deep root in density estimation               language modeling has been a rapidly developing research area           ',\n",
              " 'however  there has been a gap between language modeling and pretraining due to the lack of the capability of bidirectional context modeling  as analyzed in section a     ',\n",
              " 'it has even been challenged by some machine learning practitioners whether language modeling is a meaningful pursuit if it does not directly improve downstream tasks    ',\n",
              " 'xlnet generalizes language modeling and bridges such a gap ',\n",
              " 'as a result  it further  justifies  language modeling research ',\n",
              " 'moreover  it becomes possible to leverage the rapid progress of language modeling research for pretraining ',\n",
              " 'as an example  we integrate transformer xl into xlnet to demonstrate the usefulness of the latest language modeling progress ',\n",
              " 'a   qualitative analysis of attention patterns we compare the attention pattern of bert and xlnet without finetuning ',\n",
              " 'firstly  we found   typical patterns shared by both  as shown in fig ',\n",
              " '  ',\n",
              " ' a  content stripes  b  local self focus  c  two segments  d  content based symmetry figure    attention patterns shared by xlnet and bert ',\n",
              " 'rows and columns represent query and key respectively ',\n",
              " 'more interestingly  in fig ',\n",
              " '   we present   patterns that only appear in xlnet but not bert   a  the self exclusion pattern attends to all other tokens but itself  probably offering a fast way to gather global information   b  the relative stride pattern attends to positions every a few stride apart relative to the query position   c  the one side masked pattern is very similar to the lower left part of fig ',\n",
              " '   d   with the upper right triangle masked out ',\n",
              " 'it seems that the model learns not to attend the relative right half ',\n",
              " 'note that all these three unique patterns involve the relative positions rather than absolute ones  and hence are likely enabled by the  relative attention  mechanism in xlnet ',\n",
              " 'we conjecture these unique patterns contribute to the performance advantage of xlnet ',\n",
              " 'on the other hand  the proposed permutation lm objective mostly contributes to a better data efficiency  whose effects may not be obvious from qualitative visualization ',\n",
              " ' a  self exclusion  b  relative stride  c  one side masked figure    attention patterns that appear only in xlnet ',\n",
              " 'rows and columns represent query and key respectively ',\n",
              " '   x  x  x  x  h      h      h      h      h      h      factorization order                x  x  x  x  h      h      h      h      h      factorization order                h      h      h      h      h      mem    mem    x  x  x  x  h      h      h      h      h      factorization order                h      h      h      x  x  x  x  h      h      h      h      h      h      h      h      factorization order                mem    mem    mem    mem    mem    mem    x  x  x  x  figure    illustration of the permutation language modeling objective for predicting x  given the same input sequence x but with different factorization orders ',\n",
              " 'a   visualizing memory and permutation in this section  we provide a detailed visualization of the proposed permutation language modeling objective  including the mechanism of reusing memory  aka the recurrence mechanism   how we use attention masks to permute the factorization order  and the difference of the two attention streams ',\n",
              " 'as shown in figure   and    given the current position zt  the attention mask is decided by the permutation  or factorization order  z such that only tokens the occur before zt in the permutation can be attended  i e   positions zi with i   t  moreover  comparing figure   and    we can see how the query stream and the content stream work differently with a specific permutation through attention masks ',\n",
              " 'the main difference is that the query stream cannot do self attention and does not have access to the token at the position  while the content stream performs normal self attention ',\n",
              " ' the problem of language modeling is essentially density estimation for text data ',\n",
              " '  https   openreview net forum id hjepno cym    position   view position   view w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      w w w w g      h      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      position   view w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      position   view split view of the content stream  factorization order                 joint view of the content stream  factorization order                 mem    x  w x  w x  w x  w g      g      g      g      mem    h      h      h      h      g      g      g      g      h      h      h      h      split view figure    a detailed illustration of the content stream of the proposed objective with both the joint view and split views based on a length   sequence under the factorization order              ',\n",
              " 'note that if we ignore the query representation  the computation in this figure is simply the standard self attention  though with a particular attention mask ',\n",
              " '   w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      w w w w g      h      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      w w w w g      g      g      g      g      g      g      g      mem    mem    x  x  x  x  h      h      h      h      h      h      h      h      position   view position   view position   view position   view split view of the query stream  factorization order                 split view mem    x  w x  w x  w x  w g      g      g      g  mem        h      h      h      h      g      g      g      g      h      h      h      h      joint view of the query stream  factorization order                 figure    a detailed illustration of the query stream of the proposed objective with both the joint view and split views based on a length   sequence under the factorization order              ',\n",
              " 'the dash arrows indicate that the query stream cannot access the token  content  at the same position  but only the location information ',\n",
              " '  ']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuYbBCDNXuYQ",
        "outputId": "31c3f949-b2fc-4134-c3b5-803dcc905240"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words(\"english\")):\n",
        "      print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VWrX-bQXzUh",
        "outputId": "5c1885b0-2bce-485a-b01c-f775ce9e4fad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "auto\n",
            "encoding\n",
            "specifically\n",
            "text\n",
            "sequence\n",
            "x\n",
            "bert\n",
            "first\n",
            "construct\n",
            "corrupted\n",
            "version\n",
            "x\n",
            "randomly\n",
            "setting\n",
            "portion\n",
            "e\n",
            "g\n",
            "token\n",
            "x\n",
            "special\n",
            "symbol\n",
            "mask\n",
            "let\n",
            "masked\n",
            "token\n",
            "x\n",
            "training\n",
            "objective\n",
            "reconstruct\n",
            "x\n",
            "x\n",
            "max\n",
            "log\n",
            "p\n",
            "x\n",
            "x\n",
            "x\n",
            "mt\n",
            "log\n",
            "p\n",
            "xt\n",
            "x\n",
            "x\n",
            "mt\n",
            "log\n",
            "exp\n",
            "h\n",
            "x\n",
            "e\n",
            "xt\n",
            "p\n",
            "x\n",
            "exp\n",
            "h\n",
            "x\n",
            "e\n",
            "x\n",
            "mt\n",
            "indicates\n",
            "xt\n",
            "masked\n",
            "h\n",
            "transformer\n",
            "map\n",
            "length\n",
            "text\n",
            "sequence\n",
            "x\n",
            "sequence\n",
            "hidden\n",
            "vector\n",
            "h\n",
            "x\n",
            "h\n",
            "x\n",
            "h\n",
            "x\n",
            "h\n",
            "x\n",
            "pro\n",
            "con\n",
            "two\n",
            "pretraining\n",
            "objective\n",
            "compared\n",
            "following\n",
            "aspect\n",
            "independence\n",
            "assumption\n",
            "emphasized\n",
            "sign\n",
            "eq\n",
            "bert\n",
            "factorizes\n",
            "joint\n",
            "conditional\n",
            "probability\n",
            "p\n",
            "x\n",
            "x\n",
            "based\n",
            "independence\n",
            "assumption\n",
            "masked\n",
            "token\n",
            "x\n",
            "separately\n",
            "reconstructed\n",
            "comparison\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "factorizes\n",
            "p\n",
            "x\n",
            "using\n",
            "product\n",
            "rule\n",
            "hold\n",
            "universally\n",
            "without\n",
            "independence\n",
            "assumption\n",
            "input\n",
            "noise\n",
            "input\n",
            "bert\n",
            "contains\n",
            "artificial\n",
            "symbol\n",
            "like\n",
            "mask\n",
            "never\n",
            "occur\n",
            "downstream\n",
            "task\n",
            "creates\n",
            "pretrain\n",
            "finetune\n",
            "discrepancy\n",
            "replacing\n",
            "mask\n",
            "original\n",
            "token\n",
            "solve\n",
            "problem\n",
            "original\n",
            "token\n",
            "used\n",
            "small\n",
            "probability\n",
            "otherwise\n",
            "eq\n",
            "trivial\n",
            "optimize\n",
            "comparison\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "rely\n",
            "input\n",
            "corruption\n",
            "suffer\n",
            "issue\n",
            "context\n",
            "dependency\n",
            "ar\n",
            "representation\n",
            "h\n",
            "x\n",
            "conditioned\n",
            "token\n",
            "position\n",
            "e\n",
            "token\n",
            "left\n",
            "bert\n",
            "representation\n",
            "h\n",
            "x\n",
            "access\n",
            "contextual\n",
            "information\n",
            "side\n",
            "result\n",
            "bert\n",
            "objective\n",
            "allows\n",
            "model\n",
            "pretrained\n",
            "better\n",
            "capture\n",
            "bidirectional\n",
            "context\n",
            "objective\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "according\n",
            "comparison\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "bert\n",
            "posse\n",
            "unique\n",
            "advantage\n",
            "natural\n",
            "question\n",
            "ask\n",
            "whether\n",
            "exists\n",
            "pretraining\n",
            "objective\n",
            "brings\n",
            "advantage\n",
            "avoiding\n",
            "weakness\n",
            "borrowing\n",
            "idea\n",
            "orderless\n",
            "nade\n",
            "propose\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "retains\n",
            "benefit\n",
            "ar\n",
            "model\n",
            "also\n",
            "allows\n",
            "model\n",
            "capture\n",
            "bidirectional\n",
            "context\n",
            "specifically\n",
            "sequence\n",
            "x\n",
            "length\n",
            "different\n",
            "order\n",
            "perform\n",
            "valid\n",
            "autoregressive\n",
            "factorization\n",
            "intuitively\n",
            "model\n",
            "parameter\n",
            "shared\n",
            "across\n",
            "factorization\n",
            "order\n",
            "expectation\n",
            "model\n",
            "learn\n",
            "gather\n",
            "information\n",
            "position\n",
            "side\n",
            "formalize\n",
            "idea\n",
            "let\n",
            "zt\n",
            "set\n",
            "possible\n",
            "permutation\n",
            "length\n",
            "index\n",
            "sequence\n",
            "use\n",
            "zt\n",
            "z\n",
            "denote\n",
            "th\n",
            "element\n",
            "first\n",
            "element\n",
            "permutation\n",
            "z\n",
            "zt\n",
            "proposed\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "expressed\n",
            "follows\n",
            "max\n",
            "ez\n",
            "zt\n",
            "x\n",
            "log\n",
            "p\n",
            "xzt\n",
            "xz\n",
            "essentially\n",
            "text\n",
            "sequence\n",
            "x\n",
            "sample\n",
            "factorization\n",
            "order\n",
            "z\n",
            "time\n",
            "decompose\n",
            "likelihood\n",
            "p\n",
            "x\n",
            "according\n",
            "factorization\n",
            "order\n",
            "since\n",
            "model\n",
            "parameter\n",
            "shared\n",
            "across\n",
            "factorization\n",
            "order\n",
            "training\n",
            "expectation\n",
            "xt\n",
            "seen\n",
            "every\n",
            "possible\n",
            "element\n",
            "xi\n",
            "xt\n",
            "sequence\n",
            "hence\n",
            "able\n",
            "capture\n",
            "bidirectional\n",
            "context\n",
            "moreover\n",
            "objective\n",
            "fit\n",
            "ar\n",
            "framework\n",
            "naturally\n",
            "avoids\n",
            "independence\n",
            "assumption\n",
            "pretrain\n",
            "finetune\n",
            "discrepancy\n",
            "discussed\n",
            "section\n",
            "remark\n",
            "permutation\n",
            "proposed\n",
            "objective\n",
            "permutes\n",
            "factorization\n",
            "order\n",
            "sequence\n",
            "order\n",
            "word\n",
            "keep\n",
            "original\n",
            "sequence\n",
            "order\n",
            "use\n",
            "positional\n",
            "encoding\n",
            "corresponding\n",
            "original\n",
            "sequence\n",
            "rely\n",
            "proper\n",
            "attention\n",
            "mask\n",
            "transformer\n",
            "achieve\n",
            "permutation\n",
            "factorization\n",
            "order\n",
            "note\n",
            "choice\n",
            "necessary\n",
            "since\n",
            "model\n",
            "encounter\n",
            "text\n",
            "sequence\n",
            "natural\n",
            "order\n",
            "finetuning\n",
            "provide\n",
            "overall\n",
            "picture\n",
            "show\n",
            "example\n",
            "predicting\n",
            "token\n",
            "x\n",
            "given\n",
            "input\n",
            "sequence\n",
            "x\n",
            "different\n",
            "factorization\n",
            "order\n",
            "appendix\n",
            "figure\n",
            "architecture\n",
            "two\n",
            "stream\n",
            "self\n",
            "attention\n",
            "target\n",
            "aware\n",
            "representation\n",
            "sample\n",
            "factorization\n",
            "order\n",
            "attention\n",
            "mask\n",
            "e\n",
            "x\n",
            "w\n",
            "e\n",
            "x\n",
            "w\n",
            "e\n",
            "x\n",
            "w\n",
            "e\n",
            "x\n",
            "w\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "content\n",
            "stream\n",
            "see\n",
            "self\n",
            "query\n",
            "stream\n",
            "see\n",
            "self\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "masked\n",
            "two\n",
            "stream\n",
            "attention\n",
            "masked\n",
            "two\n",
            "stream\n",
            "attention\n",
            "c\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "attention\n",
            "q\n",
            "k\n",
            "v\n",
            "h\n",
            "g\n",
            "attention\n",
            "q\n",
            "k\n",
            "v\n",
            "b\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "h\n",
            "g\n",
            "figure\n",
            "content\n",
            "stream\n",
            "attention\n",
            "standard\n",
            "self\n",
            "attention\n",
            "b\n",
            "query\n",
            "stream\n",
            "attention\n",
            "access\n",
            "information\n",
            "content\n",
            "xzt\n",
            "c\n",
            "overview\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "training\n",
            "two\n",
            "stream\n",
            "attention\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "desired\n",
            "property\n",
            "naive\n",
            "implementation\n",
            "standard\n",
            "transformer\n",
            "parameterization\n",
            "may\n",
            "work\n",
            "see\n",
            "problem\n",
            "assume\n",
            "parameterize\n",
            "next\n",
            "token\n",
            "distribution\n",
            "p\n",
            "xzt\n",
            "xz\n",
            "using\n",
            "standard\n",
            "softmax\n",
            "formulation\n",
            "e\n",
            "p\n",
            "xzt\n",
            "x\n",
            "xz\n",
            "exp\n",
            "e\n",
            "x\n",
            "h\n",
            "xz\n",
            "p\n",
            "x\n",
            "exp\n",
            "e\n",
            "x\n",
            "h\n",
            "xz\n",
            "h\n",
            "xz\n",
            "denotes\n",
            "hidden\n",
            "representation\n",
            "xz\n",
            "produced\n",
            "shared\n",
            "transformer\n",
            "network\n",
            "proper\n",
            "masking\n",
            "notice\n",
            "representation\n",
            "h\n",
            "xz\n",
            "depend\n",
            "position\n",
            "predict\n",
            "e\n",
            "value\n",
            "zt\n",
            "consequently\n",
            "distribution\n",
            "predicted\n",
            "regardless\n",
            "target\n",
            "position\n",
            "able\n",
            "learn\n",
            "useful\n",
            "representation\n",
            "see\n",
            "appendix\n",
            "concrete\n",
            "example\n",
            "avoid\n",
            "problem\n",
            "propose\n",
            "parameterize\n",
            "next\n",
            "token\n",
            "distribution\n",
            "target\n",
            "position\n",
            "aware\n",
            "p\n",
            "xzt\n",
            "x\n",
            "xz\n",
            "exp\n",
            "e\n",
            "x\n",
            "g\n",
            "xz\n",
            "zt\n",
            "p\n",
            "x\n",
            "exp\n",
            "e\n",
            "x\n",
            "g\n",
            "xz\n",
            "zt\n",
            "g\n",
            "xz\n",
            "zt\n",
            "denotes\n",
            "new\n",
            "type\n",
            "representation\n",
            "additionally\n",
            "take\n",
            "target\n",
            "position\n",
            "zt\n",
            "input\n",
            "two\n",
            "stream\n",
            "self\n",
            "attention\n",
            "idea\n",
            "target\n",
            "aware\n",
            "representation\n",
            "remove\n",
            "ambiguity\n",
            "target\n",
            "prediction\n",
            "formulate\n",
            "g\n",
            "xz\n",
            "zt\n",
            "remains\n",
            "non\n",
            "trivial\n",
            "problem\n",
            "among\n",
            "possibility\n",
            "propose\n",
            "stand\n",
            "target\n",
            "position\n",
            "zt\n",
            "rely\n",
            "position\n",
            "zt\n",
            "gather\n",
            "information\n",
            "context\n",
            "xz\n",
            "attention\n",
            "parameterization\n",
            "work\n",
            "two\n",
            "requirement\n",
            "contradictory\n",
            "standard\n",
            "transformer\n",
            "architecture\n",
            "predict\n",
            "token\n",
            "xzt\n",
            "g\n",
            "xz\n",
            "zt\n",
            "use\n",
            "position\n",
            "zt\n",
            "content\n",
            "xzt\n",
            "otherwise\n",
            "objective\n",
            "becomes\n",
            "trivial\n",
            "predict\n",
            "token\n",
            "xzj\n",
            "j\n",
            "g\n",
            "xz\n",
            "zt\n",
            "also\n",
            "encode\n",
            "content\n",
            "xzt\n",
            "provide\n",
            "full\n",
            "contextual\n",
            "information\n",
            "resolve\n",
            "contradiction\n",
            "propose\n",
            "use\n",
            "two\n",
            "set\n",
            "hidden\n",
            "representation\n",
            "instead\n",
            "one\n",
            "content\n",
            "representation\n",
            "h\n",
            "xz\n",
            "abbreviated\n",
            "hzt\n",
            "serf\n",
            "similar\n",
            "role\n",
            "standard\n",
            "hidden\n",
            "state\n",
            "transformer\n",
            "representation\n",
            "encodes\n",
            "context\n",
            "xzt\n",
            "query\n",
            "representation\n",
            "g\n",
            "xz\n",
            "zt\n",
            "abbreviated\n",
            "gzt\n",
            "access\n",
            "contextual\n",
            "information\n",
            "xz\n",
            "position\n",
            "zt\n",
            "content\n",
            "xzt\n",
            "discussed\n",
            "computationally\n",
            "first\n",
            "layer\n",
            "query\n",
            "stream\n",
            "initialized\n",
            "trainable\n",
            "vector\n",
            "e\n",
            "g\n",
            "w\n",
            "content\n",
            "stream\n",
            "set\n",
            "corresponding\n",
            "word\n",
            "embedding\n",
            "e\n",
            "h\n",
            "e\n",
            "xi\n",
            "self\n",
            "attention\n",
            "layer\n",
            "two\n",
            "stream\n",
            "representation\n",
            "schematically\n",
            "updated\n",
            "avoid\n",
            "clutter\n",
            "omit\n",
            "implementation\n",
            "detail\n",
            "including\n",
            "multi\n",
            "head\n",
            "attention\n",
            "residual\n",
            "connection\n",
            "layer\n",
            "normalization\n",
            "position\n",
            "wise\n",
            "feed\n",
            "forward\n",
            "used\n",
            "transformer\n",
            "xl\n",
            "detail\n",
            "included\n",
            "appendix\n",
            "reference\n",
            "shared\n",
            "set\n",
            "parameter\n",
            "follows\n",
            "illustrated\n",
            "figure\n",
            "b\n",
            "g\n",
            "zt\n",
            "attention\n",
            "q\n",
            "g\n",
            "zt\n",
            "kv\n",
            "h\n",
            "z\n",
            "query\n",
            "stream\n",
            "use\n",
            "zt\n",
            "see\n",
            "xzt\n",
            "h\n",
            "zt\n",
            "attention\n",
            "q\n",
            "h\n",
            "zt\n",
            "kv\n",
            "h\n",
            "z\n",
            "content\n",
            "stream\n",
            "use\n",
            "zt\n",
            "xzt\n",
            "q\n",
            "k\n",
            "v\n",
            "denote\n",
            "query\n",
            "key\n",
            "value\n",
            "attention\n",
            "operation\n",
            "update\n",
            "rule\n",
            "content\n",
            "representation\n",
            "exactly\n",
            "standard\n",
            "self\n",
            "attention\n",
            "finetuning\n",
            "simply\n",
            "drop\n",
            "query\n",
            "stream\n",
            "use\n",
            "content\n",
            "stream\n",
            "normal\n",
            "transformer\n",
            "xl\n",
            "finally\n",
            "use\n",
            "last\n",
            "layer\n",
            "query\n",
            "representation\n",
            "g\n",
            "zt\n",
            "compute\n",
            "eq\n",
            "partial\n",
            "prediction\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "several\n",
            "benefit\n",
            "much\n",
            "challenging\n",
            "optimization\n",
            "problem\n",
            "due\n",
            "permutation\n",
            "cause\n",
            "slow\n",
            "convergence\n",
            "preliminary\n",
            "experiment\n",
            "reduce\n",
            "optimization\n",
            "difficulty\n",
            "choose\n",
            "predict\n",
            "last\n",
            "token\n",
            "factorization\n",
            "order\n",
            "formally\n",
            "split\n",
            "z\n",
            "non\n",
            "target\n",
            "subsequence\n",
            "z\n",
            "c\n",
            "target\n",
            "subsequence\n",
            "z\n",
            "c\n",
            "c\n",
            "cutting\n",
            "point\n",
            "objective\n",
            "maximize\n",
            "log\n",
            "likelihood\n",
            "target\n",
            "subsequence\n",
            "conditioned\n",
            "non\n",
            "target\n",
            "subsequence\n",
            "e\n",
            "max\n",
            "ez\n",
            "zt\n",
            "h\n",
            "log\n",
            "p\n",
            "xz\n",
            "c\n",
            "xz\n",
            "c\n",
            "ez\n",
            "zt\n",
            "x\n",
            "z\n",
            "c\n",
            "log\n",
            "p\n",
            "xzt\n",
            "xz\n",
            "note\n",
            "z\n",
            "c\n",
            "chosen\n",
            "target\n",
            "posse\n",
            "longest\n",
            "context\n",
            "sequence\n",
            "given\n",
            "current\n",
            "factorization\n",
            "order\n",
            "z\n",
            "hyperparameter\n",
            "k\n",
            "used\n",
            "k\n",
            "token\n",
            "selected\n",
            "prediction\n",
            "e\n",
            "z\n",
            "z\n",
            "c\n",
            "k\n",
            "unselected\n",
            "token\n",
            "query\n",
            "representation\n",
            "need\n",
            "computed\n",
            "save\n",
            "speed\n",
            "memory\n",
            "incorporating\n",
            "idea\n",
            "transformer\n",
            "xl\n",
            "since\n",
            "objective\n",
            "function\n",
            "fit\n",
            "ar\n",
            "framework\n",
            "incorporate\n",
            "state\n",
            "art\n",
            "ar\n",
            "language\n",
            "model\n",
            "transformer\n",
            "xl\n",
            "pretraining\n",
            "framework\n",
            "name\n",
            "method\n",
            "integrate\n",
            "two\n",
            "important\n",
            "technique\n",
            "transformer\n",
            "xl\n",
            "namely\n",
            "relative\n",
            "positional\n",
            "encoding\n",
            "scheme\n",
            "segment\n",
            "recurrence\n",
            "mechanism\n",
            "apply\n",
            "relative\n",
            "positional\n",
            "encoding\n",
            "based\n",
            "original\n",
            "sequence\n",
            "discussed\n",
            "earlier\n",
            "straightforward\n",
            "discus\n",
            "integrate\n",
            "recurrence\n",
            "mechanism\n",
            "proposed\n",
            "permutation\n",
            "setting\n",
            "enable\n",
            "model\n",
            "reuse\n",
            "hidden\n",
            "state\n",
            "previous\n",
            "segment\n",
            "without\n",
            "loss\n",
            "generality\n",
            "suppose\n",
            "two\n",
            "segment\n",
            "taken\n",
            "long\n",
            "sequence\n",
            "e\n",
            "x\n",
            "x\n",
            "st\n",
            "let\n",
            "z\n",
            "z\n",
            "permutation\n",
            "respectively\n",
            "based\n",
            "permutation\n",
            "z\n",
            "process\n",
            "first\n",
            "segment\n",
            "cache\n",
            "obtained\n",
            "content\n",
            "representation\n",
            "h\n",
            "layer\n",
            "next\n",
            "segment\n",
            "x\n",
            "attention\n",
            "update\n",
            "memory\n",
            "written\n",
            "h\n",
            "zt\n",
            "attention\n",
            "q\n",
            "h\n",
            "zt\n",
            "kv\n",
            "h\n",
            "h\n",
            "h\n",
            "z\n",
            "denotes\n",
            "concatenation\n",
            "along\n",
            "sequence\n",
            "dimension\n",
            "notice\n",
            "positional\n",
            "encoding\n",
            "depend\n",
            "actual\n",
            "position\n",
            "original\n",
            "sequence\n",
            "thus\n",
            "attention\n",
            "update\n",
            "independent\n",
            "z\n",
            "representation\n",
            "h\n",
            "obtained\n",
            "allows\n",
            "caching\n",
            "reusing\n",
            "memory\n",
            "without\n",
            "knowing\n",
            "factorization\n",
            "order\n",
            "previous\n",
            "segment\n",
            "expectation\n",
            "model\n",
            "learns\n",
            "utilize\n",
            "memory\n",
            "factorization\n",
            "order\n",
            "last\n",
            "segment\n",
            "query\n",
            "stream\n",
            "computed\n",
            "way\n",
            "finally\n",
            "figure\n",
            "c\n",
            "present\n",
            "overview\n",
            "proposed\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "two\n",
            "stream\n",
            "attention\n",
            "see\n",
            "appendix\n",
            "detailed\n",
            "illustration\n",
            "modeling\n",
            "multiple\n",
            "segment\n",
            "many\n",
            "downstream\n",
            "task\n",
            "multiple\n",
            "input\n",
            "segment\n",
            "e\n",
            "g\n",
            "question\n",
            "context\n",
            "paragraph\n",
            "question\n",
            "answering\n",
            "discus\n",
            "pretrain\n",
            "xlnet\n",
            "model\n",
            "multiple\n",
            "segment\n",
            "autoregressive\n",
            "framework\n",
            "pretraining\n",
            "phase\n",
            "following\n",
            "bert\n",
            "randomly\n",
            "sample\n",
            "two\n",
            "segment\n",
            "either\n",
            "context\n",
            "treat\n",
            "concatenation\n",
            "two\n",
            "segment\n",
            "one\n",
            "sequence\n",
            "perform\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "reuse\n",
            "memory\n",
            "belongs\n",
            "context\n",
            "specifically\n",
            "input\n",
            "model\n",
            "bert\n",
            "cl\n",
            "sep\n",
            "b\n",
            "sep\n",
            "sep\n",
            "cl\n",
            "two\n",
            "special\n",
            "symbol\n",
            "b\n",
            "two\n",
            "segment\n",
            "although\n",
            "follow\n",
            "two\n",
            "segment\n",
            "data\n",
            "format\n",
            "xlnet\n",
            "large\n",
            "use\n",
            "objective\n",
            "next\n",
            "sentence\n",
            "prediction\n",
            "show\n",
            "consistent\n",
            "improvement\n",
            "ablation\n",
            "study\n",
            "see\n",
            "section\n",
            "relative\n",
            "segment\n",
            "encoding\n",
            "architecturally\n",
            "different\n",
            "bert\n",
            "add\n",
            "absolute\n",
            "segment\n",
            "embedding\n",
            "word\n",
            "embedding\n",
            "position\n",
            "extend\n",
            "idea\n",
            "relative\n",
            "encoding\n",
            "transformer\n",
            "xl\n",
            "also\n",
            "encode\n",
            "segment\n",
            "given\n",
            "pair\n",
            "position\n",
            "j\n",
            "sequence\n",
            "j\n",
            "segment\n",
            "use\n",
            "segment\n",
            "encoding\n",
            "sij\n",
            "otherwise\n",
            "sij\n",
            "learnable\n",
            "model\n",
            "parameter\n",
            "attention\n",
            "head\n",
            "word\n",
            "consider\n",
            "whether\n",
            "two\n",
            "position\n",
            "within\n",
            "segment\n",
            "opposed\n",
            "considering\n",
            "specific\n",
            "segment\n",
            "consistent\n",
            "core\n",
            "idea\n",
            "relative\n",
            "encoding\n",
            "e\n",
            "modeling\n",
            "relationship\n",
            "position\n",
            "attends\n",
            "j\n",
            "segment\n",
            "encoding\n",
            "sij\n",
            "used\n",
            "compute\n",
            "attention\n",
            "weight\n",
            "aij\n",
            "qi\n",
            "b\n",
            "sij\n",
            "qi\n",
            "query\n",
            "vector\n",
            "standard\n",
            "attention\n",
            "operation\n",
            "b\n",
            "learnable\n",
            "head\n",
            "specific\n",
            "bias\n",
            "vector\n",
            "finally\n",
            "value\n",
            "aij\n",
            "added\n",
            "normal\n",
            "attention\n",
            "weight\n",
            "two\n",
            "benefit\n",
            "using\n",
            "relative\n",
            "segment\n",
            "encoding\n",
            "first\n",
            "inductive\n",
            "bias\n",
            "relative\n",
            "encoding\n",
            "improves\n",
            "generalization\n",
            "second\n",
            "open\n",
            "possibility\n",
            "finetuning\n",
            "task\n",
            "two\n",
            "input\n",
            "segment\n",
            "possible\n",
            "using\n",
            "absolute\n",
            "segment\n",
            "encoding\n",
            "discussion\n",
            "comparing\n",
            "eq\n",
            "observe\n",
            "bert\n",
            "xlnet\n",
            "perform\n",
            "partial\n",
            "prediction\n",
            "e\n",
            "predicting\n",
            "subset\n",
            "token\n",
            "sequence\n",
            "necessary\n",
            "choice\n",
            "bert\n",
            "token\n",
            "masked\n",
            "impossible\n",
            "make\n",
            "meaningful\n",
            "prediction\n",
            "addition\n",
            "bert\n",
            "xlnet\n",
            "partial\n",
            "prediction\n",
            "play\n",
            "role\n",
            "reducing\n",
            "optimization\n",
            "difficulty\n",
            "predicting\n",
            "token\n",
            "sufficient\n",
            "context\n",
            "however\n",
            "independence\n",
            "assumption\n",
            "discussed\n",
            "section\n",
            "disables\n",
            "bert\n",
            "model\n",
            "dependency\n",
            "target\n",
            "better\n",
            "understand\n",
            "difference\n",
            "let\n",
            "consider\n",
            "concrete\n",
            "example\n",
            "new\n",
            "york\n",
            "city\n",
            "suppose\n",
            "bert\n",
            "xlnet\n",
            "select\n",
            "two\n",
            "token\n",
            "new\n",
            "york\n",
            "prediction\n",
            "target\n",
            "maximize\n",
            "log\n",
            "p\n",
            "new\n",
            "york\n",
            "city\n",
            "also\n",
            "suppose\n",
            "xlnet\n",
            "sample\n",
            "factorization\n",
            "order\n",
            "city\n",
            "new\n",
            "york\n",
            "case\n",
            "bert\n",
            "xlnet\n",
            "respectively\n",
            "reduce\n",
            "following\n",
            "objective\n",
            "jbert\n",
            "log\n",
            "p\n",
            "new\n",
            "city\n",
            "log\n",
            "p\n",
            "york\n",
            "city\n",
            "jxlnet\n",
            "log\n",
            "p\n",
            "new\n",
            "city\n",
            "log\n",
            "p\n",
            "york\n",
            "new\n",
            "city\n",
            "notice\n",
            "xlnet\n",
            "able\n",
            "capture\n",
            "dependency\n",
            "pair\n",
            "new\n",
            "york\n",
            "omitted\n",
            "bert\n",
            "although\n",
            "example\n",
            "bert\n",
            "learns\n",
            "dependency\n",
            "pair\n",
            "new\n",
            "city\n",
            "york\n",
            "city\n",
            "obvious\n",
            "xlnet\n",
            "always\n",
            "learns\n",
            "dependency\n",
            "pair\n",
            "given\n",
            "target\n",
            "contains\n",
            "denser\n",
            "effective\n",
            "training\n",
            "signal\n",
            "formal\n",
            "analysis\n",
            "discussion\n",
            "please\n",
            "refer\n",
            "appendix\n",
            "experiment\n",
            "pretraining\n",
            "implementation\n",
            "following\n",
            "bert\n",
            "use\n",
            "bookscorpus\n",
            "english\n",
            "wikipedia\n",
            "part\n",
            "pretraining\n",
            "data\n",
            "gb\n",
            "plain\n",
            "text\n",
            "combined\n",
            "addition\n",
            "include\n",
            "giga\n",
            "gb\n",
            "text\n",
            "clueweb\n",
            "b\n",
            "extended\n",
            "common\n",
            "crawl\n",
            "pretraining\n",
            "use\n",
            "heuristic\n",
            "aggressively\n",
            "filter\n",
            "short\n",
            "low\n",
            "quality\n",
            "article\n",
            "clueweb\n",
            "b\n",
            "common\n",
            "crawl\n",
            "result\n",
            "gb\n",
            "gb\n",
            "text\n",
            "respectively\n",
            "tokenization\n",
            "sentencepiece\n",
            "obtain\n",
            "b\n",
            "b\n",
            "b\n",
            "b\n",
            "b\n",
            "subword\n",
            "piece\n",
            "wikipedia\n",
            "bookscorpus\n",
            "giga\n",
            "clueweb\n",
            "common\n",
            "crawl\n",
            "respectively\n",
            "b\n",
            "total\n",
            "largest\n",
            "model\n",
            "xlnet\n",
            "large\n",
            "architecture\n",
            "hyperparameters\n",
            "bert\n",
            "large\n",
            "result\n",
            "similar\n",
            "model\n",
            "size\n",
            "pretraining\n",
            "always\n",
            "use\n",
            "full\n",
            "sequence\n",
            "length\n",
            "firstly\n",
            "provide\n",
            "fair\n",
            "comparison\n",
            "bert\n",
            "section\n",
            "also\n",
            "trained\n",
            "xlnet\n",
            "large\n",
            "wikibooks\n",
            "bookscorpus\n",
            "wikipedia\n",
            "reuse\n",
            "pretraining\n",
            "hyper\n",
            "parameter\n",
            "original\n",
            "bert\n",
            "scale\n",
            "training\n",
            "xlnet\n",
            "large\n",
            "using\n",
            "datasets\n",
            "described\n",
            "specifically\n",
            "train\n",
            "tpu\n",
            "v\n",
            "chip\n",
            "k\n",
            "step\n",
            "adam\n",
            "weight\n",
            "decay\n",
            "optimizer\n",
            "linear\n",
            "learning\n",
            "rate\n",
            "decay\n",
            "batch\n",
            "size\n",
            "take\n",
            "day\n",
            "observed\n",
            "model\n",
            "still\n",
            "underfits\n",
            "data\n",
            "end\n",
            "training\n",
            "finally\n",
            "perform\n",
            "ablation\n",
            "study\n",
            "section\n",
            "based\n",
            "xlnet\n",
            "base\n",
            "wikibooks\n",
            "since\n",
            "recurrence\n",
            "mechanism\n",
            "introduced\n",
            "use\n",
            "bidirectional\n",
            "data\n",
            "input\n",
            "pipeline\n",
            "forward\n",
            "backward\n",
            "direction\n",
            "take\n",
            "half\n",
            "batch\n",
            "size\n",
            "training\n",
            "xlnet\n",
            "large\n",
            "set\n",
            "partial\n",
            "prediction\n",
            "constant\n",
            "k\n",
            "see\n",
            "section\n",
            "finetuning\n",
            "procedure\n",
            "follows\n",
            "bert\n",
            "except\n",
            "otherwise\n",
            "specified\n",
            "employ\n",
            "idea\n",
            "span\n",
            "based\n",
            "prediction\n",
            "first\n",
            "sample\n",
            "length\n",
            "l\n",
            "randomly\n",
            "select\n",
            "consecutive\n",
            "span\n",
            "l\n",
            "token\n",
            "prediction\n",
            "target\n",
            "within\n",
            "context\n",
            "kl\n",
            "token\n",
            "use\n",
            "variety\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "datasets\n",
            "evaluate\n",
            "performance\n",
            "method\n",
            "detailed\n",
            "description\n",
            "setting\n",
            "datasets\n",
            "found\n",
            "appendix\n",
            "fair\n",
            "comparison\n",
            "bert\n",
            "model\n",
            "squad\n",
            "squad\n",
            "race\n",
            "mnli\n",
            "qnli\n",
            "qqp\n",
            "rte\n",
            "sst\n",
            "mrpc\n",
            "cola\n",
            "sts\n",
            "b\n",
            "bert\n",
            "large\n",
            "best\n",
            "xlnet\n",
            "largewikibooks\n",
            "table\n",
            "fair\n",
            "comparison\n",
            "bert\n",
            "model\n",
            "trained\n",
            "using\n",
            "data\n",
            "hyperparameters\n",
            "bert\n",
            "use\n",
            "best\n",
            "bert\n",
            "variant\n",
            "comparison\n",
            "e\n",
            "original\n",
            "bert\n",
            "bert\n",
            "whole\n",
            "word\n",
            "masking\n",
            "bert\n",
            "without\n",
            "next\n",
            "sentence\n",
            "prediction\n",
            "first\n",
            "compare\n",
            "performance\n",
            "bert\n",
            "xlnet\n",
            "fair\n",
            "setting\n",
            "decouple\n",
            "effect\n",
            "using\n",
            "data\n",
            "improvement\n",
            "bert\n",
            "xlnet\n",
            "table\n",
            "compare\n",
            "best\n",
            "performance\n",
            "three\n",
            "different\n",
            "variant\n",
            "bert\n",
            "xlnet\n",
            "trained\n",
            "data\n",
            "hyperparameters\n",
            "see\n",
            "trained\n",
            "data\n",
            "almost\n",
            "identical\n",
            "training\n",
            "recipe\n",
            "xlnet\n",
            "outperforms\n",
            "bert\n",
            "sizable\n",
            "margin\n",
            "considered\n",
            "datasets\n",
            "comparison\n",
            "roberta\n",
            "scaling\n",
            "race\n",
            "accuracy\n",
            "middle\n",
            "high\n",
            "model\n",
            "ndcg\n",
            "err\n",
            "gpt\n",
            "drmm\n",
            "bert\n",
            "knrm\n",
            "bert\n",
            "dcmn\n",
            "conv\n",
            "roberta\n",
            "bert\n",
            "xlnet\n",
            "xlnet\n",
            "table\n",
            "comparison\n",
            "state\n",
            "art\n",
            "result\n",
            "test\n",
            "set\n",
            "race\n",
            "reading\n",
            "comprehension\n",
            "task\n",
            "clueweb\n",
            "b\n",
            "document\n",
            "ranking\n",
            "task\n",
            "indicates\n",
            "using\n",
            "ensemble\n",
            "indicates\n",
            "implementation\n",
            "middle\n",
            "high\n",
            "race\n",
            "two\n",
            "subset\n",
            "representing\n",
            "middle\n",
            "high\n",
            "school\n",
            "difficulty\n",
            "level\n",
            "bert\n",
            "roberta\n",
            "xlnet\n",
            "result\n",
            "obtained\n",
            "layer\n",
            "architecture\n",
            "similar\n",
            "model\n",
            "size\n",
            "aka\n",
            "bert\n",
            "large\n",
            "initial\n",
            "publication\n",
            "manuscript\n",
            "pretrained\n",
            "model\n",
            "released\n",
            "roberta\n",
            "albert\n",
            "since\n",
            "albert\n",
            "involves\n",
            "increasing\n",
            "model\n",
            "hidden\n",
            "size\n",
            "thus\n",
            "substantially\n",
            "increase\n",
            "amount\n",
            "computation\n",
            "term\n",
            "flop\n",
            "exclude\n",
            "albert\n",
            "following\n",
            "result\n",
            "hard\n",
            "lead\n",
            "scientific\n",
            "conclusion\n",
            "obtain\n",
            "relatively\n",
            "fair\n",
            "comparison\n",
            "roberta\n",
            "experiment\n",
            "section\n",
            "based\n",
            "full\n",
            "data\n",
            "reuses\n",
            "hyper\n",
            "parameter\n",
            "roberta\n",
            "described\n",
            "section\n",
            "result\n",
            "presented\n",
            "table\n",
            "reading\n",
            "comprehension\n",
            "document\n",
            "ranking\n",
            "question\n",
            "answering\n",
            "text\n",
            "classification\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "xlnet\n",
            "generally\n",
            "outperforms\n",
            "bert\n",
            "roberta\n",
            "addition\n",
            "make\n",
            "two\n",
            "interesting\n",
            "observation\n",
            "hyperparameters\n",
            "pretraining\n",
            "finetuning\n",
            "appendix\n",
            "squad\n",
            "em\n",
            "f\n",
            "squad\n",
            "em\n",
            "f\n",
            "dev\n",
            "set\n",
            "result\n",
            "single\n",
            "model\n",
            "bert\n",
            "bert\n",
            "roberta\n",
            "roberta\n",
            "xlnet\n",
            "xlnet\n",
            "test\n",
            "set\n",
            "result\n",
            "leaderboard\n",
            "single\n",
            "model\n",
            "dec\n",
            "bert\n",
            "bert\n",
            "roberta\n",
            "bert\n",
            "xlnet\n",
            "xlnet\n",
            "table\n",
            "result\n",
            "squad\n",
            "reading\n",
            "comprehension\n",
            "dataset\n",
            "mark\n",
            "run\n",
            "official\n",
            "code\n",
            "indicates\n",
            "ensemble\n",
            "able\n",
            "obtain\n",
            "test\n",
            "result\n",
            "latest\n",
            "model\n",
            "squad\n",
            "organizer\n",
            "submitting\n",
            "result\n",
            "one\n",
            "month\n",
            "thus\n",
            "report\n",
            "result\n",
            "older\n",
            "version\n",
            "squad\n",
            "test\n",
            "set\n",
            "model\n",
            "imdb\n",
            "yelp\n",
            "yelp\n",
            "dbpedia\n",
            "ag\n",
            "amazon\n",
            "amazon\n",
            "cnn\n",
            "dpcnn\n",
            "mixed\n",
            "vat\n",
            "ulmfit\n",
            "bert\n",
            "xlnet\n",
            "table\n",
            "comparison\n",
            "state\n",
            "art\n",
            "error\n",
            "rate\n",
            "test\n",
            "set\n",
            "several\n",
            "text\n",
            "classification\n",
            "datasets\n",
            "bert\n",
            "xlnet\n",
            "result\n",
            "obtained\n",
            "layer\n",
            "architecture\n",
            "similar\n",
            "model\n",
            "size\n",
            "aka\n",
            "bert\n",
            "large\n",
            "model\n",
            "mnli\n",
            "qnli\n",
            "qqp\n",
            "rte\n",
            "sst\n",
            "mrpc\n",
            "cola\n",
            "sts\n",
            "b\n",
            "wnli\n",
            "single\n",
            "task\n",
            "single\n",
            "model\n",
            "dev\n",
            "bert\n",
            "roberta\n",
            "xlnet\n",
            "multi\n",
            "task\n",
            "ensemble\n",
            "test\n",
            "leaderboard\n",
            "oct\n",
            "mt\n",
            "dnn\n",
            "roberta\n",
            "xlnet\n",
            "table\n",
            "result\n",
            "glue\n",
            "indicates\n",
            "using\n",
            "ensemble\n",
            "denotes\n",
            "single\n",
            "task\n",
            "result\n",
            "multi\n",
            "task\n",
            "row\n",
            "dev\n",
            "result\n",
            "median\n",
            "run\n",
            "upper\n",
            "section\n",
            "show\n",
            "direct\n",
            "comparison\n",
            "dev\n",
            "data\n",
            "lower\n",
            "section\n",
            "show\n",
            "comparison\n",
            "state\n",
            "art\n",
            "result\n",
            "public\n",
            "leaderboard\n",
            "explicit\n",
            "reasoning\n",
            "task\n",
            "like\n",
            "squad\n",
            "race\n",
            "involve\n",
            "longer\n",
            "context\n",
            "performance\n",
            "gain\n",
            "xlnet\n",
            "usually\n",
            "larger\n",
            "superiority\n",
            "dealing\n",
            "longer\n",
            "context\n",
            "could\n",
            "come\n",
            "transformer\n",
            "xl\n",
            "backbone\n",
            "xlnet\n",
            "classification\n",
            "task\n",
            "already\n",
            "abundant\n",
            "supervised\n",
            "example\n",
            "mnli\n",
            "k\n",
            "yelp\n",
            "k\n",
            "amazon\n",
            "xlnet\n",
            "still\n",
            "lead\n",
            "substantial\n",
            "gain\n",
            "ablation\n",
            "study\n",
            "perform\n",
            "ablation\n",
            "study\n",
            "understand\n",
            "importance\n",
            "design\n",
            "choice\n",
            "based\n",
            "four\n",
            "datasets\n",
            "diverse\n",
            "characteristic\n",
            "specifically\n",
            "three\n",
            "main\n",
            "aspect\n",
            "hope\n",
            "study\n",
            "effectiveness\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "alone\n",
            "especially\n",
            "compared\n",
            "denoising\n",
            "auto\n",
            "encoding\n",
            "objective\n",
            "used\n",
            "bert\n",
            "importance\n",
            "using\n",
            "transformer\n",
            "xl\n",
            "backbone\n",
            "neural\n",
            "architecture\n",
            "necessity\n",
            "implementation\n",
            "detail\n",
            "including\n",
            "span\n",
            "based\n",
            "prediction\n",
            "bidirectional\n",
            "input\n",
            "pipeline\n",
            "next\n",
            "sentence\n",
            "prediction\n",
            "purpose\n",
            "mind\n",
            "table\n",
            "compare\n",
            "xlnet\n",
            "base\n",
            "variant\n",
            "different\n",
            "implementation\n",
            "detail\n",
            "row\n",
            "original\n",
            "bert\n",
            "base\n",
            "model\n",
            "row\n",
            "additional\n",
            "transformer\n",
            "xl\n",
            "baseline\n",
            "trained\n",
            "denoising\n",
            "auto\n",
            "encoding\n",
            "dae\n",
            "objective\n",
            "used\n",
            "bert\n",
            "bidirectional\n",
            "input\n",
            "pipeline\n",
            "row\n",
            "fair\n",
            "comparison\n",
            "model\n",
            "based\n",
            "layer\n",
            "architecture\n",
            "model\n",
            "hyper\n",
            "parameter\n",
            "bert\n",
            "base\n",
            "trained\n",
            "wikipedia\n",
            "bookscorpus\n",
            "result\n",
            "reported\n",
            "median\n",
            "run\n",
            "model\n",
            "race\n",
            "squad\n",
            "mnli\n",
            "sst\n",
            "f\n",
            "em\n",
            "mm\n",
            "bert\n",
            "base\n",
            "dae\n",
            "transformer\n",
            "xl\n",
            "xlnet\n",
            "base\n",
            "k\n",
            "xlnet\n",
            "base\n",
            "k\n",
            "memory\n",
            "span\n",
            "based\n",
            "pred\n",
            "bidirectional\n",
            "data\n",
            "next\n",
            "sent\n",
            "pred\n",
            "table\n",
            "result\n",
            "bert\n",
            "race\n",
            "taken\n",
            "run\n",
            "bert\n",
            "datasets\n",
            "using\n",
            "official\n",
            "implementation\n",
            "hyperparameter\n",
            "search\n",
            "space\n",
            "xlnet\n",
            "k\n",
            "hyperparameter\n",
            "control\n",
            "optimization\n",
            "difficulty\n",
            "see\n",
            "section\n",
            "examining\n",
            "row\n",
            "table\n",
            "see\n",
            "transformer\n",
            "xl\n",
            "permutation\n",
            "lm\n",
            "clearly\n",
            "contribute\n",
            "superior\n",
            "performance\n",
            "xlnet\n",
            "bert\n",
            "moreover\n",
            "remove\n",
            "memory\n",
            "caching\n",
            "mechanism\n",
            "row\n",
            "performance\n",
            "clearly\n",
            "drop\n",
            "especially\n",
            "race\n",
            "involves\n",
            "longest\n",
            "context\n",
            "among\n",
            "task\n",
            "addition\n",
            "row\n",
            "show\n",
            "span\n",
            "based\n",
            "prediction\n",
            "bidirectional\n",
            "input\n",
            "pipeline\n",
            "play\n",
            "important\n",
            "role\n",
            "xlnet\n",
            "finally\n",
            "unexpectedly\n",
            "find\n",
            "next\n",
            "sentence\n",
            "prediction\n",
            "objective\n",
            "proposed\n",
            "original\n",
            "bert\n",
            "necessarily\n",
            "lead\n",
            "improvement\n",
            "setting\n",
            "hence\n",
            "exclude\n",
            "next\n",
            "sentence\n",
            "prediction\n",
            "objective\n",
            "xlnet\n",
            "finally\n",
            "also\n",
            "perform\n",
            "qualitative\n",
            "study\n",
            "attention\n",
            "pattern\n",
            "included\n",
            "appendix\n",
            "due\n",
            "page\n",
            "limit\n",
            "conclusion\n",
            "xlnet\n",
            "generalized\n",
            "ar\n",
            "pretraining\n",
            "method\n",
            "us\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "combine\n",
            "advantage\n",
            "ar\n",
            "ae\n",
            "method\n",
            "neural\n",
            "architecture\n",
            "xlnet\n",
            "developed\n",
            "work\n",
            "seamlessly\n",
            "ar\n",
            "objective\n",
            "including\n",
            "integrating\n",
            "transformer\n",
            "xl\n",
            "careful\n",
            "design\n",
            "two\n",
            "stream\n",
            "attention\n",
            "mechanism\n",
            "xlnet\n",
            "achieves\n",
            "substantial\n",
            "improvement\n",
            "previous\n",
            "pretraining\n",
            "objective\n",
            "various\n",
            "task\n",
            "acknowledgment\n",
            "author\n",
            "would\n",
            "like\n",
            "thank\n",
            "qizhe\n",
            "xie\n",
            "adam\n",
            "wei\n",
            "yu\n",
            "providing\n",
            "useful\n",
            "feedback\n",
            "project\n",
            "jamie\n",
            "callan\n",
            "providing\n",
            "clueweb\n",
            "dataset\n",
            "youlong\n",
            "cheng\n",
            "yanping\n",
            "huang\n",
            "shibo\n",
            "wang\n",
            "providing\n",
            "idea\n",
            "improve\n",
            "tpu\n",
            "implementation\n",
            "chenyan\n",
            "xiong\n",
            "zhuyun\n",
            "dai\n",
            "clarifying\n",
            "setting\n",
            "document\n",
            "ranking\n",
            "task\n",
            "zy\n",
            "r\n",
            "supported\n",
            "office\n",
            "naval\n",
            "research\n",
            "grant\n",
            "n\n",
            "national\n",
            "science\n",
            "foundation\n",
            "nsf\n",
            "grant\n",
            "ii\n",
            "nvidia\n",
            "fellowship\n",
            "siebel\n",
            "scholarship\n",
            "zd\n",
            "yy\n",
            "supported\n",
            "part\n",
            "nsf\n",
            "grant\n",
            "ii\n",
            "doe\n",
            "office\n",
            "science\n",
            "grant\n",
            "ascr\n",
            "kj\n",
            "reference\n",
            "ramus\n",
            "al\n",
            "rfou\n",
            "dokook\n",
            "choe\n",
            "noah\n",
            "constant\n",
            "mandy\n",
            "guo\n",
            "llion\n",
            "jones\n",
            "character\n",
            "level\n",
            "language\n",
            "modeling\n",
            "deeper\n",
            "self\n",
            "attention\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "anonymous\n",
            "bam\n",
            "born\n",
            "multi\n",
            "task\n",
            "network\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "anonymous\n",
            "preprint\n",
            "review\n",
            "alexei\n",
            "baevski\n",
            "michael\n",
            "auli\n",
            "adaptive\n",
            "input\n",
            "representation\n",
            "neural\n",
            "language\n",
            "modeling\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "yoshua\n",
            "bengio\n",
            "samy\n",
            "bengio\n",
            "modeling\n",
            "high\n",
            "dimensional\n",
            "discrete\n",
            "data\n",
            "multi\n",
            "layer\n",
            "neural\n",
            "network\n",
            "advance\n",
            "neural\n",
            "information\n",
            "processing\n",
            "system\n",
            "page\n",
            "jamie\n",
            "callan\n",
            "mark\n",
            "hoy\n",
            "changkuk\n",
            "yoo\n",
            "le\n",
            "zhao\n",
            "clueweb\n",
            "data\n",
            "set\n",
            "common\n",
            "crawl\n",
            "common\n",
            "crawl\n",
            "url\n",
            "http\n",
            "http\n",
            "commoncrawl\n",
            "org\n",
            "andrew\n",
            "dai\n",
            "quoc\n",
            "v\n",
            "le\n",
            "semi\n",
            "supervised\n",
            "sequence\n",
            "learning\n",
            "advance\n",
            "neural\n",
            "information\n",
            "processing\n",
            "system\n",
            "page\n",
            "zhuyun\n",
            "dai\n",
            "chenyan\n",
            "xiong\n",
            "jamie\n",
            "callan\n",
            "zhiyuan\n",
            "liu\n",
            "convolutional\n",
            "neural\n",
            "network\n",
            "soft\n",
            "matching\n",
            "n\n",
            "gram\n",
            "ad\n",
            "hoc\n",
            "search\n",
            "proceeding\n",
            "eleventh\n",
            "acm\n",
            "international\n",
            "conference\n",
            "web\n",
            "search\n",
            "data\n",
            "mining\n",
            "page\n",
            "acm\n",
            "zihang\n",
            "dai\n",
            "zhilin\n",
            "yang\n",
            "yiming\n",
            "yang\n",
            "william\n",
            "w\n",
            "cohen\n",
            "jaime\n",
            "carbonell\n",
            "quoc\n",
            "v\n",
            "le\n",
            "ruslan\n",
            "salakhutdinov\n",
            "transformer\n",
            "xl\n",
            "attentive\n",
            "language\n",
            "model\n",
            "beyond\n",
            "fixed\n",
            "length\n",
            "context\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "jacob\n",
            "devlin\n",
            "ming\n",
            "wei\n",
            "chang\n",
            "kenton\n",
            "lee\n",
            "kristina\n",
            "toutanova\n",
            "bert\n",
            "pre\n",
            "training\n",
            "deep\n",
            "bidirectional\n",
            "transformer\n",
            "language\n",
            "understanding\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "william\n",
            "fedus\n",
            "ian\n",
            "goodfellow\n",
            "andrew\n",
            "dai\n",
            "maskgan\n",
            "better\n",
            "text\n",
            "generation\n",
            "via\n",
            "filling\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "mathieu\n",
            "germain\n",
            "karol\n",
            "gregor\n",
            "iain\n",
            "murray\n",
            "hugo\n",
            "larochelle\n",
            "made\n",
            "masked\n",
            "autoencoder\n",
            "distribution\n",
            "estimation\n",
            "international\n",
            "conference\n",
            "machine\n",
            "learning\n",
            "page\n",
            "jiafeng\n",
            "guo\n",
            "yixing\n",
            "fan\n",
            "qingyao\n",
            "ai\n",
            "w\n",
            "bruce\n",
            "croft\n",
            "deep\n",
            "relevance\n",
            "matching\n",
            "model\n",
            "ad\n",
            "hoc\n",
            "retrieval\n",
            "proceeding\n",
            "th\n",
            "acm\n",
            "international\n",
            "conference\n",
            "information\n",
            "knowledge\n",
            "management\n",
            "page\n",
            "acm\n",
            "jeremy\n",
            "howard\n",
            "sebastian\n",
            "ruder\n",
            "universal\n",
            "language\n",
            "model\n",
            "fine\n",
            "tuning\n",
            "text\n",
            "classification\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "rie\n",
            "johnson\n",
            "tong\n",
            "zhang\n",
            "deep\n",
            "pyramid\n",
            "convolutional\n",
            "neural\n",
            "network\n",
            "text\n",
            "categorization\n",
            "proceeding\n",
            "th\n",
            "annual\n",
            "meeting\n",
            "association\n",
            "computational\n",
            "linguistics\n",
            "volume\n",
            "long\n",
            "paper\n",
            "page\n",
            "vid\n",
            "kocijan\n",
            "ana\n",
            "maria\n",
            "cretu\n",
            "oana\n",
            "maria\n",
            "camburu\n",
            "yordan\n",
            "yordanov\n",
            "thomas\n",
            "lukasiewicz\n",
            "surprisingly\n",
            "robust\n",
            "trick\n",
            "winograd\n",
            "schema\n",
            "challenge\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "taku\n",
            "kudo\n",
            "john\n",
            "richardson\n",
            "sentencepiece\n",
            "simple\n",
            "language\n",
            "independent\n",
            "subword\n",
            "tokenizer\n",
            "detokenizer\n",
            "neural\n",
            "text\n",
            "processing\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "guokun\n",
            "lai\n",
            "qizhe\n",
            "xie\n",
            "hanxiao\n",
            "liu\n",
            "yiming\n",
            "yang\n",
            "eduard\n",
            "hovy\n",
            "race\n",
            "large\n",
            "scale\n",
            "reading\n",
            "comprehension\n",
            "dataset\n",
            "examination\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "zhenzhong\n",
            "lan\n",
            "mingda\n",
            "chen\n",
            "sebastian\n",
            "goodman\n",
            "kevin\n",
            "gimpel\n",
            "piyush\n",
            "sharma\n",
            "radu\n",
            "soricut\n",
            "albert\n",
            "lite\n",
            "bert\n",
            "self\n",
            "supervised\n",
            "learning\n",
            "language\n",
            "representation\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "xiaodong\n",
            "liu\n",
            "pengcheng\n",
            "weizhu\n",
            "chen\n",
            "jianfeng\n",
            "gao\n",
            "multi\n",
            "task\n",
            "deep\n",
            "neural\n",
            "network\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "yinhan\n",
            "liu\n",
            "myle\n",
            "ott\n",
            "naman\n",
            "goyal\n",
            "jingfei\n",
            "du\n",
            "mandar\n",
            "joshi\n",
            "danqi\n",
            "chen\n",
            "omer\n",
            "levy\n",
            "mike\n",
            "lewis\n",
            "luke\n",
            "zettlemoyer\n",
            "veselin\n",
            "stoyanov\n",
            "roberta\n",
            "robustly\n",
            "optimized\n",
            "bert\n",
            "pretraining\n",
            "approach\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "bryan\n",
            "mccann\n",
            "james\n",
            "bradbury\n",
            "caiming\n",
            "xiong\n",
            "richard\n",
            "socher\n",
            "learned\n",
            "translation\n",
            "contextualized\n",
            "word\n",
            "vector\n",
            "advance\n",
            "neural\n",
            "information\n",
            "processing\n",
            "system\n",
            "page\n",
            "takeru\n",
            "miyato\n",
            "andrew\n",
            "dai\n",
            "ian\n",
            "goodfellow\n",
            "adversarial\n",
            "training\n",
            "method\n",
            "semisupervised\n",
            "text\n",
            "classification\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "aaron\n",
            "van\n",
            "den\n",
            "oord\n",
            "nal\n",
            "kalchbrenner\n",
            "koray\n",
            "kavukcuoglu\n",
            "pixel\n",
            "recurrent\n",
            "neural\n",
            "network\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "xiaoman\n",
            "pan\n",
            "kai\n",
            "sun\n",
            "dian\n",
            "yu\n",
            "heng\n",
            "ji\n",
            "dong\n",
            "yu\n",
            "improving\n",
            "question\n",
            "answering\n",
            "external\n",
            "knowledge\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "robert\n",
            "parker\n",
            "david\n",
            "graff\n",
            "junbo\n",
            "kong\n",
            "ke\n",
            "chen\n",
            "kazuaki\n",
            "maeda\n",
            "english\n",
            "gigaword\n",
            "fifth\n",
            "edition\n",
            "linguistic\n",
            "data\n",
            "consortium\n",
            "technical\n",
            "report\n",
            "technical\n",
            "report\n",
            "linguistic\n",
            "data\n",
            "consortium\n",
            "philadelphia\n",
            "tech\n",
            "rep\n",
            "matthew\n",
            "e\n",
            "peter\n",
            "mark\n",
            "neumann\n",
            "mohit\n",
            "iyyer\n",
            "matt\n",
            "gardner\n",
            "christopher\n",
            "clark\n",
            "kenton\n",
            "lee\n",
            "luke\n",
            "zettlemoyer\n",
            "deep\n",
            "contextualized\n",
            "word\n",
            "representation\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "alec\n",
            "radford\n",
            "karthik\n",
            "narasimhan\n",
            "tim\n",
            "salimans\n",
            "ilya\n",
            "sutskever\n",
            "improving\n",
            "language\n",
            "understanding\n",
            "generative\n",
            "pre\n",
            "training\n",
            "url\n",
            "http\n",
            "u\n",
            "west\n",
            "amazonaws\n",
            "com\n",
            "openaiassets\n",
            "research\n",
            "cover\n",
            "languageunsupervised\n",
            "language\n",
            "understanding\n",
            "paper\n",
            "pdf\n",
            "pranav\n",
            "rajpurkar\n",
            "robin\n",
            "jia\n",
            "percy\n",
            "liang\n",
            "know\n",
            "know\n",
            "unanswerable\n",
            "question\n",
            "squad\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "pranav\n",
            "rajpurkar\n",
            "jian\n",
            "zhang\n",
            "konstantin\n",
            "lopyrev\n",
            "percy\n",
            "liang\n",
            "squad\n",
            "question\n",
            "machine\n",
            "comprehension\n",
            "text\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "devendra\n",
            "singh\n",
            "sachan\n",
            "manzil\n",
            "zaheer\n",
            "ruslan\n",
            "salakhutdinov\n",
            "revisiting\n",
            "lstm\n",
            "network\n",
            "semi\n",
            "supervised\n",
            "text\n",
            "classification\n",
            "via\n",
            "mixed\n",
            "objective\n",
            "function\n",
            "benigno\n",
            "uria\n",
            "marc\n",
            "alexandre\n",
            "c\n",
            "karol\n",
            "gregor\n",
            "iain\n",
            "murray\n",
            "hugo\n",
            "larochelle\n",
            "neural\n",
            "autoregressive\n",
            "distribution\n",
            "estimation\n",
            "journal\n",
            "machine\n",
            "learning\n",
            "research\n",
            "ashish\n",
            "vaswani\n",
            "noam\n",
            "shazeer\n",
            "niki\n",
            "parmar\n",
            "jakob\n",
            "uszkoreit\n",
            "llion\n",
            "jones\n",
            "aidan\n",
            "n\n",
            "gomez\n",
            "ukasz\n",
            "kaiser\n",
            "illia\n",
            "polosukhin\n",
            "attention\n",
            "need\n",
            "advance\n",
            "neural\n",
            "information\n",
            "processing\n",
            "system\n",
            "page\n",
            "alex\n",
            "wang\n",
            "amanpreet\n",
            "singh\n",
            "julian\n",
            "michael\n",
            "felix\n",
            "hill\n",
            "omer\n",
            "levy\n",
            "samuel\n",
            "r\n",
            "bowman\n",
            "glue\n",
            "multi\n",
            "task\n",
            "benchmark\n",
            "analysis\n",
            "platform\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "proceeding\n",
            "iclr\n",
            "qizhe\n",
            "xie\n",
            "zihang\n",
            "dai\n",
            "eduard\n",
            "hovy\n",
            "minh\n",
            "thang\n",
            "luong\n",
            "quoc\n",
            "v\n",
            "le\n",
            "unsupervised\n",
            "data\n",
            "augmentation\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "chenyan\n",
            "xiong\n",
            "zhuyun\n",
            "dai\n",
            "jamie\n",
            "callan\n",
            "zhiyuan\n",
            "liu\n",
            "russell\n",
            "power\n",
            "end\n",
            "end\n",
            "neural\n",
            "ad\n",
            "hoc\n",
            "ranking\n",
            "kernel\n",
            "pooling\n",
            "proceeding\n",
            "th\n",
            "international\n",
            "acm\n",
            "sigir\n",
            "conference\n",
            "research\n",
            "development\n",
            "information\n",
            "retrieval\n",
            "page\n",
            "acm\n",
            "zhilin\n",
            "yang\n",
            "zihang\n",
            "dai\n",
            "ruslan\n",
            "salakhutdinov\n",
            "william\n",
            "w\n",
            "cohen\n",
            "breaking\n",
            "softmax\n",
            "bottleneck\n",
            "high\n",
            "rank\n",
            "rnn\n",
            "language\n",
            "model\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "shuailiang\n",
            "zhang\n",
            "hai\n",
            "zhao\n",
            "yuwei\n",
            "wu\n",
            "zhuosheng\n",
            "zhang\n",
            "xi\n",
            "zhou\n",
            "xiang\n",
            "zhou\n",
            "dual\n",
            "comatching\n",
            "network\n",
            "multi\n",
            "choice\n",
            "reading\n",
            "comprehension\n",
            "arxiv\n",
            "preprint\n",
            "arxiv\n",
            "xiang\n",
            "zhang\n",
            "junbo\n",
            "zhao\n",
            "yann\n",
            "lecun\n",
            "character\n",
            "level\n",
            "convolutional\n",
            "network\n",
            "text\n",
            "classification\n",
            "advance\n",
            "neural\n",
            "information\n",
            "processing\n",
            "system\n",
            "page\n",
            "yukun\n",
            "zhu\n",
            "ryan\n",
            "kiros\n",
            "rich\n",
            "zemel\n",
            "ruslan\n",
            "salakhutdinov\n",
            "raquel\n",
            "urtasun\n",
            "antonio\n",
            "torralba\n",
            "sanja\n",
            "fidler\n",
            "aligning\n",
            "book\n",
            "movie\n",
            "towards\n",
            "story\n",
            "like\n",
            "visual\n",
            "explanation\n",
            "watching\n",
            "movie\n",
            "reading\n",
            "book\n",
            "proceeding\n",
            "ieee\n",
            "international\n",
            "conference\n",
            "computer\n",
            "vision\n",
            "page\n",
            "target\n",
            "aware\n",
            "representation\n",
            "via\n",
            "two\n",
            "stream\n",
            "self\n",
            "attention\n",
            "concrete\n",
            "example\n",
            "standard\n",
            "lm\n",
            "parameterization\n",
            "fails\n",
            "section\n",
            "provide\n",
            "concrete\n",
            "example\n",
            "show\n",
            "standard\n",
            "language\n",
            "model\n",
            "parameterization\n",
            "fails\n",
            "permutation\n",
            "objective\n",
            "discussed\n",
            "section\n",
            "specifically\n",
            "let\n",
            "consider\n",
            "two\n",
            "different\n",
            "permutation\n",
            "z\n",
            "z\n",
            "satisfying\n",
            "following\n",
            "relationship\n",
            "z\n",
            "z\n",
            "z\n",
            "z\n",
            "j\n",
            "z\n",
            "substituting\n",
            "two\n",
            "permutation\n",
            "respectively\n",
            "naive\n",
            "parameterization\n",
            "p\n",
            "xi\n",
            "x\n",
            "xz\n",
            "z\n",
            "z\n",
            "z\n",
            "z\n",
            "p\n",
            "xj\n",
            "x\n",
            "xz\n",
            "z\n",
            "z\n",
            "j\n",
            "z\n",
            "z\n",
            "exp\n",
            "e\n",
            "x\n",
            "h\n",
            "xz\n",
            "p\n",
            "x\n",
            "exp\n",
            "e\n",
            "x\n",
            "h\n",
            "xz\n",
            "effectively\n",
            "two\n",
            "different\n",
            "target\n",
            "position\n",
            "j\n",
            "share\n",
            "exactly\n",
            "model\n",
            "prediction\n",
            "however\n",
            "ground\n",
            "truth\n",
            "distribution\n",
            "two\n",
            "position\n",
            "certainly\n",
            "different\n",
            "two\n",
            "stream\n",
            "attention\n",
            "provide\n",
            "implementation\n",
            "detail\n",
            "two\n",
            "stream\n",
            "attention\n",
            "transformer\n",
            "xl\n",
            "backbone\n",
            "initial\n",
            "represetation\n",
            "ht\n",
            "e\n",
            "xt\n",
            "gt\n",
            "w\n",
            "cached\n",
            "layer\n",
            "content\n",
            "represetation\n",
            "memory\n",
            "previous\n",
            "segment\n",
            "h\n",
            "transformer\n",
            "xl\n",
            "layer\n",
            "attention\n",
            "relative\n",
            "positional\n",
            "encoding\n",
            "position\n",
            "wise\n",
            "feed\n",
            "forward\n",
            "consecutively\n",
            "employed\n",
            "update\n",
            "represetntations\n",
            "h\n",
            "zt\n",
            "layernorm\n",
            "h\n",
            "zt\n",
            "relattn\n",
            "h\n",
            "zt\n",
            "h\n",
            "h\n",
            "h\n",
            "z\n",
            "h\n",
            "zt\n",
            "layernorm\n",
            "h\n",
            "zt\n",
            "posff\n",
            "h\n",
            "zt\n",
            "g\n",
            "zt\n",
            "layernorm\n",
            "g\n",
            "zt\n",
            "relattn\n",
            "g\n",
            "zt\n",
            "h\n",
            "h\n",
            "h\n",
            "z\n",
            "g\n",
            "zt\n",
            "layernorm\n",
            "g\n",
            "zt\n",
            "posff\n",
            "g\n",
            "zt\n",
            "target\n",
            "aware\n",
            "prediction\n",
            "distribution\n",
            "p\n",
            "xzt\n",
            "x\n",
            "xz\n",
            "exp\n",
            "e\n",
            "x\n",
            "g\n",
            "zt\n",
            "p\n",
            "x\n",
            "exp\n",
            "e\n",
            "x\n",
            "g\n",
            "zt\n",
            "datasets\n",
            "race\n",
            "dataset\n",
            "race\n",
            "dataset\n",
            "contains\n",
            "near\n",
            "k\n",
            "question\n",
            "taken\n",
            "english\n",
            "exam\n",
            "middle\n",
            "high\n",
            "school\n",
            "chinese\n",
            "student\n",
            "age\n",
            "range\n",
            "answer\n",
            "generated\n",
            "human\n",
            "expert\n",
            "one\n",
            "difficult\n",
            "reading\n",
            "comprehension\n",
            "datasets\n",
            "involve\n",
            "challenging\n",
            "reasoning\n",
            "question\n",
            "moreover\n",
            "average\n",
            "length\n",
            "passage\n",
            "race\n",
            "longer\n",
            "significantly\n",
            "longer\n",
            "popular\n",
            "reading\n",
            "comprehension\n",
            "datasets\n",
            "squad\n",
            "result\n",
            "dataset\n",
            "serf\n",
            "challenging\n",
            "benchmark\n",
            "long\n",
            "text\n",
            "understanding\n",
            "use\n",
            "sequence\n",
            "length\n",
            "finetuning\n",
            "squad\n",
            "squad\n",
            "large\n",
            "scale\n",
            "reading\n",
            "comprehension\n",
            "dataset\n",
            "two\n",
            "task\n",
            "squad\n",
            "contains\n",
            "question\n",
            "always\n",
            "corresponding\n",
            "answer\n",
            "given\n",
            "passage\n",
            "squad\n",
            "introduces\n",
            "unanswerable\n",
            "question\n",
            "finetune\n",
            "xlnet\n",
            "squad\n",
            "jointly\n",
            "apply\n",
            "logistic\n",
            "regression\n",
            "loss\n",
            "answerability\n",
            "prediction\n",
            "similar\n",
            "classification\n",
            "task\n",
            "standard\n",
            "span\n",
            "extraction\n",
            "loss\n",
            "question\n",
            "answering\n",
            "text\n",
            "classification\n",
            "datasets\n",
            "following\n",
            "previous\n",
            "work\n",
            "text\n",
            "classification\n",
            "evaluate\n",
            "xlnet\n",
            "following\n",
            "benchmark\n",
            "imdb\n",
            "yelp\n",
            "yelp\n",
            "dbpedia\n",
            "ag\n",
            "amazon\n",
            "amazon\n",
            "glue\n",
            "dataset\n",
            "glue\n",
            "dataset\n",
            "collection\n",
            "natural\n",
            "language\n",
            "understanding\n",
            "task\n",
            "test\n",
            "set\n",
            "label\n",
            "removed\n",
            "publicly\n",
            "released\n",
            "version\n",
            "practitioner\n",
            "must\n",
            "submit\n",
            "prediction\n",
            "evaluation\n",
            "server\n",
            "obtain\n",
            "test\n",
            "set\n",
            "result\n",
            "table\n",
            "present\n",
            "result\n",
            "multiple\n",
            "setting\n",
            "including\n",
            "single\n",
            "task\n",
            "multi\n",
            "task\n",
            "well\n",
            "single\n",
            "model\n",
            "ensemble\n",
            "multi\n",
            "task\n",
            "setting\n",
            "jointly\n",
            "train\n",
            "xlnet\n",
            "four\n",
            "largest\n",
            "datasets\n",
            "mnli\n",
            "sst\n",
            "qnli\n",
            "qqp\n",
            "finetune\n",
            "network\n",
            "datasets\n",
            "single\n",
            "task\n",
            "training\n",
            "employed\n",
            "four\n",
            "large\n",
            "datasets\n",
            "qnli\n",
            "employed\n",
            "pairwise\n",
            "relevance\n",
            "ranking\n",
            "scheme\n",
            "test\n",
            "set\n",
            "submission\n",
            "however\n",
            "fair\n",
            "comparison\n",
            "bert\n",
            "result\n",
            "qnli\n",
            "dev\n",
            "set\n",
            "based\n",
            "standard\n",
            "classification\n",
            "paradigm\n",
            "wnli\n",
            "use\n",
            "loss\n",
            "described\n",
            "clueweb\n",
            "b\n",
            "dataset\n",
            "following\n",
            "setting\n",
            "previous\n",
            "work\n",
            "use\n",
            "clueweb\n",
            "b\n",
            "dataset\n",
            "evaluate\n",
            "performance\n",
            "document\n",
            "ranking\n",
            "query\n",
            "created\n",
            "trec\n",
            "web\n",
            "track\n",
            "based\n",
            "document\n",
            "task\n",
            "rerank\n",
            "top\n",
            "document\n",
            "retrieved\n",
            "using\n",
            "standard\n",
            "retrieval\n",
            "method\n",
            "since\n",
            "document\n",
            "ranking\n",
            "ad\n",
            "hoc\n",
            "retrieval\n",
            "mainly\n",
            "concern\n",
            "low\n",
            "level\n",
            "representation\n",
            "instead\n",
            "high\n",
            "level\n",
            "semantics\n",
            "dataset\n",
            "serf\n",
            "testbed\n",
            "evaluating\n",
            "quality\n",
            "word\n",
            "embeddings\n",
            "use\n",
            "pretrained\n",
            "xlnet\n",
            "extract\n",
            "word\n",
            "embeddings\n",
            "document\n",
            "query\n",
            "without\n",
            "finetuning\n",
            "employ\n",
            "kernel\n",
            "pooling\n",
            "network\n",
            "rank\n",
            "document\n",
            "hyperparameters\n",
            "pretraining\n",
            "hyperparameters\n",
            "hparam\n",
            "value\n",
            "number\n",
            "layer\n",
            "hidden\n",
            "size\n",
            "number\n",
            "attention\n",
            "head\n",
            "attention\n",
            "head\n",
            "size\n",
            "ffn\n",
            "inner\n",
            "hidden\n",
            "size\n",
            "hidden\n",
            "dropout\n",
            "gelu\n",
            "dropout\n",
            "attention\n",
            "dropout\n",
            "partial\n",
            "prediction\n",
            "k\n",
            "max\n",
            "sequence\n",
            "length\n",
            "batch\n",
            "size\n",
            "learning\n",
            "rate\n",
            "e\n",
            "number\n",
            "step\n",
            "k\n",
            "warmup\n",
            "step\n",
            "learning\n",
            "rate\n",
            "decay\n",
            "linear\n",
            "adam\n",
            "epsilon\n",
            "e\n",
            "weight\n",
            "decay\n",
            "table\n",
            "hyperparameters\n",
            "pretraining\n",
            "hyperparameters\n",
            "used\n",
            "pretraining\n",
            "xlnet\n",
            "shown\n",
            "table\n",
            "hyperparameters\n",
            "finetuning\n",
            "hyperparameters\n",
            "used\n",
            "finetuning\n",
            "xlnet\n",
            "various\n",
            "task\n",
            "shown\n",
            "table\n",
            "layer\n",
            "wise\n",
            "decay\n",
            "mean\n",
            "exponentially\n",
            "decaying\n",
            "learning\n",
            "rate\n",
            "individual\n",
            "layer\n",
            "top\n",
            "manner\n",
            "example\n",
            "suppose\n",
            "th\n",
            "layer\n",
            "us\n",
            "learning\n",
            "rate\n",
            "l\n",
            "layer\n",
            "wise\n",
            "decay\n",
            "rate\n",
            "learning\n",
            "rate\n",
            "layer\n",
            "l\n",
            "hparam\n",
            "race\n",
            "squad\n",
            "mnli\n",
            "yelp\n",
            "dropout\n",
            "attention\n",
            "dropout\n",
            "max\n",
            "sequence\n",
            "length\n",
            "batch\n",
            "size\n",
            "learning\n",
            "rate\n",
            "e\n",
            "e\n",
            "e\n",
            "e\n",
            "number\n",
            "step\n",
            "k\n",
            "k\n",
            "k\n",
            "k\n",
            "learning\n",
            "rate\n",
            "decay\n",
            "linear\n",
            "weight\n",
            "decay\n",
            "adam\n",
            "epsilon\n",
            "e\n",
            "e\n",
            "e\n",
            "e\n",
            "layer\n",
            "wise\n",
            "lr\n",
            "decay\n",
            "table\n",
            "hyperparameters\n",
            "finetuning\n",
            "discussion\n",
            "analysis\n",
            "comparison\n",
            "bert\n",
            "prove\n",
            "general\n",
            "point\n",
            "beyond\n",
            "one\n",
            "example\n",
            "turn\n",
            "formal\n",
            "expression\n",
            "inspired\n",
            "previous\n",
            "work\n",
            "given\n",
            "sequence\n",
            "x\n",
            "x\n",
            "xt\n",
            "define\n",
            "set\n",
            "target\n",
            "context\n",
            "pair\n",
            "interest\n",
            "x\n",
            "u\n",
            "u\n",
            "set\n",
            "token\n",
            "x\n",
            "form\n",
            "context\n",
            "x\n",
            "intuitively\n",
            "want\n",
            "model\n",
            "learn\n",
            "dependency\n",
            "x\n",
            "u\n",
            "pretraining\n",
            "loss\n",
            "term\n",
            "log\n",
            "p\n",
            "x\n",
            "u\n",
            "example\n",
            "given\n",
            "sentence\n",
            "pair\n",
            "interest\n",
            "could\n",
            "instantiated\n",
            "n\n",
            "x\n",
            "york\n",
            "u\n",
            "new\n",
            "x\n",
            "york\n",
            "u\n",
            "city\n",
            "x\n",
            "york\n",
            "u\n",
            "new\n",
            "city\n",
            "note\n",
            "merely\n",
            "virtual\n",
            "notion\n",
            "without\n",
            "unique\n",
            "ground\n",
            "truth\n",
            "analysis\n",
            "hold\n",
            "regardless\n",
            "instantiated\n",
            "given\n",
            "set\n",
            "target\n",
            "token\n",
            "set\n",
            "non\n",
            "target\n",
            "token\n",
            "n\n",
            "x\n",
            "bert\n",
            "xlnet\n",
            "maximize\n",
            "log\n",
            "p\n",
            "n\n",
            "different\n",
            "formulation\n",
            "jbert\n",
            "x\n",
            "x\n",
            "log\n",
            "p\n",
            "x\n",
            "n\n",
            "jxlnet\n",
            "x\n",
            "x\n",
            "log\n",
            "p\n",
            "x\n",
            "n\n",
            "x\n",
            "x\n",
            "denote\n",
            "token\n",
            "factorization\n",
            "order\n",
            "prior\n",
            "x\n",
            "objective\n",
            "consist\n",
            "multiple\n",
            "loss\n",
            "term\n",
            "form\n",
            "log\n",
            "p\n",
            "x\n",
            "vx\n",
            "intuitively\n",
            "exists\n",
            "target\n",
            "context\n",
            "pair\n",
            "x\n",
            "u\n",
            "u\n",
            "vx\n",
            "loss\n",
            "term\n",
            "log\n",
            "p\n",
            "x\n",
            "vx\n",
            "provides\n",
            "training\n",
            "signal\n",
            "dependency\n",
            "x\n",
            "u\n",
            "convenience\n",
            "say\n",
            "target\n",
            "context\n",
            "pair\n",
            "x\n",
            "u\n",
            "covered\n",
            "model\n",
            "objective\n",
            "u\n",
            "vx\n",
            "given\n",
            "definition\n",
            "let\n",
            "consider\n",
            "two\n",
            "case\n",
            "u\n",
            "n\n",
            "dependency\n",
            "x\n",
            "u\n",
            "covered\n",
            "bert\n",
            "xlnet\n",
            "u\n",
            "n\n",
            "x\n",
            "u\n",
            "x\n",
            "dependency\n",
            "covered\n",
            "xlnet\n",
            "bert\n",
            "result\n",
            "xlnet\n",
            "able\n",
            "cover\n",
            "dependency\n",
            "bert\n",
            "word\n",
            "xlnet\n",
            "objective\n",
            "contains\n",
            "effective\n",
            "training\n",
            "signal\n",
            "empirically\n",
            "lead\n",
            "better\n",
            "performance\n",
            "section\n",
            "comparison\n",
            "language\n",
            "modeling\n",
            "borrowing\n",
            "example\n",
            "notation\n",
            "section\n",
            "standard\n",
            "ar\n",
            "language\n",
            "model\n",
            "like\n",
            "gpt\n",
            "able\n",
            "cover\n",
            "dependency\n",
            "x\n",
            "york\n",
            "u\n",
            "new\n",
            "x\n",
            "new\n",
            "u\n",
            "york\n",
            "xlnet\n",
            "hand\n",
            "able\n",
            "cover\n",
            "expectation\n",
            "factorization\n",
            "order\n",
            "limitation\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "critical\n",
            "real\n",
            "world\n",
            "application\n",
            "example\n",
            "consider\n",
            "span\n",
            "extraction\n",
            "question\n",
            "answering\n",
            "task\n",
            "context\n",
            "thom\n",
            "yorke\n",
            "singer\n",
            "radiohead\n",
            "question\n",
            "singer\n",
            "radiohead\n",
            "representation\n",
            "thom\n",
            "yorke\n",
            "dependent\n",
            "radiohead\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "thus\n",
            "chosen\n",
            "answer\n",
            "standard\n",
            "approach\n",
            "employ\n",
            "softmax\n",
            "token\n",
            "representation\n",
            "formally\n",
            "consider\n",
            "context\n",
            "target\n",
            "pair\n",
            "x\n",
            "u\n",
            "u\n",
            "x\n",
            "x\n",
            "denotes\n",
            "token\n",
            "prior\n",
            "x\n",
            "original\n",
            "sequence\n",
            "ar\n",
            "language\n",
            "modeling\n",
            "able\n",
            "cover\n",
            "dependency\n",
            "comparison\n",
            "xlnet\n",
            "able\n",
            "cover\n",
            "dependency\n",
            "expectation\n",
            "approach\n",
            "like\n",
            "elmo\n",
            "concatenate\n",
            "forward\n",
            "backward\n",
            "language\n",
            "model\n",
            "shallow\n",
            "manner\n",
            "sufficient\n",
            "modeling\n",
            "deep\n",
            "interaction\n",
            "two\n",
            "direction\n",
            "bridging\n",
            "gap\n",
            "language\n",
            "modeling\n",
            "pretraining\n",
            "deep\n",
            "root\n",
            "density\n",
            "estimation\n",
            "language\n",
            "modeling\n",
            "rapidly\n",
            "developing\n",
            "research\n",
            "area\n",
            "however\n",
            "gap\n",
            "language\n",
            "modeling\n",
            "pretraining\n",
            "due\n",
            "lack\n",
            "capability\n",
            "bidirectional\n",
            "context\n",
            "modeling\n",
            "analyzed\n",
            "section\n",
            "even\n",
            "challenged\n",
            "machine\n",
            "learning\n",
            "practitioner\n",
            "whether\n",
            "language\n",
            "modeling\n",
            "meaningful\n",
            "pursuit\n",
            "directly\n",
            "improve\n",
            "downstream\n",
            "task\n",
            "xlnet\n",
            "generalizes\n",
            "language\n",
            "modeling\n",
            "bridge\n",
            "gap\n",
            "result\n",
            "justifies\n",
            "language\n",
            "modeling\n",
            "research\n",
            "moreover\n",
            "becomes\n",
            "possible\n",
            "leverage\n",
            "rapid\n",
            "progress\n",
            "language\n",
            "modeling\n",
            "research\n",
            "pretraining\n",
            "example\n",
            "integrate\n",
            "transformer\n",
            "xl\n",
            "xlnet\n",
            "demonstrate\n",
            "usefulness\n",
            "latest\n",
            "language\n",
            "modeling\n",
            "progress\n",
            "qualitative\n",
            "analysis\n",
            "attention\n",
            "pattern\n",
            "compare\n",
            "attention\n",
            "pattern\n",
            "bert\n",
            "xlnet\n",
            "without\n",
            "finetuning\n",
            "firstly\n",
            "found\n",
            "typical\n",
            "pattern\n",
            "shared\n",
            "shown\n",
            "fig\n",
            "content\n",
            "stripe\n",
            "b\n",
            "local\n",
            "self\n",
            "focus\n",
            "c\n",
            "two\n",
            "segment\n",
            "content\n",
            "based\n",
            "symmetry\n",
            "figure\n",
            "attention\n",
            "pattern\n",
            "shared\n",
            "xlnet\n",
            "bert\n",
            "row\n",
            "column\n",
            "represent\n",
            "query\n",
            "key\n",
            "respectively\n",
            "interestingly\n",
            "fig\n",
            "present\n",
            "pattern\n",
            "appear\n",
            "xlnet\n",
            "bert\n",
            "self\n",
            "exclusion\n",
            "pattern\n",
            "attends\n",
            "token\n",
            "probably\n",
            "offering\n",
            "fast\n",
            "way\n",
            "gather\n",
            "global\n",
            "information\n",
            "b\n",
            "relative\n",
            "stride\n",
            "pattern\n",
            "attends\n",
            "position\n",
            "every\n",
            "stride\n",
            "apart\n",
            "relative\n",
            "query\n",
            "position\n",
            "c\n",
            "one\n",
            "side\n",
            "masked\n",
            "pattern\n",
            "similar\n",
            "lower\n",
            "left\n",
            "part\n",
            "fig\n",
            "upper\n",
            "right\n",
            "triangle\n",
            "masked\n",
            "seems\n",
            "model\n",
            "learns\n",
            "attend\n",
            "relative\n",
            "right\n",
            "half\n",
            "note\n",
            "three\n",
            "unique\n",
            "pattern\n",
            "involve\n",
            "relative\n",
            "position\n",
            "rather\n",
            "absolute\n",
            "one\n",
            "hence\n",
            "likely\n",
            "enabled\n",
            "relative\n",
            "attention\n",
            "mechanism\n",
            "xlnet\n",
            "conjecture\n",
            "unique\n",
            "pattern\n",
            "contribute\n",
            "performance\n",
            "advantage\n",
            "xlnet\n",
            "hand\n",
            "proposed\n",
            "permutation\n",
            "lm\n",
            "objective\n",
            "mostly\n",
            "contributes\n",
            "better\n",
            "data\n",
            "efficiency\n",
            "whose\n",
            "effect\n",
            "may\n",
            "obvious\n",
            "qualitative\n",
            "visualization\n",
            "self\n",
            "exclusion\n",
            "b\n",
            "relative\n",
            "stride\n",
            "c\n",
            "one\n",
            "side\n",
            "masked\n",
            "figure\n",
            "attention\n",
            "pattern\n",
            "appear\n",
            "xlnet\n",
            "row\n",
            "column\n",
            "represent\n",
            "query\n",
            "key\n",
            "respectively\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "factorization\n",
            "order\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "factorization\n",
            "order\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "factorization\n",
            "order\n",
            "h\n",
            "h\n",
            "h\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "factorization\n",
            "order\n",
            "mem\n",
            "mem\n",
            "mem\n",
            "mem\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "figure\n",
            "illustration\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "predicting\n",
            "x\n",
            "given\n",
            "input\n",
            "sequence\n",
            "x\n",
            "different\n",
            "factorization\n",
            "order\n",
            "visualizing\n",
            "memory\n",
            "permutation\n",
            "section\n",
            "provide\n",
            "detailed\n",
            "visualization\n",
            "proposed\n",
            "permutation\n",
            "language\n",
            "modeling\n",
            "objective\n",
            "including\n",
            "mechanism\n",
            "reusing\n",
            "memory\n",
            "aka\n",
            "recurrence\n",
            "mechanism\n",
            "use\n",
            "attention\n",
            "mask\n",
            "permute\n",
            "factorization\n",
            "order\n",
            "difference\n",
            "two\n",
            "attention\n",
            "stream\n",
            "shown\n",
            "figure\n",
            "given\n",
            "current\n",
            "position\n",
            "zt\n",
            "attention\n",
            "mask\n",
            "decided\n",
            "permutation\n",
            "factorization\n",
            "order\n",
            "z\n",
            "token\n",
            "occur\n",
            "zt\n",
            "permutation\n",
            "attended\n",
            "e\n",
            "position\n",
            "zi\n",
            "moreover\n",
            "comparing\n",
            "figure\n",
            "see\n",
            "query\n",
            "stream\n",
            "content\n",
            "stream\n",
            "work\n",
            "differently\n",
            "specific\n",
            "permutation\n",
            "attention\n",
            "mask\n",
            "main\n",
            "difference\n",
            "query\n",
            "stream\n",
            "self\n",
            "attention\n",
            "access\n",
            "token\n",
            "position\n",
            "content\n",
            "stream\n",
            "performs\n",
            "normal\n",
            "self\n",
            "attention\n",
            "problem\n",
            "language\n",
            "modeling\n",
            "essentially\n",
            "density\n",
            "estimation\n",
            "text\n",
            "data\n",
            "http\n",
            "openreview\n",
            "net\n",
            "forum\n",
            "id\n",
            "hjepno\n",
            "cym\n",
            "position\n",
            "view\n",
            "position\n",
            "view\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "h\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "position\n",
            "view\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "position\n",
            "view\n",
            "split\n",
            "view\n",
            "content\n",
            "stream\n",
            "factorization\n",
            "order\n",
            "joint\n",
            "view\n",
            "content\n",
            "stream\n",
            "factorization\n",
            "order\n",
            "mem\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "split\n",
            "view\n",
            "figure\n",
            "detailed\n",
            "illustration\n",
            "content\n",
            "stream\n",
            "proposed\n",
            "objective\n",
            "joint\n",
            "view\n",
            "split\n",
            "view\n",
            "based\n",
            "length\n",
            "sequence\n",
            "factorization\n",
            "order\n",
            "note\n",
            "ignore\n",
            "query\n",
            "representation\n",
            "computation\n",
            "figure\n",
            "simply\n",
            "standard\n",
            "self\n",
            "attention\n",
            "though\n",
            "particular\n",
            "attention\n",
            "mask\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "h\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "w\n",
            "w\n",
            "w\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "mem\n",
            "x\n",
            "x\n",
            "x\n",
            "x\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "position\n",
            "view\n",
            "position\n",
            "view\n",
            "position\n",
            "view\n",
            "position\n",
            "view\n",
            "split\n",
            "view\n",
            "query\n",
            "stream\n",
            "factorization\n",
            "order\n",
            "split\n",
            "view\n",
            "mem\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "x\n",
            "w\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "mem\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "g\n",
            "g\n",
            "g\n",
            "g\n",
            "h\n",
            "h\n",
            "h\n",
            "h\n",
            "joint\n",
            "view\n",
            "query\n",
            "stream\n",
            "factorization\n",
            "order\n",
            "figure\n",
            "detailed\n",
            "illustration\n",
            "query\n",
            "stream\n",
            "proposed\n",
            "objective\n",
            "joint\n",
            "view\n",
            "split\n",
            "view\n",
            "based\n",
            "length\n",
            "sequence\n",
            "factorization\n",
            "order\n",
            "dash\n",
            "arrow\n",
            "indicate\n",
            "query\n",
            "stream\n",
            "access\n",
            "token\n",
            "content\n",
            "position\n",
            "location\n",
            "information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "   review = re.sub('[^a-zA-Z]',\" \",sentences[i])\n",
        "   review = review.lower()\n",
        "   review = review.split()\n",
        "   review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words(\"english\"))]\n",
        "   review = \" \".join(review)\n",
        "   corpus.append(review)\n"
      ],
      "metadata": {
        "id": "tCB-BZapag74"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.nist_score import ngrams\n",
        "#for bag of words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(binary=True,ngram_range=(3,3))"
      ],
      "metadata": {
        "id": "OlUw9jtgcB_3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "6aVnZxDqcCWX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_ #feature number or index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zc4FfYHcGAH",
        "outputId": "f8982caa-885a-4a0a-b7be-d97b4d745d00"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'xlnet generalized autoregressive': 3593,\n",
              " 'generalized autoregressive pretraining': 1175,\n",
              " 'autoregressive pretraining language': 245,\n",
              " 'pretraining language understanding': 2405,\n",
              " 'language understanding zhilin': 1551,\n",
              " 'understanding zhilin yang': 3372,\n",
              " 'zhilin yang zihang': 3722,\n",
              " 'yang zihang dai': 3677,\n",
              " 'zihang dai yiming': 3734,\n",
              " 'dai yiming yang': 691,\n",
              " 'yiming yang jaime': 3686,\n",
              " 'yang jaime carbonell': 3674,\n",
              " 'jaime carbonell ruslan': 1445,\n",
              " 'carbonell ruslan salakhutdinov': 430,\n",
              " 'ruslan salakhutdinov quoc': 2752,\n",
              " 'salakhutdinov quoc le': 2757,\n",
              " 'quoc le carnegie': 2538,\n",
              " 'le carnegie mellon': 1587,\n",
              " 'carnegie mellon university': 432,\n",
              " 'mellon university google': 1789,\n",
              " 'university google ai': 3380,\n",
              " 'google ai brain': 1209,\n",
              " 'ai brain team': 64,\n",
              " 'brain team zhiliny': 406,\n",
              " 'team zhiliny dzihang': 3188,\n",
              " 'zhiliny dzihang yiming': 3723,\n",
              " 'dzihang yiming jgc': 879,\n",
              " 'yiming jgc rsalakhu': 3684,\n",
              " 'jgc rsalakhu cmu': 1455,\n",
              " 'rsalakhu cmu edu': 2744,\n",
              " 'cmu edu qvl': 492,\n",
              " 'edu qvl google': 881,\n",
              " 'qvl google com': 2540,\n",
              " 'google com abstract': 1210,\n",
              " 'com abstract capability': 500,\n",
              " 'abstract capability modeling': 18,\n",
              " 'capability modeling bidirectional': 425,\n",
              " 'modeling bidirectional context': 1896,\n",
              " 'bidirectional context denoising': 387,\n",
              " 'context denoising autoencoding': 616,\n",
              " 'denoising autoencoding based': 760,\n",
              " 'autoencoding based pretraining': 236,\n",
              " 'based pretraining like': 289,\n",
              " 'pretraining like bert': 2406,\n",
              " 'like bert achieves': 1641,\n",
              " 'bert achieves better': 309,\n",
              " 'achieves better performance': 28,\n",
              " 'better performance pretraining': 379,\n",
              " 'performance pretraining approach': 2255,\n",
              " 'pretraining approach based': 2395,\n",
              " 'approach based autoregressive': 140,\n",
              " 'based autoregressive language': 275,\n",
              " 'autoregressive language modeling': 241,\n",
              " 'however relying corrupting': 1277,\n",
              " 'relying corrupting input': 2629,\n",
              " 'corrupting input mask': 661,\n",
              " 'input mask bert': 1395,\n",
              " 'mask bert neglect': 1741,\n",
              " 'bert neglect dependency': 335,\n",
              " 'neglect dependency masked': 1994,\n",
              " 'dependency masked position': 781,\n",
              " 'masked position suffers': 1755,\n",
              " 'position suffers pretrain': 2319,\n",
              " 'suffers pretrain finetune': 3104,\n",
              " 'pretrain finetune discrepancy': 2386,\n",
              " 'light pro con': 1640,\n",
              " 'pro con propose': 2430,\n",
              " 'con propose xlnet': 548,\n",
              " 'propose xlnet generalized': 2468,\n",
              " 'autoregressive pretraining method': 246,\n",
              " 'pretraining method enables': 2409,\n",
              " 'method enables learning': 1812,\n",
              " 'enables learning bidirectional': 917,\n",
              " 'learning bidirectional context': 1603,\n",
              " 'bidirectional context maximizing': 389,\n",
              " 'context maximizing expected': 620,\n",
              " 'maximizing expected likelihood': 1774,\n",
              " 'expected likelihood permutation': 1005,\n",
              " 'likelihood permutation factorization': 1653,\n",
              " 'permutation factorization order': 2265,\n",
              " 'factorization order overcomes': 1037,\n",
              " 'order overcomes limitation': 2156,\n",
              " 'overcomes limitation bert': 2189,\n",
              " 'limitation bert thanks': 1657,\n",
              " 'bert thanks autoregressive': 355,\n",
              " 'thanks autoregressive formulation': 3225,\n",
              " 'furthermore xlnet integrates': 1157,\n",
              " 'xlnet integrates idea': 3599,\n",
              " 'integrates idea transformer': 1418,\n",
              " 'idea transformer xl': 1312,\n",
              " 'transformer xl state': 3321,\n",
              " 'xl state art': 3573,\n",
              " 'state art autoregressive': 3037,\n",
              " 'art autoregressive model': 167,\n",
              " 'autoregressive model pretraining': 243,\n",
              " 'empirically comparable experiment': 906,\n",
              " 'comparable experiment setting': 509,\n",
              " 'experiment setting xlnet': 1009,\n",
              " 'setting xlnet outperforms': 2903,\n",
              " 'xlnet outperforms bert': 3613,\n",
              " 'outperforms bert task': 2186,\n",
              " 'bert task often': 354,\n",
              " 'task often large': 3175,\n",
              " 'often large margin': 2116,\n",
              " 'large margin including': 1555,\n",
              " 'margin including question': 1735,\n",
              " 'including question answering': 1355,\n",
              " 'question answering natural': 2530,\n",
              " 'answering natural language': 128,\n",
              " 'natural language inference': 1979,\n",
              " 'language inference sentiment': 1508,\n",
              " 'inference sentiment analysis': 1377,\n",
              " 'sentiment analysis document': 2851,\n",
              " 'analysis document ranking': 115,\n",
              " 'introduction unsupervised representation': 1432,\n",
              " 'unsupervised representation learning': 3386,\n",
              " 'representation learning highly': 2652,\n",
              " 'learning highly successful': 1604,\n",
              " 'highly successful domain': 1262,\n",
              " 'successful domain natural': 3101,\n",
              " 'domain natural language': 862,\n",
              " 'natural language processing': 1980,\n",
              " 'typically method first': 3360,\n",
              " 'method first pretrain': 1813,\n",
              " 'first pretrain neural': 1101,\n",
              " 'pretrain neural network': 2387,\n",
              " 'neural network large': 2014,\n",
              " 'network large scale': 1996,\n",
              " 'large scale unlabeled': 1558,\n",
              " 'scale unlabeled text': 2769,\n",
              " 'unlabeled text corpus': 3381,\n",
              " 'text corpus finetune': 3210,\n",
              " 'corpus finetune model': 656,\n",
              " 'finetune model representation': 1086,\n",
              " 'model representation downstream': 1872,\n",
              " 'representation downstream task': 2646,\n",
              " 'shared high level': 2910,\n",
              " 'high level idea': 1254,\n",
              " 'level idea different': 1631,\n",
              " 'idea different unsupervised': 1303,\n",
              " 'different unsupervised pretraining': 824,\n",
              " 'unsupervised pretraining objective': 3385,\n",
              " 'pretraining objective explored': 2413,\n",
              " 'objective explored literature': 2075,\n",
              " 'among autoregressive ar': 108,\n",
              " 'autoregressive ar language': 237,\n",
              " 'ar language modeling': 147,\n",
              " 'language modeling autoencoding': 1521,\n",
              " 'modeling autoencoding ae': 1893,\n",
              " 'autoencoding ae two': 235,\n",
              " 'ae two successful': 59,\n",
              " 'two successful pretraining': 3356,\n",
              " 'successful pretraining objective': 3102,\n",
              " 'language modeling seek': 1539,\n",
              " 'modeling seek estimate': 1927,\n",
              " 'seek estimate probability': 2804,\n",
              " 'estimate probability distribution': 953,\n",
              " 'probability distribution text': 2433,\n",
              " 'distribution text corpus': 849,\n",
              " 'text corpus autoregressive': 3209,\n",
              " 'corpus autoregressive model': 655,\n",
              " 'specifically given text': 2988,\n",
              " 'given text sequence': 1199,\n",
              " 'text sequence xt': 3217,\n",
              " 'sequence xt ar': 2874,\n",
              " 'xt ar language': 3636,\n",
              " 'language modeling factorizes': 1529,\n",
              " 'modeling factorizes likelihood': 1906,\n",
              " 'factorizes likelihood forward': 1046,\n",
              " 'likelihood forward product': 1652,\n",
              " 'forward product qt': 1143,\n",
              " 'product qt xt': 2455,\n",
              " 'qt xt backward': 2505,\n",
              " 'xt backward one': 3637,\n",
              " 'backward one xt': 264,\n",
              " 'neural network trained': 2018,\n",
              " 'network trained model': 2006,\n",
              " 'trained model conditional': 3287,\n",
              " 'model conditional distribution': 1845,\n",
              " 'since ar language': 2944,\n",
              " 'ar language model': 146,\n",
              " 'language model trained': 1515,\n",
              " 'model trained encode': 1881,\n",
              " 'trained encode uni': 3286,\n",
              " 'encode uni directional': 920,\n",
              " 'uni directional context': 3374,\n",
              " 'directional context either': 834,\n",
              " 'context either forward': 618,\n",
              " 'either forward backward': 891,\n",
              " 'forward backward effective': 1139,\n",
              " 'backward effective modeling': 261,\n",
              " 'effective modeling deep': 885,\n",
              " 'modeling deep bidirectional': 1900,\n",
              " 'deep bidirectional context': 746,\n",
              " 'contrary downstream language': 642,\n",
              " 'downstream language understanding': 863,\n",
              " 'language understanding task': 1549,\n",
              " 'understanding task often': 3369,\n",
              " 'task often require': 3176,\n",
              " 'often require bidirectional': 2117,\n",
              " 'require bidirectional context': 2669,\n",
              " 'bidirectional context information': 388,\n",
              " 'result gap ar': 2682,\n",
              " 'gap ar language': 1159,\n",
              " 'language modeling effective': 1527,\n",
              " 'modeling effective pretraining': 1903,\n",
              " 'comparison ae based': 518,\n",
              " 'ae based pretraining': 58,\n",
              " 'based pretraining perform': 290,\n",
              " 'pretraining perform explicit': 2417,\n",
              " 'perform explicit density': 2244,\n",
              " 'explicit density estimation': 1011,\n",
              " 'density estimation instead': 772,\n",
              " 'estimation instead aim': 955,\n",
              " 'instead aim reconstruct': 1411,\n",
              " 'aim reconstruct original': 70,\n",
              " 'reconstruct original data': 2591,\n",
              " 'original data corrupted': 2173,\n",
              " 'data corrupted input': 697,\n",
              " 'notable example bert': 2044,\n",
              " 'example bert state': 972,\n",
              " 'bert state art': 353,\n",
              " 'state art pretraining': 3039,\n",
              " 'art pretraining approach': 169,\n",
              " 'given input token': 1192,\n",
              " 'input token sequence': 1407,\n",
              " 'token sequence certain': 3265,\n",
              " 'sequence certain portion': 2857,\n",
              " 'certain portion token': 436,\n",
              " 'portion token replaced': 2298,\n",
              " 'token replaced special': 3262,\n",
              " 'replaced special symbol': 2636,\n",
              " 'special symbol mask': 2984,\n",
              " 'symbol mask model': 3121,\n",
              " 'mask model trained': 1744,\n",
              " 'model trained recover': 1882,\n",
              " 'trained recover original': 3288,\n",
              " 'recover original token': 2592,\n",
              " 'original token corrupted': 2178,\n",
              " 'token corrupted version': 3242,\n",
              " 'since density estimation': 2945,\n",
              " 'density estimation part': 774,\n",
              " 'estimation part objective': 957,\n",
              " 'part objective bert': 2220,\n",
              " 'objective bert allowed': 2067,\n",
              " 'bert allowed utilize': 311,\n",
              " 'allowed utilize equal': 82,\n",
              " 'utilize equal contribution': 3446,\n",
              " 'order determined swapping': 2147,\n",
              " 'determined swapping one': 801,\n",
              " 'pretrained model code': 2390,\n",
              " 'model code available': 1844,\n",
              " 'code available http': 494,\n",
              " 'available http github': 247,\n",
              " 'http github com': 1282,\n",
              " 'github com zihangdai': 1187,\n",
              " 'com zihangdai xlnet': 502,\n",
              " 'zihangdai xlnet rd': 3736,\n",
              " 'xlnet rd conference': 3616,\n",
              " 'rd conference neural': 2581,\n",
              " 'conference neural information': 564,\n",
              " 'neural information processing': 2011,\n",
              " 'information processing system': 1384,\n",
              " 'processing system neurips': 2451,\n",
              " 'system neurips vancouver': 3124,\n",
              " 'neurips vancouver canada': 2020,\n",
              " 'arxiv cl jan': 174,\n",
              " 'cl jan bidirectional': 469,\n",
              " 'jan bidirectional context': 1451,\n",
              " 'bidirectional context reconstruction': 391,\n",
              " 'immediate benefit close': 1324,\n",
              " 'benefit close aforementioned': 303,\n",
              " 'close aforementioned bidirectional': 483,\n",
              " 'aforementioned bidirectional information': 60,\n",
              " 'bidirectional information gap': 394,\n",
              " 'information gap ar': 1380,\n",
              " 'language modeling leading': 1530,\n",
              " 'modeling leading improved': 1908,\n",
              " 'leading improved performance': 1595,\n",
              " 'however artificial symbol': 1272,\n",
              " 'artificial symbol like': 173,\n",
              " 'symbol like mask': 3120,\n",
              " 'like mask used': 1646,\n",
              " 'mask used bert': 1749,\n",
              " 'used bert pretraining': 3422,\n",
              " 'bert pretraining absent': 339,\n",
              " 'pretraining absent real': 2393,\n",
              " 'absent real data': 14,\n",
              " 'real data finetuning': 2586,\n",
              " 'data finetuning time': 700,\n",
              " 'finetuning time resulting': 1094,\n",
              " 'time resulting pretrain': 3239,\n",
              " 'resulting pretrain finetune': 2703,\n",
              " 'moreover since predicted': 1940,\n",
              " 'since predicted token': 2950,\n",
              " 'predicted token masked': 2359,\n",
              " 'token masked input': 3253,\n",
              " 'masked input bert': 1753,\n",
              " 'input bert able': 1392,\n",
              " 'bert able model': 308,\n",
              " 'able model joint': 12,\n",
              " 'model joint probability': 1854,\n",
              " 'joint probability using': 1464,\n",
              " 'probability using product': 2436,\n",
              " 'using product rule': 3439,\n",
              " 'product rule ar': 2456,\n",
              " 'rule ar language': 2746,\n",
              " 'word bert assumes': 3526,\n",
              " 'bert assumes predicted': 312,\n",
              " 'assumes predicted token': 182,\n",
              " 'predicted token independent': 2358,\n",
              " 'token independent given': 3249,\n",
              " 'independent given unmasked': 1368,\n",
              " 'given unmasked token': 1200,\n",
              " 'unmasked token oversimplified': 3382,\n",
              " 'token oversimplified high': 3256,\n",
              " 'oversimplified high order': 2190,\n",
              " 'high order long': 1257,\n",
              " 'order long range': 2154,\n",
              " 'long range dependency': 1692,\n",
              " 'range dependency prevalent': 2564,\n",
              " 'dependency prevalent natural': 785,\n",
              " 'prevalent natural language': 2420,\n",
              " 'faced pro con': 1022,\n",
              " 'pro con existing': 2429,\n",
              " 'con existing language': 547,\n",
              " 'existing language pretraining': 989,\n",
              " 'language pretraining objective': 1545,\n",
              " 'pretraining objective work': 2415,\n",
              " 'objective work propose': 2096,\n",
              " 'work propose xlnet': 3537,\n",
              " 'generalized autoregressive method': 1174,\n",
              " 'autoregressive method leverage': 242,\n",
              " 'method leverage best': 1814,\n",
              " 'leverage best ar': 1635,\n",
              " 'best ar language': 373,\n",
              " 'language modeling ae': 1520,\n",
              " 'modeling ae avoiding': 1891,\n",
              " 'ae avoiding limitation': 57,\n",
              " 'firstly instead using': 1106,\n",
              " 'instead using fixed': 1414,\n",
              " 'using fixed forward': 3437,\n",
              " 'fixed forward backward': 1110,\n",
              " 'forward backward factorization': 1140,\n",
              " 'backward factorization order': 262,\n",
              " 'factorization order conventional': 1028,\n",
              " 'order conventional ar': 2146,\n",
              " 'conventional ar model': 650,\n",
              " 'ar model xlnet': 150,\n",
              " 'model xlnet maximizes': 1886,\n",
              " 'xlnet maximizes expected': 3608,\n",
              " 'maximizes expected log': 1773,\n",
              " 'expected log likelihood': 1006,\n",
              " 'log likelihood sequence': 1677,\n",
              " 'possible permutation factorization': 2342,\n",
              " 'thanks permutation operation': 3226,\n",
              " 'permutation operation context': 2271,\n",
              " 'operation context position': 2133,\n",
              " 'context position consist': 627,\n",
              " 'position consist token': 2306,\n",
              " 'consist token left': 581,\n",
              " 'token left right': 3251,\n",
              " 'expectation position learns': 1003,\n",
              " 'position learns utilize': 2311,\n",
              " 'learns utilize contextual': 1613,\n",
              " 'utilize contextual information': 3445,\n",
              " 'contextual information position': 635,\n",
              " 'information position capturing': 1382,\n",
              " 'position capturing bidirectional': 2304,\n",
              " 'capturing bidirectional context': 428,\n",
              " 'secondly generalized ar': 2784,\n",
              " 'generalized ar language': 1172,\n",
              " 'language model xlnet': 1517,\n",
              " 'model xlnet rely': 1888,\n",
              " 'xlnet rely data': 3617,\n",
              " 'rely data corruption': 2625,\n",
              " 'hence xlnet suffer': 1241,\n",
              " 'xlnet suffer pretrain': 3625,\n",
              " 'suffer pretrain finetune': 3103,\n",
              " 'finetune discrepancy bert': 1084,\n",
              " 'discrepancy bert subject': 837,\n",
              " 'meanwhile autoregressive objective': 1781,\n",
              " 'autoregressive objective also': 244,\n",
              " 'objective also provides': 2065,\n",
              " 'also provides natural': 95,\n",
              " 'provides natural way': 2483,\n",
              " 'natural way use': 1984,\n",
              " 'way use product': 3488,\n",
              " 'use product rule': 3413,\n",
              " 'product rule factorizing': 2457,\n",
              " 'rule factorizing joint': 2748,\n",
              " 'factorizing joint probability': 1048,\n",
              " 'joint probability predicted': 1463,\n",
              " 'probability predicted token': 2435,\n",
              " 'predicted token eliminating': 2357,\n",
              " 'token eliminating independence': 3245,\n",
              " 'eliminating independence assumption': 896,\n",
              " 'independence assumption made': 1365,\n",
              " 'assumption made bert': 185,\n",
              " 'addition novel pretraining': 48,\n",
              " 'novel pretraining objective': 2055,\n",
              " 'pretraining objective xlnet': 2416,\n",
              " 'objective xlnet improves': 2097,\n",
              " 'xlnet improves architectural': 3597,\n",
              " 'improves architectural design': 1344,\n",
              " 'architectural design pretraining': 156,\n",
              " 'inspired latest advancement': 1408,\n",
              " 'latest advancement ar': 1568,\n",
              " 'advancement ar language': 53,\n",
              " 'language modeling xlnet': 1544,\n",
              " 'modeling xlnet integrates': 1932,\n",
              " 'xlnet integrates segment': 3600,\n",
              " 'integrates segment recurrence': 1419,\n",
              " 'segment recurrence mechanism': 2821,\n",
              " 'recurrence mechanism relative': 2595,\n",
              " 'mechanism relative encoding': 1784,\n",
              " 'relative encoding scheme': 2609,\n",
              " 'encoding scheme transformer': 932,\n",
              " 'scheme transformer xl': 2774,\n",
              " 'transformer xl pretraining': 3319,\n",
              " 'xl pretraining empirically': 3570,\n",
              " 'pretraining empirically improves': 2399,\n",
              " 'empirically improves performance': 907,\n",
              " 'improves performance especially': 1345,\n",
              " 'performance especially task': 2253,\n",
              " 'especially task involving': 950,\n",
              " 'task involving longer': 3170,\n",
              " 'involving longer text': 1441,\n",
              " 'longer text sequence': 1699,\n",
              " 'naively applying transformer': 1973,\n",
              " 'applying transformer xl': 139,\n",
              " 'transformer xl architecture': 3310,\n",
              " 'xl architecture permutation': 3560,\n",
              " 'architecture permutation based': 160,\n",
              " 'permutation based language': 2263,\n",
              " 'based language modeling': 281,\n",
              " 'language modeling work': 1543,\n",
              " 'modeling work factorization': 1931,\n",
              " 'work factorization order': 3534,\n",
              " 'factorization order arbitrary': 1025,\n",
              " 'order arbitrary target': 2143,\n",
              " 'arbitrary target ambiguous': 155,\n",
              " 'solution propose reparameterize': 2977,\n",
              " 'propose reparameterize transformer': 2465,\n",
              " 'reparameterize transformer xl': 2635,\n",
              " 'transformer xl network': 3317,\n",
              " 'xl network remove': 3568,\n",
              " 'network remove ambiguity': 2001,\n",
              " 'setting xlnet consistently': 2902,\n",
              " 'xlnet consistently outperforms': 3585,\n",
              " 'consistently outperforms bert': 584,\n",
              " 'outperforms bert wide': 2187,\n",
              " 'bert wide spectrum': 360,\n",
              " 'wide spectrum problem': 3504,\n",
              " 'spectrum problem including': 2995,\n",
              " 'problem including glue': 2440,\n",
              " 'including glue language': 1351,\n",
              " 'glue language understanding': 1204,\n",
              " 'understanding task reading': 3370,\n",
              " 'task reading comprehension': 3177,\n",
              " 'reading comprehension task': 2585,\n",
              " 'comprehension task like': 539,\n",
              " 'task like squad': 3171,\n",
              " 'like squad race': 1647,\n",
              " 'squad race text': 3014,\n",
              " 'race text classification': 2551,\n",
              " 'text classification task': 3206,\n",
              " 'classification task yelp': 479,\n",
              " 'task yelp imdb': 3187,\n",
              " 'yelp imdb clueweb': 3682,\n",
              " 'imdb clueweb document': 1322,\n",
              " 'clueweb document ranking': 489,\n",
              " 'document ranking task': 857,\n",
              " 'related work idea': 2605,\n",
              " 'work idea permutation': 3536,\n",
              " 'idea permutation based': 1308,\n",
              " 'permutation based ar': 2262,\n",
              " 'based ar modeling': 274,\n",
              " 'ar modeling explored': 151,\n",
              " 'modeling explored several': 1905,\n",
              " 'explored several key': 1013,\n",
              " 'several key difference': 2905,\n",
              " 'firstly previous model': 1107,\n",
              " 'previous model aim': 2421,\n",
              " 'model aim improve': 1836,\n",
              " 'aim improve density': 69,\n",
              " 'improve density estimation': 1338,\n",
              " 'density estimation baking': 771,\n",
              " 'estimation baking orderless': 954,\n",
              " 'baking orderless inductive': 266,\n",
              " 'orderless inductive bias': 2165,\n",
              " 'inductive bias model': 1375,\n",
              " 'bias model xlnet': 385,\n",
              " 'model xlnet motivated': 1887,\n",
              " 'xlnet motivated enabling': 3610,\n",
              " 'motivated enabling ar': 1942,\n",
              " 'enabling ar language': 918,\n",
              " 'language model learn': 1511,\n",
              " 'model learn bidirectional': 1855,\n",
              " 'learn bidirectional context': 1596,\n",
              " 'technically construct valid': 3190,\n",
              " 'construct valid target': 589,\n",
              " 'valid target aware': 3449,\n",
              " 'target aware prediction': 3143,\n",
              " 'aware prediction distribution': 252,\n",
              " 'prediction distribution xlnet': 2366,\n",
              " 'distribution xlnet incorporates': 851,\n",
              " 'xlnet incorporates target': 3598,\n",
              " 'incorporates target position': 1359,\n",
              " 'target position hidden': 3151,\n",
              " 'position hidden state': 2310,\n",
              " 'hidden state via': 1252,\n",
              " 'state via two': 3042,\n",
              " 'via two stream': 3466,\n",
              " 'two stream attention': 3352,\n",
              " 'stream attention previous': 3053,\n",
              " 'attention previous permutation': 217,\n",
              " 'previous permutation based': 2422,\n",
              " 'based ar model': 273,\n",
              " 'ar model relied': 149,\n",
              " 'model relied implicit': 1871,\n",
              " 'relied implicit position': 2624,\n",
              " 'implicit position awareness': 1332,\n",
              " 'position awareness inherent': 2303,\n",
              " 'awareness inherent mlp': 257,\n",
              " 'inherent mlp architecture': 1388,\n",
              " 'finally orderless nade': 1077,\n",
              " 'orderless nade xlnet': 2168,\n",
              " 'nade xlnet would': 1970,\n",
              " 'xlnet would like': 3633,\n",
              " 'would like emphasize': 3542,\n",
              " 'like emphasize orderless': 1643,\n",
              " 'emphasize orderless mean': 904,\n",
              " 'orderless mean input': 2166,\n",
              " 'mean input sequence': 1779,\n",
              " 'input sequence randomly': 1406,\n",
              " 'sequence randomly permuted': 2869,\n",
              " 'randomly permuted model': 2559,\n",
              " 'permuted model allows': 2279,\n",
              " 'model allows different': 1837,\n",
              " 'allows different factorization': 84,\n",
              " 'different factorization order': 818,\n",
              " 'factorization order distribution': 1030,\n",
              " 'another related idea': 122,\n",
              " 'related idea perform': 2604,\n",
              " 'idea perform autoregressive': 1307,\n",
              " 'perform autoregressive denoising': 2243,\n",
              " 'autoregressive denoising context': 238,\n",
              " 'denoising context text': 761,\n",
              " 'context text generation': 631,\n",
              " 'text generation considers': 3211,\n",
              " 'generation considers fixed': 1179,\n",
              " 'considers fixed order': 579,\n",
              " 'fixed order though': 1112,\n",
              " 'proposed method background': 2469,\n",
              " 'method background section': 1811,\n",
              " 'background section first': 259,\n",
              " 'section first review': 2789,\n",
              " 'first review compare': 1102,\n",
              " 'review compare conventional': 2713,\n",
              " 'compare conventional ar': 512,\n",
              " 'conventional ar language': 649,\n",
              " 'language modeling bert': 1522,\n",
              " 'modeling bert language': 1894,\n",
              " 'bert language pretraining': 328,\n",
              " 'language modeling performs': 1533,\n",
              " 'modeling performs pretraining': 1920,\n",
              " 'performs pretraining maximizing': 2259,\n",
              " 'pretraining maximizing likelihood': 2408,\n",
              " 'maximizing likelihood forward': 1775,\n",
              " 'likelihood forward autoregressive': 1651,\n",
              " 'forward autoregressive factorization': 1137,\n",
              " 'autoregressive factorization max': 240,\n",
              " 'factorization max log': 1023,\n",
              " 'max log log': 1767,\n",
              " 'log log xt': 1679,\n",
              " 'log xt log': 1684,\n",
              " 'xt log exp': 3642,\n",
              " 'log exp xt': 1675,\n",
              " 'exp xt exp': 994,\n",
              " 'xt exp context': 3639,\n",
              " 'exp context representation': 992,\n",
              " 'context representation produced': 628,\n",
              " 'representation produced neural': 2655,\n",
              " 'produced neural model': 2453,\n",
              " 'neural model rnns': 2013,\n",
              " 'model rnns transformer': 1874,\n",
              " 'rnns transformer denotes': 2720,\n",
              " 'transformer denotes embedding': 3304,\n",
              " 'comparison bert based': 520,\n",
              " 'bert based denoising': 316,\n",
              " 'based denoising auto': 276,\n",
              " 'denoising auto encoding': 759,\n",
              " 'specifically text sequence': 2992,\n",
              " 'text sequence bert': 3213,\n",
              " 'sequence bert first': 2856,\n",
              " 'bert first construct': 326,\n",
              " 'first construct corrupted': 1097,\n",
              " 'construct corrupted version': 588,\n",
              " 'corrupted version randomly': 660,\n",
              " 'version randomly setting': 3463,\n",
              " 'randomly setting portion': 2562,\n",
              " 'token special symbol': 3268,\n",
              " 'let masked token': 1627,\n",
              " 'training objective reconstruct': 3296,\n",
              " 'objective reconstruct max': 2091,\n",
              " 'reconstruct max log': 2590,\n",
              " 'max log mt': 1768,\n",
              " 'log mt log': 1680,\n",
              " 'mt log xt': 1949,\n",
              " 'log xt mt': 1685,\n",
              " 'xt mt log': 3644,\n",
              " 'mt log exp': 1948,\n",
              " 'xt exp mt': 3640,\n",
              " 'exp mt indicates': 993,\n",
              " 'mt indicates xt': 1947,\n",
              " 'indicates xt masked': 1373,\n",
              " 'xt masked transformer': 3643,\n",
              " 'masked transformer map': 1757,\n",
              " 'transformer map length': 3306,\n",
              " 'map length text': 1732,\n",
              " 'length text sequence': 1624,\n",
              " 'text sequence sequence': 3216,\n",
              " 'sequence sequence hidden': 2873,\n",
              " 'sequence hidden vector': 2863,\n",
              " 'pro con two': 2431,\n",
              " 'con two pretraining': 549,\n",
              " 'two pretraining objective': 3343,\n",
              " 'pretraining objective compared': 2412,\n",
              " 'objective compared following': 2070,\n",
              " 'compared following aspect': 516,\n",
              " 'following aspect independence': 1116,\n",
              " 'aspect independence assumption': 179,\n",
              " 'independence assumption emphasized': 1364,\n",
              " 'assumption emphasized sign': 184,\n",
              " 'emphasized sign eq': 905,\n",
              " 'bert factorizes joint': 325,\n",
              " 'factorizes joint conditional': 1045,\n",
              " 'joint conditional probability': 1462,\n",
              " 'conditional probability based': 558,\n",
              " 'probability based independence': 2432,\n",
              " 'based independence assumption': 280,\n",
              " 'independence assumption masked': 1366,\n",
              " 'assumption masked token': 186,\n",
              " 'masked token separately': 1756,\n",
              " 'token separately reconstructed': 3264,\n",
              " 'comparison ar language': 519,\n",
              " 'language modeling objective': 1532,\n",
              " 'modeling objective factorizes': 1915,\n",
              " 'objective factorizes using': 2077,\n",
              " 'factorizes using product': 1047,\n",
              " 'product rule hold': 2458,\n",
              " 'rule hold universally': 2749,\n",
              " 'hold universally without': 1268,\n",
              " 'universally without independence': 3379,\n",
              " 'without independence assumption': 3519,\n",
              " 'input noise input': 1397,\n",
              " 'noise input bert': 2036,\n",
              " 'input bert contains': 1393,\n",
              " 'bert contains artificial': 321,\n",
              " 'contains artificial symbol': 590,\n",
              " 'like mask never': 1645,\n",
              " 'mask never occur': 1745,\n",
              " 'never occur downstream': 2021,\n",
              " 'occur downstream task': 2109,\n",
              " 'downstream task creates': 864,\n",
              " 'task creates pretrain': 3167,\n",
              " 'creates pretrain finetune': 676,\n",
              " 'replacing mask original': 2637,\n",
              " 'mask original token': 1746,\n",
              " 'original token solve': 2179,\n",
              " 'token solve problem': 3267,\n",
              " 'solve problem original': 2978,\n",
              " 'problem original token': 2442,\n",
              " 'original token used': 2180,\n",
              " 'token used small': 3270,\n",
              " 'used small probability': 3426,\n",
              " 'small probability otherwise': 2972,\n",
              " 'probability otherwise eq': 2434,\n",
              " 'language modeling rely': 1537,\n",
              " 'modeling rely input': 1925,\n",
              " 'rely input corruption': 2626,\n",
              " 'input corruption suffer': 1394,\n",
              " 'corruption suffer issue': 662,\n",
              " 'context dependency ar': 617,\n",
              " 'dependency ar representation': 778,\n",
              " 'ar representation conditioned': 154,\n",
              " 'representation conditioned token': 2645,\n",
              " 'conditioned token position': 560,\n",
              " 'token left bert': 3250,\n",
              " 'left bert representation': 1617,\n",
              " 'bert representation access': 344,\n",
              " 'representation access contextual': 2642,\n",
              " 'access contextual information': 20,\n",
              " 'contextual information side': 636,\n",
              " 'result bert objective': 2679,\n",
              " 'bert objective allows': 336,\n",
              " 'objective allows model': 2063,\n",
              " 'allows model pretrained': 86,\n",
              " 'model pretrained better': 1868,\n",
              " 'pretrained better capture': 2389,\n",
              " 'better capture bidirectional': 377,\n",
              " 'capture bidirectional context': 426,\n",
              " 'objective permutation language': 2087,\n",
              " 'permutation language modeling': 2266,\n",
              " 'language modeling according': 1519,\n",
              " 'modeling according comparison': 1890,\n",
              " 'according comparison ar': 24,\n",
              " 'modeling bert posse': 1895,\n",
              " 'bert posse unique': 337,\n",
              " 'posse unique advantage': 2337,\n",
              " 'natural question ask': 1983,\n",
              " 'question ask whether': 2533,\n",
              " 'ask whether exists': 177,\n",
              " 'whether exists pretraining': 3499,\n",
              " 'exists pretraining objective': 990,\n",
              " 'pretraining objective brings': 2411,\n",
              " 'objective brings advantage': 2068,\n",
              " 'brings advantage avoiding': 409,\n",
              " 'advantage avoiding weakness': 55,\n",
              " 'borrowing idea orderless': 403,\n",
              " 'idea orderless nade': 1306,\n",
              " 'orderless nade propose': 2167,\n",
              " 'nade propose permutation': 1969,\n",
              " 'propose permutation language': 2464,\n",
              " 'modeling objective retains': 1918,\n",
              " 'objective retains benefit': 2092,\n",
              " 'retains benefit ar': 2704,\n",
              " 'benefit ar model': 302,\n",
              " 'ar model also': 148,\n",
              " 'model also allows': 1838,\n",
              " 'also allows model': 91,\n",
              " 'allows model capture': 85,\n",
              " 'model capture bidirectional': 1843,\n",
              " 'specifically sequence length': 2991,\n",
              " 'different order perform': 821,\n",
              " 'order perform valid': 2157,\n",
              " 'perform valid autoregressive': 2248,\n",
              " 'valid autoregressive factorization': 3448,\n",
              " 'intuitively model parameter': 1434,\n",
              " 'model parameter shared': 1866,\n",
              " 'parameter shared across': 2210,\n",
              " 'shared across factorization': 2909,\n",
              " 'across factorization order': 33,\n",
              " 'factorization order expectation': 1031,\n",
              " 'order expectation model': 2149,\n",
              " 'expectation model learn': 1001,\n",
              " 'model learn gather': 1857,\n",
              " 'learn gather information': 1598,\n",
              " 'gather information position': 1164,\n",
              " 'information position side': 1383,\n",
              " 'formalize idea let': 1129,\n",
              " 'idea let zt': 1305,\n",
              " 'let zt set': 1629,\n",
              " 'zt set possible': 3760,\n",
              " 'set possible permutation': 2887,\n",
              " 'possible permutation length': 2343,\n",
              " 'permutation length index': 2267,\n",
              " 'length index sequence': 1620,\n",
              " 'use zt denote': 3419,\n",
              " 'zt denote th': 3745,\n",
              " 'denote th element': 763,\n",
              " 'th element first': 3220,\n",
              " 'element first element': 892,\n",
              " 'first element permutation': 1098,\n",
              " 'element permutation zt': 893,\n",
              " 'proposed permutation language': 2473,\n",
              " 'modeling objective expressed': 1914,\n",
              " 'objective expressed follows': 2076,\n",
              " 'expressed follows max': 1015,\n",
              " 'follows max ez': 1126,\n",
              " 'max ez zt': 1766,\n",
              " 'ez zt log': 1021,\n",
              " 'zt log xzt': 3754,\n",
              " 'log xzt xz': 1687,\n",
              " 'essentially text sequence': 952,\n",
              " 'text sequence sample': 3215,\n",
              " 'sequence sample factorization': 2871,\n",
              " 'sample factorization order': 2761,\n",
              " 'factorization order time': 1042,\n",
              " 'order time decompose': 2161,\n",
              " 'time decompose likelihood': 3238,\n",
              " 'decompose likelihood according': 744,\n",
              " 'likelihood according factorization': 1650,\n",
              " 'according factorization order': 25,\n",
              " 'since model parameter': 2948,\n",
              " 'factorization order training': 1044,\n",
              " 'order training expectation': 2163,\n",
              " 'training expectation xt': 3294,\n",
              " 'expectation xt seen': 1004,\n",
              " 'xt seen every': 3645,\n",
              " 'seen every possible': 2806,\n",
              " 'every possible element': 965,\n",
              " 'possible element xi': 2340,\n",
              " 'element xi xt': 894,\n",
              " 'xi xt sequence': 3546,\n",
              " 'xt sequence hence': 3646,\n",
              " 'sequence hence able': 2862,\n",
              " 'hence able capture': 1238,\n",
              " 'able capture bidirectional': 7,\n",
              " 'moreover objective fit': 1938,\n",
              " 'objective fit ar': 2078,\n",
              " 'fit ar framework': 1109,\n",
              " 'ar framework naturally': 145,\n",
              " 'framework naturally avoids': 1152,\n",
              " 'naturally avoids independence': 1985,\n",
              " 'avoids independence assumption': 251,\n",
              " 'independence assumption pretrain': 1367,\n",
              " 'assumption pretrain finetune': 187,\n",
              " 'finetune discrepancy discussed': 1085,\n",
              " 'discrepancy discussed section': 838,\n",
              " 'remark permutation proposed': 2631,\n",
              " 'permutation proposed objective': 2273,\n",
              " 'proposed objective permutes': 2471,\n",
              " 'objective permutes factorization': 2088,\n",
              " 'permutes factorization order': 2280,\n",
              " 'factorization order sequence': 1040,\n",
              " 'order sequence order': 2159,\n",
              " 'word keep original': 3530,\n",
              " 'keep original sequence': 1485,\n",
              " 'original sequence order': 2176,\n",
              " 'sequence order use': 2867,\n",
              " 'order use positional': 2164,\n",
              " 'use positional encoding': 3411,\n",
              " 'positional encoding corresponding': 2332,\n",
              " 'encoding corresponding original': 924,\n",
              " 'corresponding original sequence': 658,\n",
              " 'original sequence rely': 2177,\n",
              " 'sequence rely proper': 2870,\n",
              " 'rely proper attention': 2628,\n",
              " 'proper attention mask': 2461,\n",
              " 'attention mask transformer': 208,\n",
              " 'mask transformer achieve': 1748,\n",
              " 'transformer achieve permutation': 3302,\n",
              " 'achieve permutation factorization': 27,\n",
              " 'note choice necessary': 2046,\n",
              " 'choice necessary since': 457,\n",
              " 'necessary since model': 1991,\n",
              " 'since model encounter': 2947,\n",
              " 'model encounter text': 1849,\n",
              " 'encounter text sequence': 936,\n",
              " 'text sequence natural': 3214,\n",
              " 'sequence natural order': 2866,\n",
              " 'natural order finetuning': 1982,\n",
              " 'provide overall picture': 2482,\n",
              " 'overall picture show': 2188,\n",
              " 'picture show example': 2283,\n",
              " 'show example predicting': 2922,\n",
              " 'example predicting token': 979,\n",
              " 'predicting token given': 2362,\n",
              " 'token given input': 3248,\n",
              " 'given input sequence': 1191,\n",
              " 'input sequence different': 1405,\n",
              " 'sequence different factorization': 2858,\n",
              " 'factorization order appendix': 1024,\n",
              " 'order appendix figure': 2142,\n",
              " 'architecture two stream': 163,\n",
              " 'two stream self': 3354,\n",
              " 'stream self attention': 3070,\n",
              " 'self attention target': 2833,\n",
              " 'attention target aware': 223,\n",
              " 'target aware representation': 3144,\n",
              " 'aware representation sample': 254,\n",
              " 'representation sample factorization': 2657,\n",
              " 'factorization order attention': 1026,\n",
              " 'order attention mask': 2144,\n",
              " 'attention mask content': 205,\n",
              " 'mask content stream': 1742,\n",
              " 'content stream see': 606,\n",
              " 'stream see self': 3069,\n",
              " 'see self query': 2800,\n",
              " 'self query stream': 2839,\n",
              " 'query stream cannot': 2519,\n",
              " 'stream cannot see': 3059,\n",
              " 'cannot see self': 421,\n",
              " 'see self masked': 2799,\n",
              " 'self masked two': 2838,\n",
              " 'masked two stream': 1758,\n",
              " 'stream attention masked': 3051,\n",
              " 'attention masked two': 209,\n",
              " 'stream attention attention': 3050,\n",
              " 'attention attention attention': 195,\n",
              " 'attention attention figure': 196,\n",
              " 'attention figure content': 200,\n",
              " 'figure content stream': 1066,\n",
              " 'content stream attention': 601,\n",
              " 'stream attention standard': 3056,\n",
              " 'attention standard self': 222,\n",
              " 'standard self attention': 3031,\n",
              " 'query stream attention': 2518,\n",
              " 'stream attention access': 3049,\n",
              " 'attention access information': 193,\n",
              " 'access information content': 21,\n",
              " 'information content xzt': 1378,\n",
              " 'overview permutation language': 2191,\n",
              " 'language modeling training': 1541,\n",
              " 'modeling training two': 1929,\n",
              " 'training two stream': 3300,\n",
              " 'modeling objective desired': 1913,\n",
              " 'objective desired property': 2073,\n",
              " 'desired property naive': 791,\n",
              " 'property naive implementation': 2462,\n",
              " 'naive implementation standard': 1971,\n",
              " 'implementation standard transformer': 1331,\n",
              " 'standard transformer parameterization': 3035,\n",
              " 'transformer parameterization may': 3308,\n",
              " 'parameterization may work': 2213,\n",
              " 'see problem assume': 2797,\n",
              " 'problem assume parameterize': 2438,\n",
              " 'assume parameterize next': 181,\n",
              " 'parameterize next token': 2216,\n",
              " 'next token distribution': 2032,\n",
              " 'token distribution xzt': 3244,\n",
              " 'distribution xzt xz': 852,\n",
              " 'xzt xz using': 3670,\n",
              " 'xz using standard': 3655,\n",
              " 'using standard softmax': 3442,\n",
              " 'standard softmax formulation': 3032,\n",
              " 'softmax formulation xzt': 2975,\n",
              " 'formulation xzt xz': 1135,\n",
              " 'xzt xz exp': 3669,\n",
              " 'xz exp xz': 3650,\n",
              " 'exp xz exp': 995,\n",
              " 'exp xz xz': 996,\n",
              " 'xz xz denotes': 3657,\n",
              " 'xz denotes hidden': 3648,\n",
              " 'denotes hidden representation': 766,\n",
              " 'hidden representation xz': 1246,\n",
              " 'representation xz produced': 2664,\n",
              " 'xz produced shared': 3654,\n",
              " 'produced shared transformer': 2454,\n",
              " 'shared transformer network': 2913,\n",
              " 'transformer network proper': 3307,\n",
              " 'network proper masking': 1999,\n",
              " 'notice representation xz': 2052,\n",
              " 'representation xz depend': 2663,\n",
              " 'xz depend position': 3649,\n",
              " 'depend position predict': 777,\n",
              " 'position predict value': 2315,\n",
              " 'predict value zt': 2355,\n",
              " 'consequently distribution predicted': 571,\n",
              " 'distribution predicted regardless': 847,\n",
              " 'predicted regardless target': 2356,\n",
              " 'regardless target position': 2602,\n",
              " 'target position able': 3149,\n",
              " 'position able learn': 2301,\n",
              " 'able learn useful': 11,\n",
              " 'learn useful representation': 1599,\n",
              " 'useful representation see': 3430,\n",
              " 'representation see appendix': 2659,\n",
              " 'see appendix concrete': 2795,\n",
              " 'appendix concrete example': 134,\n",
              " 'avoid problem propose': 250,\n",
              " 'problem propose parameterize': 2443,\n",
              " 'propose parameterize next': 2463,\n",
              " 'token distribution target': 3243,\n",
              " 'distribution target position': 848,\n",
              " 'target position aware': 3150,\n",
              " 'position aware xzt': 2302,\n",
              " 'aware xzt xz': 256,\n",
              " 'exp xz zt': 997,\n",
              " 'xz zt exp': 3662,\n",
              " 'zt exp xz': 3747,\n",
              " 'xz zt xz': 3665,\n",
              " 'zt xz zt': 3763,\n",
              " 'xz zt denotes': 3661,\n",
              " 'zt denotes new': 3746,\n",
              " 'denotes new type': 767,\n",
              " 'new type representation': 2025,\n",
              " 'type representation additionally': 3358,\n",
              " 'representation additionally take': 2643,\n",
              " 'additionally take target': 51,\n",
              " 'take target position': 3138,\n",
              " 'target position zt': 3153,\n",
              " 'position zt input': 2329,\n",
              " 'self attention idea': 2831,\n",
              " 'attention idea target': 204,\n",
              " 'idea target aware': 1311,\n",
              " 'aware representation remove': 253,\n",
              " 'representation remove ambiguity': 2656,\n",
              " 'remove ambiguity target': 2632,\n",
              " 'ambiguity target prediction': 107,\n",
              " 'target prediction formulate': 3155,\n",
              " 'prediction formulate xz': 2370,\n",
              " 'formulate xz zt': 1133,\n",
              " 'xz zt remains': 3663,\n",
              " 'zt remains non': 3759,\n",
              " 'remains non trivial': 2630,\n",
              " 'non trivial problem': 2039,\n",
              " 'among possibility propose': 109,\n",
              " 'possibility propose stand': 2339,\n",
              " 'propose stand target': 2466,\n",
              " 'stand target position': 3022,\n",
              " 'position zt rely': 2330,\n",
              " 'zt rely position': 3758,\n",
              " 'rely position zt': 2627,\n",
              " 'position zt gather': 2328,\n",
              " 'zt gather information': 3749,\n",
              " 'gather information context': 1163,\n",
              " 'information context xz': 1379,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3npw-JCJcHmL",
        "outputId": "5b163d40-aabe-4592-febc-b638253e3aff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xlnet generalized autoregressive pretraining language understanding zhilin yang zihang dai yiming yang jaime carbonell ruslan salakhutdinov quoc v le carnegie mellon university google ai brain team zhiliny dzihang yiming jgc rsalakhu c cmu edu qvl google com abstract capability modeling bidirectional context denoising autoencoding based pretraining like bert achieves better performance pretraining approach based autoregressive language modeling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-bbsGGycLUG",
        "outputId": "ea883971-6e49-4819-cdc5-b0f10b0fc50f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N45LK8stcM1M",
        "outputId": "259199fe-3019-4779-e562-c7f0dbafcf9e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3766)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### TF -IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer(ngram_range =(1,1),max_features=20)\n",
        "x = cv.fit_transform(corpus)\n"
      ],
      "metadata": {
        "id": "nFnzKoJzcPY6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "y9t1-iy5cRCW",
        "outputId": "cac7a327-95e8-4f5f-e298-77bc120c7db4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xlnet generalized autoregressive pretraining language understanding zhilin yang zihang dai yiming yang jaime carbonell ruslan salakhutdinov quoc v le carnegie mellon university google ai brain team zhiliny dzihang yiming jgc rsalakhu c cmu edu qvl google com abstract capability modeling bidirectional context denoising autoencoding based pretraining like bert achieves better performance pretraining approach based autoregressive language modeling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6mTKZOycSeO",
        "outputId": "2f562842-7b56-4635-eb71-a2978c7b481a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.19326762, 0.24181002, 0.        ,\n",
              "        0.39054391, 0.        , 0.43613309, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.72543005, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.18759042, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJGLvTJlcUDm"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}